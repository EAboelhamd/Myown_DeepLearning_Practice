{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction .. \n",
    "\n",
    "In this notebook LSTM will be used to perform sentiment analysis on movie reviews from the Large Movie Review Dataset (IMDB) .. \n",
    "\n",
    "The dataset can be downloaded from ==> http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\n",
    "In this task, given a movie review, the model attempts to predict whether it is positive or negative (i.e. This is a\n",
    "binary classification task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import six.moves.cPickle as pickle\n",
    "\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "import theano\n",
    "from theano import config\n",
    "import theano.tensor as tensor\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "\n",
    "import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'imdb': (<function imdb.load_data>, <function imdb.prepare_data>)}"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = {'imdb': (imdb.load_data, imdb.prepare_data)}\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the random number generators' seeds for consistency\n",
    "SEED = 123\n",
    "numpy.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## this is to adjust the type of the data .. determine it at running time (i.e. float64 in case of GPUs)\n",
    "def numpy_floatX(data):\n",
    "    return numpy.asarray(data, dtype=config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Used to shuffle the dataset at each iteration.\n",
    "def get_minibatches_idx(n, minibatch_size, shuffle=False):\n",
    "\n",
    "    idx_list = numpy.arange(n, dtype=\"int32\")\n",
    "\n",
    "    if shuffle:\n",
    "        numpy.random.shuffle(idx_list)\n",
    "\n",
    "    minibatches = []\n",
    "    minibatch_start = 0\n",
    "    for i in range(n // minibatch_size):\n",
    "        minibatches.append(idx_list[minibatch_start: minibatch_start + minibatch_size])\n",
    "        minibatch_start += minibatch_size\n",
    "\n",
    "    if (minibatch_start != n):\n",
    "        # Make a minibatch out of what is left\n",
    "        minibatches.append(idx_list[minibatch_start:])\n",
    "\n",
    "    return zip(range(len(minibatches)), minibatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataset(name):\n",
    "    return datasets[name][0], datasets[name][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## drop out .. \n",
    "def dropout_layer(state_before, use_noise, trng):\n",
    "    proj = tensor.switch(use_noise,\n",
    "                         (state_before * trng.binomial(state_before.shape, p = 0.5, n = 1, dtype=state_before.dtype))\n",
    "                         , state_before * 0.5)\n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _p(pp, name):\n",
    "    return '%s_%s' % (pp, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For the embeding and the classifier \n",
    "def init_params(options):\n",
    "\n",
    "    params = OrderedDict()\n",
    "    # embedding\n",
    "    randn = numpy.random.rand(options['n_words'], options['dim_proj'])\n",
    "    params['Wemb'] = (0.01 * randn).astype(config.floatX)  # weights os the input \n",
    "    params = get_layer(options['encoder'])[0](options, params, prefix=options['encoder'])\n",
    "    # classifier\n",
    "    params['U'] = 0.01 * numpy.random.randn(options['dim_proj'], options['ydim']).astype(config.floatX) # weights for the output\n",
    "    params['b'] = numpy.zeros((options['ydim'],)).astype(config.floatX)  # biases\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## load the paramters of the model \n",
    "def load_params(path, params):\n",
    "    pp = numpy.load(path)\n",
    "    for kk, vv in params.items():\n",
    "        if kk not in pp:\n",
    "            raise Warning('%s is not in the archive' % kk)\n",
    "        params[kk] = pp[kk]\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## init the paramters of the model \n",
    "def init_tparams(params):\n",
    "    tparams = OrderedDict()\n",
    "    for kk, pp in params.items():\n",
    "        tparams[kk] = theano.shared(params[kk], name=kk)\n",
    "    return tparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_layer(name):\n",
    "    fns = layers[name]\n",
    "    return fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ortho_weight(ndim):\n",
    "    W = numpy.random.randn(ndim, ndim)\n",
    "    u, s, v = numpy.linalg.svd(W)\n",
    "    return u.astype(config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Init the LSTM parameter:\n",
    "## in this implementation, all the weights are going to be concatenated in one big weight matrix for fatser results \n",
    "def param_init_lstm(options, params, prefix='lstm'):\n",
    "\n",
    "    W = numpy.concatenate([ortho_weight(options['dim_proj']),\n",
    "                           ortho_weight(options['dim_proj']),\n",
    "                           ortho_weight(options['dim_proj']),\n",
    "                           ortho_weight(options['dim_proj'])], axis=1)\n",
    "    params[_p(prefix, 'W')] = W\n",
    "    U = numpy.concatenate([ortho_weight(options['dim_proj']),\n",
    "                           ortho_weight(options['dim_proj']),\n",
    "                           ortho_weight(options['dim_proj']),\n",
    "                           ortho_weight(options['dim_proj'])], axis=1)\n",
    "    params[_p(prefix, 'U')] = U\n",
    "    b = numpy.zeros((4 * options['dim_proj'],))\n",
    "    params[_p(prefix, 'b')] = b.astype(config.floatX)\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM model .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_layer(tparams, state_below, options, prefix='lstm', mask=None):\n",
    "    nsteps = state_below.shape[0]\n",
    "    if state_below.ndim == 3:\n",
    "        n_samples = state_below.shape[1]\n",
    "    else:\n",
    "        n_samples = 1\n",
    "\n",
    "    assert mask is not None\n",
    "\n",
    "    def _slice(_x, n, dim):\n",
    "        if _x.ndim == 3:\n",
    "            return _x[:, :, n * dim:(n + 1) * dim]\n",
    "        return _x[:, n * dim:(n + 1) * dim]\n",
    "\n",
    "    def _step(m_, x_, h_, c_): # c is the candidate value \n",
    "        preact = tensor.dot(h_, tparams[_p(prefix, 'U')])\n",
    "        preact += x_\n",
    "\n",
    "        i = tensor.nnet.sigmoid(_slice(preact, 0, options['dim_proj']))\n",
    "        f = tensor.nnet.sigmoid(_slice(preact, 1, options['dim_proj']))\n",
    "        o = tensor.nnet.sigmoid(_slice(preact, 2, options['dim_proj']))\n",
    "        c = tensor.tanh(_slice(preact, 3, options['dim_proj']))\n",
    "\n",
    "        c = f * c_ + i * c\n",
    "        c = m_[:, None] * c + (1. - m_)[:, None] * c_\n",
    "\n",
    "        h = o * tensor.tanh(c)\n",
    "        h = m_[:, None] * h + (1. - m_)[:, None] * h_\n",
    "\n",
    "        return h, c\n",
    "\n",
    "    state_below = (tensor.dot(state_below, tparams[_p(prefix, 'W')]) +\n",
    "                   tparams[_p(prefix, 'b')])\n",
    "\n",
    "    dim_proj = options['dim_proj']\n",
    "    rval, updates = theano.scan(_step,\n",
    "                                sequences=[mask, state_below],\n",
    "                                outputs_info=[tensor.alloc(numpy_floatX(0.), n_samples, dim_proj),\n",
    "                                              tensor.alloc(numpy_floatX(0.), n_samples, dim_proj)],\n",
    "                                name=_p(prefix, '_layers'), n_steps=nsteps)\n",
    "    return rval[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lstm': (<function __main__.param_init_lstm>, <function __main__.lstm_layer>)}"
      ]
     },
     "execution_count": 824,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ff: Feed Forward (normal neural net), only useful to put after lstm before the classifier.\n",
    "layers = {'lstm': (param_init_lstm, lstm_layer)}\n",
    "layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__:\n",
    "In this implementation three optimizers are used (SGD, AdaDelta and RMSProp) .. however, SGD gives the worest results .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sgd(lr, tparams, grads, x, mask, y, cost):\n",
    "    \"\"\" Stochastic Gradient Descent\n",
    "\n",
    "    :note: A more complicated version of sgd then needed.  This is\n",
    "        done like that for adadelta and rmsprop.\n",
    "\n",
    "    \"\"\"\n",
    "    # New set of shared variable that will contain the gradient\n",
    "    # for a mini-batch.\n",
    "    gshared = [theano.shared(p.get_value() * 0., name='%s_grad' % k)\n",
    "               for k, p in tparams.items()]\n",
    "    gsup = [(gs, g) for gs, g in zip(gshared, grads)]\n",
    "\n",
    "    # Function that computes gradients for a mini-batch, but do not\n",
    "    # updates the weights.\n",
    "    f_grad_shared = theano.function([x, mask, y], cost, updates=gsup,\n",
    "                                    name='sgd_f_grad_shared')\n",
    "\n",
    "    pup = [(p, p - lr * g) for p, g in zip(tparams.values(), gshared)]\n",
    "\n",
    "    # Function that updates the weights from the previously computed gradient.\n",
    "    f_update = theano.function([lr], [], updates=pup, name='sgd_f_update')\n",
    "\n",
    "    return f_grad_shared, f_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An adaptive learning rate optimizer\n",
    "\n",
    "Inputs:\n",
    "----------\n",
    "lr : Theano SharedVariable Initial learning rate\n",
    "\n",
    "tpramas: Theano SharedVariable Model parameters\n",
    "\n",
    "grads: Theano variable Gradients of cost w.r.t to parameres\n",
    "\n",
    "x: Theano variable Model inputs\n",
    "\n",
    "mask: Theano variable Sequence mask\n",
    "\n",
    "y: Theano variable Targets\n",
    "\n",
    "cost: Theano variable Objective fucntion to minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adadelta(lr, tparams, grads, x, mask, y, cost):\n",
    "\n",
    "    zipped_grads = [theano.shared(p.get_value() * numpy_floatX(0.),\n",
    "                                  name='%s_grad' % k)\n",
    "                    for k, p in tparams.items()]\n",
    "    running_up2 = [theano.shared(p.get_value() * numpy_floatX(0.),\n",
    "                                 name='%s_rup2' % k)\n",
    "                   for k, p in tparams.items()]\n",
    "    running_grads2 = [theano.shared(p.get_value() * numpy_floatX(0.),\n",
    "                                    name='%s_rgrad2' % k)\n",
    "                      for k, p in tparams.items()]\n",
    "\n",
    "    zgup = [(zg, g) for zg, g in zip(zipped_grads, grads)]\n",
    "    rg2up = [(rg2, 0.95 * rg2 + 0.05 * (g ** 2))\n",
    "             for rg2, g in zip(running_grads2, grads)]\n",
    "\n",
    "    f_grad_shared = theano.function([x, mask, y], cost, updates=zgup + rg2up,\n",
    "                                    name='adadelta_f_grad_shared')\n",
    "\n",
    "    updir = [-tensor.sqrt(ru2 + 1e-6) / tensor.sqrt(rg2 + 1e-6) * zg\n",
    "             for zg, ru2, rg2 in zip(zipped_grads,\n",
    "                                     running_up2,\n",
    "                                     running_grads2)]\n",
    "    ru2up = [(ru2, 0.95 * ru2 + 0.05 * (ud ** 2))\n",
    "             for ru2, ud in zip(running_up2, updir)]\n",
    "    param_up = [(p, p + ud) for p, ud in zip(tparams.values(), updir)]\n",
    "\n",
    "    f_update = theano.function([lr], [], updates=ru2up + param_up, on_unused_input='ignore', name='adadelta_f_update')\n",
    "\n",
    "    return f_grad_shared, f_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A variant of  SGD that scales the step size by running average of the recent step norms.\n",
    "def rmsprop(lr, tparams, grads, x, mask, y, cost):\n",
    "\n",
    "    zipped_grads = [theano.shared(p.get_value() * numpy_floatX(0.),\n",
    "                                  name='%s_grad' % k)\n",
    "                    for k, p in tparams.items()]\n",
    "    running_grads = [theano.shared(p.get_value() * numpy_floatX(0.),\n",
    "                                   name='%s_rgrad' % k)\n",
    "                     for k, p in tparams.items()]\n",
    "    running_grads2 = [theano.shared(p.get_value() * numpy_floatX(0.),\n",
    "                                    name='%s_rgrad2' % k)\n",
    "                      for k, p in tparams.items()]\n",
    "\n",
    "    zgup = [(zg, g) for zg, g in zip(zipped_grads, grads)]\n",
    "    rgup = [(rg, 0.95 * rg + 0.05 * g) for rg, g in zip(running_grads, grads)]\n",
    "    rg2up = [(rg2, 0.95 * rg2 + 0.05 * (g ** 2))\n",
    "             for rg2, g in zip(running_grads2, grads)]\n",
    "\n",
    "    f_grad_shared = theano.function([x, mask, y], cost,\n",
    "                                    updates=zgup + rgup + rg2up,\n",
    "                                    name='rmsprop_f_grad_shared')\n",
    "\n",
    "    updir = [theano.shared(p.get_value() * numpy_floatX(0.),\n",
    "                           name='%s_updir' % k)\n",
    "             for k, p in tparams.items()]\n",
    "    updir_new = [(ud, 0.9 * ud - 1e-4 * zg / tensor.sqrt(rg2 - rg ** 2 + 1e-4))\n",
    "                 for ud, zg, rg, rg2 in zip(updir, zipped_grads, running_grads,\n",
    "                                            running_grads2)]\n",
    "    \n",
    "    param_up = [(p, p + udn[1]) for p, udn in zip(tparams.values(), updir_new)]\n",
    "    f_update = theano.function([lr], [], updates=updir_new + param_up, on_unused_input='ignore', name='rmsprop_f_update')\n",
    "\n",
    "    return f_grad_shared, f_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(tparams, options):\n",
    "    trng = RandomStreams(SEED)\n",
    "\n",
    "    # Used for dropout.\n",
    "    use_noise = theano.shared(numpy_floatX(0.))\n",
    "\n",
    "    x = tensor.matrix('x', dtype='int64')\n",
    "    mask = tensor.matrix('mask', dtype=config.floatX)\n",
    "    y = tensor.vector('y', dtype='int64')\n",
    "\n",
    "    n_timesteps = x.shape[0]\n",
    "    n_samples = x.shape[1]\n",
    "\n",
    "    emb = tparams['Wemb'][x.flatten()].reshape([n_timesteps, n_samples, options['dim_proj']])\n",
    "    proj = get_layer(options['encoder'])[1](tparams, emb, options, prefix=options['encoder'], mask=mask)\n",
    "    \n",
    "    if options['encoder'] == 'lstm':\n",
    "        proj = (proj * mask[:, :, None]).sum(axis=0)\n",
    "        proj = proj / mask.sum(axis=0)[:, None]\n",
    "        \n",
    "    if options['use_dropout']:\n",
    "        proj = dropout_layer(proj, use_noise, trng)\n",
    "\n",
    "    pred = tensor.nnet.softmax(tensor.dot(proj, tparams['U']) + tparams['b'])\n",
    "\n",
    "    f_pred_prob = theano.function([x, mask], pred, name='f_pred_prob')\n",
    "    f_pred = theano.function([x, mask], pred.argmax(axis=1), name='f_pred')\n",
    "\n",
    "    off = 1e-8\n",
    "    if pred.dtype == 'float16':\n",
    "        off = 1e-6\n",
    "\n",
    "    cost = -tensor.log(pred[tensor.arange(n_samples), y] + off).mean()\n",
    "\n",
    "    return use_noise, x, mask, y, f_pred_prob, f_pred, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you want to use a trained model, this is useful to compute the probabilities of new examples.\n",
    "\n",
    "def pred_probs(f_pred_prob, prepare_data, data, iterator, verbose=False):\n",
    "\n",
    "    n_samples = len(data[0])\n",
    "    probs = numpy.zeros((n_samples, 2)).astype(config.floatX)\n",
    "\n",
    "    n_done = 0\n",
    "\n",
    "    for _, valid_index in iterator:\n",
    "        x, mask, y = prepare_data([data[0][t] for t in valid_index],\n",
    "                                  numpy.array(data[1])[valid_index], maxlen=None)\n",
    "        pred_probs = f_pred_prob(x, mask)\n",
    "        probs[valid_index, :] = pred_probs\n",
    "\n",
    "        n_done += len(valid_index)\n",
    "        if verbose:\n",
    "            print('%d/%d samples classified' % (n_done, n_samples))\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# f_pred: Theano fct computing the prediction prepare_data: usual prepare_data for that dataset.\n",
    "def pred_error(f_pred, prepare_data, data, iterator, verbose=False):\n",
    "    \n",
    "    valid_err = 0\n",
    "    for _, valid_index in iterator:\n",
    "        x, mask, y = prepare_data([data[0][t] for t in valid_index], numpy.array(data[1])[valid_index], maxlen=None)\n",
    "        preds = f_pred(x, mask)\n",
    "        targets = numpy.array(data[1])[valid_index]\n",
    "        valid_err += (preds == targets).sum()\n",
    "    valid_err = 1. - numpy_floatX(valid_err) / len(data[0])\n",
    "\n",
    "    return valid_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are needed if u r working on a GPU .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zipp(params, tparams):\n",
    "    for kk, vv in params.items():\n",
    "        tparams[kk].set_value(vv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unzip(zipped):\n",
    "    new_params = OrderedDict()\n",
    "    for kk, vv in zipped.items():\n",
    "        new_params[kk] = vv.get_value()\n",
    "    return new_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_lstm(max_epochs, test_size):\n",
    "    \n",
    "    ## function (i.e. model) parameters .. \n",
    "    dim_proj=128  # word embeding dimension and LSTM number of hidden units.\n",
    "    patience=10  # Number of epoch to wait before early stop if no progress\n",
    "    max_epochs=5000  # The maximum number of epoch to run\n",
    "    dispFreq=10  # Display to stdout the training progress every N updates\n",
    "    decay_c=0.  # Weight decay for the classifier applied to the U weights.\n",
    "    lrate=0.0001  # Learning rate for sgd (not used for adadelta and rmsprop)\n",
    "    n_words=10000  # Vocabulary size\n",
    "    optimizer=adadelta  # sgd, adadelta and rmsprop available, sgd very hard to use, not recommanded (probably need momentum and decaying learning rate).\n",
    "    encoder='lstm'  # TODO: can be removed must be lstm.\n",
    "    saveto='lstm_model.npz'  # The best model will be saved there\n",
    "    validFreq=370  # Compute the validation error after this number of update.\n",
    "    saveFreq=1110  # Save the parameters after every saveFreq updates\n",
    "    maxlen=100  # Sequence longer then this get ignored\n",
    "    batch_size=16  # The batch size during training.\n",
    "    valid_batch_size=64  # The batch size used for validation/test set.\n",
    "    dataset='imdb'\n",
    "\n",
    "    # Parameter for extra option\n",
    "    noise_std=0.\n",
    "    use_dropout=True  # if False slightly faster, but worst test error\n",
    "                       # This frequently need a bigger model.\n",
    "    reload_model=None  # Path to a saved model we want to start from.\n",
    "    test_size=-1  # If >0, we keep only this number of test example.\n",
    "\n",
    "    \n",
    "    # Model options\n",
    "    model_options = locals().copy()\n",
    "    print(\"model options\", model_options)\n",
    "   \n",
    "    load_data, prepare_data = get_dataset(dataset)\n",
    "\n",
    "    print('Loading data')\n",
    "    \n",
    "#     print (type(load_data))  ## it's a function ..\n",
    "\n",
    "    train, valid, test = load_data(n_words = n_words, valid_portion = 0.05, maxlen = maxlen)\n",
    "    \n",
    "    if test_size > 0:\n",
    "        # The test set is sorted by size, but we want to keep random\n",
    "        # size example.  So we must select a random selection of the examples.\n",
    "        idx = numpy.arange(len(test[0]))\n",
    "        numpy.random.shuffle(idx)\n",
    "        idx = idx[:test_size]\n",
    "        test = ([test[0][n] for n in idx], [test[1][n] for n in idx])\n",
    "\n",
    "    ydim = numpy.max(train[1]) + 1\n",
    "\n",
    "    model_options['ydim'] = ydim\n",
    "\n",
    "    print('Building model')\n",
    "    # This create the initial parameters as numpy ndarrays.\n",
    "    # Dict name (string) -> numpy ndarray\n",
    "    params = init_params(model_options)\n",
    "\n",
    "    if reload_model:\n",
    "        load_params('lstm_model.npz', params)\n",
    "\n",
    "    # This create Theano Shared Variable from the parameters.\n",
    "    # Dict name (string) -> Theano Tensor Shared Variable\n",
    "    # params and tparams have different copy of the weights.\n",
    "    tparams = init_tparams(params)\n",
    "\n",
    "    # use_noise is for dropout\n",
    "    (use_noise, x, mask,\n",
    "     y, f_pred_prob, f_pred, cost) = build_model(tparams, model_options)\n",
    "\n",
    "    if decay_c > 0.:\n",
    "        decay_c = theano.shared(numpy_floatX(decay_c), name='decay_c')\n",
    "        weight_decay = 0.\n",
    "        weight_decay += (tparams['U'] ** 2).sum()\n",
    "        weight_decay *= decay_c\n",
    "        cost += weight_decay\n",
    "\n",
    "    f_cost = theano.function([x, mask, y], cost, name='f_cost')\n",
    "\n",
    "    grads = tensor.grad(cost, wrt=list(tparams.values()))\n",
    "    f_grad = theano.function([x, mask, y], grads, name='f_grad')\n",
    "\n",
    "    lr = tensor.scalar(name='lr')\n",
    "    f_grad_shared, f_update = optimizer(lr, tparams, grads,\n",
    "                                        x, mask, y, cost)\n",
    "\n",
    "    print('Optimization')\n",
    "\n",
    "    kf_valid = get_minibatches_idx(len(valid[0]), valid_batch_size)\n",
    "    kf_test = get_minibatches_idx(len(test[0]), valid_batch_size)\n",
    "\n",
    "    print(\"%d train examples\" % len(train[0]))\n",
    "    print(\"%d valid examples\" % len(valid[0]))\n",
    "    print(\"%d test examples\" % len(test[0]))\n",
    "\n",
    "    history_errs = []\n",
    "    best_p = None\n",
    "    bad_count = 0\n",
    "\n",
    "    if validFreq == -1:\n",
    "        validFreq = len(train[0]) // batch_size\n",
    "    if saveFreq == -1:\n",
    "        saveFreq = len(train[0]) // batch_size\n",
    "\n",
    "    uidx = 0  # the number of update done\n",
    "    estop = False  # early stop\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        for eidx in range(max_epochs):\n",
    "            n_samples = 0\n",
    "\n",
    "            # Get new shuffled index for the training set.\n",
    "            kf = get_minibatches_idx(len(train[0]), batch_size, shuffle=True)\n",
    "\n",
    "            for _, train_index in kf:\n",
    "                uidx += 1\n",
    "                use_noise.set_value(1.)\n",
    "\n",
    "                # Select the random examples for this minibatch\n",
    "                y = [train[1][t] for t in train_index]\n",
    "                x = [train[0][t]for t in train_index]\n",
    "\n",
    "                # Get the data in numpy.ndarray format\n",
    "                # This swap the axis!\n",
    "                # Return something of shape (minibatch maxlen, n samples)\n",
    "                x, mask, y = prepare_data(x, y)\n",
    "                n_samples += x.shape[1]\n",
    "\n",
    "                cost = f_grad_shared(x, mask, y)\n",
    "                f_update(lrate)\n",
    "\n",
    "                if numpy.isnan(cost) or numpy.isinf(cost):\n",
    "                    print('bad cost detected: ', cost)\n",
    "                    return 1., 1., 1.\n",
    "\n",
    "                if numpy.mod(uidx, dispFreq) == 0:\n",
    "                    print('Epoch ', eidx, 'Update ', uidx, 'Cost ', cost)\n",
    "\n",
    "                if saveto and numpy.mod(uidx, saveFreq) == 0:\n",
    "                    print('Saving...')\n",
    "\n",
    "                    if best_p is not None:\n",
    "                        params = best_p\n",
    "                    else:\n",
    "                        params = unzip(tparams)\n",
    "                    numpy.savez(saveto, history_errs=history_errs, **params)\n",
    "                    pickle.dump(model_options, open('%s.pkl' % saveto, 'wb'), -1)\n",
    "                    print('Done')\n",
    "\n",
    "                if numpy.mod(uidx, validFreq) == 0:\n",
    "                    use_noise.set_value(0.)\n",
    "                    train_err = pred_error(f_pred, prepare_data, train, kf)\n",
    "                    valid_err = pred_error(f_pred, prepare_data, valid,\n",
    "                                           kf_valid)\n",
    "                    test_err = pred_error(f_pred, prepare_data, test, kf_test)\n",
    "\n",
    "                    history_errs.append([valid_err, test_err])\n",
    "\n",
    "                    if (best_p is None or\n",
    "                        valid_err <= numpy.array(history_errs)[:,\n",
    "                                                               0].min()):\n",
    "\n",
    "                        best_p = unzip(tparams)\n",
    "                        bad_counter = 0\n",
    "\n",
    "                    print('Train ', train_err, 'Valid ', valid_err,\n",
    "                           'Test ', test_err)\n",
    "\n",
    "                    if (len(history_errs) > patience and\n",
    "                        valid_err >= numpy.array(history_errs)[:-patience,\n",
    "                                                               0].min()):\n",
    "                        bad_counter += 1\n",
    "                        if bad_counter > patience:\n",
    "                            print('Early Stop!')\n",
    "                            estop = True\n",
    "                            break\n",
    "\n",
    "            print('Seen %d samples' % n_samples)\n",
    "\n",
    "            if estop:\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Training interupted\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    if best_p is not None:\n",
    "        zipp(best_p, tparams)\n",
    "    else:\n",
    "        best_p = unzip(tparams)\n",
    "\n",
    "    use_noise.set_value(0.)\n",
    "    kf_train_sorted = get_minibatches_idx(len(train[0]), batch_size)\n",
    "    train_err = pred_error(f_pred, prepare_data, train, kf_train_sorted)\n",
    "    valid_err = pred_error(f_pred, prepare_data, valid, kf_valid)\n",
    "    test_err = pred_error(f_pred, prepare_data, test, kf_test)\n",
    "\n",
    "    print( 'Train ', train_err, 'Valid ', valid_err, 'Test ', test_err )\n",
    "    if saveto:\n",
    "        numpy.savez(saveto, train_err=train_err,\n",
    "                    valid_err=valid_err, test_err=test_err,\n",
    "                    history_errs=history_errs, **best_p)\n",
    "    print('The code run for %d epochs, with %f sec/epochs' % (\n",
    "        (eidx + 1), (end_time - start_time) / (1. * (eidx + 1))))\n",
    "    print( ('Training took %.1fs' %\n",
    "            (end_time - start_time)), file=sys.stderr)\n",
    "    return train_err, valid_err, test_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model options {'encoder': 'lstm', 'optimizer': <function adadelta at 0x7f0dec293c80>, 'validFreq': 370, 'n_words': 10000, 'batch_size': 16, 'decay_c': 0.0, 'patience': 10, 'reload_model': None, 'lrate': 0.0001, 'max_epochs': 5000, 'dispFreq': 10, 'dataset': 'imdb', 'valid_batch_size': 64, 'use_dropout': True, 'dim_proj': 128, 'maxlen': 100, 'saveto': 'lstm_model.npz', 'noise_std': 0.0, 'test_size': -1, 'saveFreq': 1110}\n",
      "Loading data\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-840-e2cc25d0c8a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-835-3bca72fe265b>\u001b[0m in \u001b[0;36mtrain_lstm\u001b[0;34m(max_epochs, test_size)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m#     print (type(load_data))  ## it's a function ..\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_portion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mimdb.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(path, n_words, valid_portion, maxlen, sort_by_len)\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_lstm(max_epochs=100, test_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment:\n",
    "This implementation stems from that one here ==> http://deeplearning.net/tutorial/deeplearning.pdf\n",
    "\n",
    "It run correctly at the beginning but suddenly gave an error in the test_set (as shown above) .. taking into consideration that it imports imdb notebook that loads the data and preprocess it ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
