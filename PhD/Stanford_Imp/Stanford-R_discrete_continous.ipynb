{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "This is an implementation for Stanford paper without any modification .. \n",
    "\n",
    "\n",
    "Main Goals:\n",
    "\n",
    "1. Identify the recipients that will engage with the campaign.\n",
    "2. Maximise the campaignâ€™s revenue.\n",
    "\n",
    "\n",
    "Comments\n",
    "\n",
    "- The dataset contains only 5% of donors.\n",
    "- The donations are usually smaller than $20.\n",
    "- This data is quite noisy, high dimensional.\n",
    "- There is an inverse relationship between the probability to donate and the amount donated.\n",
    "\n",
    "\n",
    "Link for dataset and some analysis ==> \n",
    "\n",
    "https://github.com/rebordao/kdd98cup\n",
    "\n",
    "https://github.com/bobbyantonio/KDD98/blob/master/CleanData.py\n",
    "\n",
    "- Github solutions ==>\n",
    "https://github.com/rebordao/kdd98cup\n",
    "\n",
    "\n",
    "- Siraj notebook for a better data visualization:\n",
    "\n",
    "https://www.youtube.com/watch?v=yQsOFWqpjkE\n",
    "\n",
    "- Implementations:\n",
    "\n",
    "https://github.com/sisl/CustomerSim/blob/master/src/kdd98_preprocess.R\n",
    "\n",
    "https://github.com/ugo-nama-kun/DQN-chainer/blob/master/dqn_agent_nature.py\n",
    "\n",
    "- Yegor Tk's website => http://yegortkachenko.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# from tensorflow.python.ops import rnn, rnn_cell\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "## plotting .. \n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import random \n",
    "# random.seed(123)\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "## warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df = pd.read_csv('tuple.csv', header = 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r0</th>\n",
       "      <th>f0</th>\n",
       "      <th>m0</th>\n",
       "      <th>ir0</th>\n",
       "      <th>if0</th>\n",
       "      <th>a</th>\n",
       "      <th>r1</th>\n",
       "      <th>f1</th>\n",
       "      <th>m1</th>\n",
       "      <th>ir1</th>\n",
       "      <th>if1</th>\n",
       "      <th>rew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  r0 f0 m0 ir0 if0  a r1 f1 m1 ir1 if1 rew\n",
       "0  0  0  0   0   0  5  0  1  9   0   1   9\n",
       "1  0  0  0   0   0  5  1  0  0   0   1   0\n",
       "2  0  0  0   0   0  5  0  1  6   0   1   6\n",
       "3  0  0  0   0   0  0  1  0  0   1   0   0\n",
       "4  0  0  0   0   0  5  1  0  0   0   1   0"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_split():\n",
    "    df = load_data()\n",
    "    \n",
    "    df_ = pd.DataFrame(np.hstack((df, np.ones([np.shape(df)[0], 1])+1)), columns = ['r0', 'f0', 'm0', 'ir0', 'if0', 'a', 'r1', 'f1', 'm1', 'ir1', 'if1', 'rew', 'ac'])  ## adding the cont. var to df (month number)\n",
    "    \n",
    "    train, test = train_test_split(df_, test_size = 0.95)  # split data to 50-50 cross validate, Roger 1.6*1000,000\n",
    "    \n",
    "    train = train.convert_objects(convert_numeric=True)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, _ = df_split()\n",
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_(train):\n",
    "       \n",
    "    next_actions = np.zeros([np.shape(train)[0], 12])\n",
    "    \n",
    "    #     # fill in next_actions  \n",
    "    for i in xrange(11):\n",
    "        next_actions[:, i] = i\n",
    "    \n",
    "    \n",
    "    # next_state_next_action\n",
    "    tuplesMx0 = np.column_stack((train, next_actions[:,0]))\n",
    "    tuplesMx1 = np.column_stack((train, next_actions[:,1]))\n",
    "    tuplesMx2 = np.column_stack((train, next_actions[:,2]))\n",
    "    tuplesMx3 = np.column_stack((train, next_actions[:,3]))\n",
    "    tuplesMx4 = np.column_stack((train, next_actions[:,4]))\n",
    "    tuplesMx5 = np.column_stack((train, next_actions[:,5]))\n",
    "    tuplesMx6 = np.column_stack((train, next_actions[:,6]))\n",
    "    tuplesMx7 = np.column_stack((train, next_actions[:,7]))\n",
    "    tuplesMx8 = np.column_stack((train, next_actions[:,8]))\n",
    "    tuplesMx9 = np.column_stack((train, next_actions[:,9]))\n",
    "    tuplesMx10 = np.column_stack((train, next_actions[:,10]))\n",
    "    tuplesMx11 = np.column_stack((train, next_actions[:,11]))\n",
    "    \n",
    "    return tuplesMx0, tuplesMx1, tuplesMx2, tuplesMx3, tuplesMx4, tuplesMx5, tuplesMx6, tuplesMx7, tuplesMx8, tuplesMx9, tuplesMx10, tuplesMx11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['rew'], tuplesMx0, tuplesMx1, tuplesMx2, tuplesMx3, tuplesMx4, tuplesMx5, tuplesMx6, tuplesMx7, tuplesMx8, tuplesMx9, tuplesMx10, tuplesMx11  = tuple_()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression phase:\n",
    "\n",
    "Before performing the prediction task .. let's split the data to training and validation sets .. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid any problems in prediction by having string variables .. let's binarize (catergorize) all the variables .. \n",
    "\n",
    "Guidance ==> https://pythonprogramming.net/rnn-tensorflow-python-machine-learning-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Deep Neural Network (DQN):\n",
    "\n",
    "https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/blob/master/contents/5_Deep_Q_Network/RL_brain.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training:\n",
    "\n",
    "1. https://stackoverflow.com/questions/46832151/tensorflow-neural-network-multi-layer-perceptron-for-regression-example\n",
    "2. \n",
    "https://medium.com/mlreview/a-simple-deep-learning-model-for-stock-price-prediction-using-tensorflow-30505541d877\n",
    "\n",
    "Guidance: https://www.youtube.com/watch?v=FbJw8J0rTyQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN_train(x_inputs, y_outputs):\n",
    "\n",
    "#     print np.shape(y_outputs)\n",
    "    \n",
    "    # Placeholder\n",
    "    X = tf.placeholder(dtype=tf.float32, shape=[None, np.shape(x_inputs)[1] ])\n",
    "    Y = tf.placeholder(dtype=tf.float32, shape=[None])\n",
    "\n",
    "\n",
    "    # Model architecture parameters\n",
    "    n_dim = np.shape(x_inputs)[1] \n",
    "    n_neurons_1 = 40\n",
    "    n_neurons_2 = 15\n",
    "    n_target = 1 #np.shape(x_inputs)[0]\n",
    "    \n",
    "    batch_size = 500 \n",
    "    epochs = 100\n",
    "    \n",
    "    predicted_output = []\n",
    "    \n",
    "        # Initializers\n",
    "    sigma = 1\n",
    "#     weight_initializer = tf.variance_scaling_initializer(mode=\"fan_avg\", distribution=\"uniform\", scale=sigma)\n",
    "#     bias_initializer = tf.zeros_initializer()\n",
    "    \n",
    "\n",
    "#     # Layer 1: Variables for hidden weights and biases\n",
    "#     W_hidden_1 = tf.Variable(weight_initializer([n_dim, n_neurons_1]))\n",
    "#     bias_hidden_1 = tf.Variable(bias_initializer([n_neurons_1]))\n",
    "\n",
    "#     # Layer 2: Variables for hidden weights and biases\n",
    "#     W_hidden_2 = tf.Variable(weight_initializer([n_neurons_1, n_neurons_2]))\n",
    "#     bias_hidden_2 = tf.Variable(bias_initializer([n_neurons_2]))\n",
    "\n",
    "#     # Output layer: Variables for output weights and biases\n",
    "#     W_out = tf.Variable(weight_initializer([n_neurons_2, n_target]))\n",
    "#     bias_out = tf.Variable(bias_initializer([n_target]))\n",
    "\n",
    "\n",
    "#     # Hidden layer\n",
    "#     hidden_1 = tf.nn.relu(tf.add(tf.matmul(X, W_hidden_1), bias_hidden_1))\n",
    "#     hidden_2 = tf.nn.relu(tf.add(tf.matmul(hidden_1, W_hidden_2), bias_hidden_2))\n",
    "\n",
    "#     # Output layer (must be transposed)\n",
    "#     y_ = tf.add(tf.matmul(hidden_2, W_out), bias_out)\n",
    "    \n",
    "    \n",
    "    #First Q Network\n",
    "    w1 = tf.Variable(tf.random_uniform([n_dim, n_neurons_1], 0, 0.1))\n",
    "    bias1 = tf.Variable(tf.random_uniform([n_neurons_1], 0, 0.1))\n",
    "    \n",
    "    w2 = tf.Variable(tf.random_uniform([n_neurons_1, n_neurons_2], 0, 0.1))\n",
    "    bias2 = tf.Variable(tf.random_uniform([n_neurons_2], 0, 0.1))\n",
    "    \n",
    "    w3 = tf.Variable(tf.random_uniform([n_neurons_2, n_target], 0, 0.1))\n",
    "    bias3 = tf.Variable(tf.random_uniform([n_target], 0, 0.1))\n",
    "    \n",
    "    \n",
    "    hidden_1 = tf.nn.relu(tf.matmul(X, w1) + bias1)\n",
    "    hidden_2 = tf.nn.relu(tf.matmul(hidden_1, w2) + bias2)\n",
    "    y_ = tf.matmul(hidden_2, w3) + bias3\n",
    "    \n",
    "    # initialize variables\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    # Cost function\n",
    "    mse = tf.reduce_mean(tf.squared_difference(y_, Y))\n",
    "\n",
    "    # Optimizer\n",
    "    opt = tf.train.RMSPropOptimizer(0.0001, 0.99).minimize(mse)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        num_itr = int(np.shape(y_outputs)[0] / batch_size)\n",
    "        \n",
    "#         for epoch in range(epochs):\n",
    "#             for i in range(num_itr):\n",
    "        predicted_output = sess.run(y_, feed_dict={X: x_inputs, Y: y_outputs})\n",
    "#     print predicted_output\n",
    "#         print np.shape(predicted_output)       \n",
    "#         _, c = sess.run([opt, mse], feed_dict={X: x_inputs, Y: y_outputs})\n",
    "#         print predicted_output\n",
    "    return predicted_output.astype(int) #[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q(s,a) representing the (Quality) of action a at state is .. \n",
    "\n",
    "this Q value depends on the immediate reward r .. however, it'll be more effective if it takes the future rewards Q(s', a') into consideration .. \n",
    "\n",
    "the future rewards are discounted by probability gama .. cause the evironment is stochastic hence, it is uncertain that each time you select action a you gonna get the same reward r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_learning():\n",
    "    \n",
    "    avg_Q = []  \n",
    "    gamma = 0.9\n",
    "#     actions = actions_prep(df)\n",
    "\n",
    "# nepisode > https://stats.stackexchange.com/questions/250943/what-is-the-difference-between-episode-and-epoch-in-deep-q-learning\n",
    "# means one complete path from state, action, next_s, next_a, reward upuntil terminal state\n",
    "\n",
    "    nepisod = 10 #2 #np.shape(actions)[1]  ##22+ \n",
    "    explore = 0.4\n",
    "    sample_size = 100000\n",
    "    \n",
    "    train, _ = df_split()\n",
    "    \n",
    "    train = train.sample(sample_size) \n",
    "    \n",
    "    tuplesMx0, tuplesMx1, tuplesMx2, tuplesMx3, tuplesMx4, tuplesMx5, tuplesMx6, tuplesMx7, tuplesMx8, tuplesMx9, tuplesMx10, tuplesMx11 = tuple_(train)   \n",
    "    \n",
    "    num_rows = np.shape(tuplesMx0)[0] #-1\n",
    "    \n",
    "    Q_predicted = np.zeros([num_rows, 13]) #num_rows, num_columns\n",
    "    \n",
    "    best_action = np.zeros([num_rows, 1])\n",
    "#     Q_optimal = np.zeros([nepisod, num_rows])\n",
    "    \n",
    "    for i in xrange(nepisod):\n",
    "        Q_optimal = train['rew'].astype(np.float32) + gamma*Q_predicted.max(axis=1) #np.max(Q_predicted) # returns max value per row !\n",
    "        \n",
    "        Q_predicted0 = DQN_train(tuplesMx0, Q_optimal)\n",
    "        Q_predicted1 = DQN_train(tuplesMx1, Q_optimal)\n",
    "        Q_predicted2 = DQN_train(tuplesMx2, Q_optimal)\n",
    "        Q_predicted3 = DQN_train(tuplesMx3, Q_optimal)\n",
    "        Q_predicted4 = DQN_train(tuplesMx4, Q_optimal)\n",
    "        Q_predicted5 = DQN_train(tuplesMx5, Q_optimal)\n",
    "        Q_predicted6 = DQN_train(tuplesMx6, Q_optimal)\n",
    "        Q_predicted7 = DQN_train(tuplesMx7, Q_optimal)\n",
    "        Q_predicted8 = DQN_train(tuplesMx8, Q_optimal)\n",
    "        Q_predicted9 = DQN_train(tuplesMx9, Q_optimal)\n",
    "        Q_predicted10 = DQN_train(tuplesMx10, Q_optimal)\n",
    "        Q_predicted11 = DQN_train(tuplesMx11, Q_optimal)\n",
    "        Q_predicted = np.column_stack((Q_predicted0, Q_predicted1, Q_predicted2, Q_predicted3,\n",
    "                                          Q_predicted4, Q_predicted5, Q_predicted6, Q_predicted7,\n",
    "                                          Q_predicted8, Q_predicted9, Q_predicted10, Q_predicted11))\n",
    "    \n",
    "#     for i in Q_optimal:\n",
    "#         if i == 0.0:\n",
    "#             i = rewards_.astype(np.float32)\n",
    "            \n",
    "    best_action = np.argmax(Q_predicted, axis=1) \n",
    "        \n",
    "    return best_action, Q_optimal, train['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_action, Q_optimal, train_a = Q_learning()\n",
    "# best_action, Q_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.073152763082394"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## writing best action on file to use it again in (top berforming action) notebook\n",
    "\n",
    "# Q_optimal[Q_optimal.nonzero()].mean()\n",
    "np.mean(Q_optimal)  ## mmm 6yeb now el avg +ve bas very small + el Q_optimal has -ve values !\n",
    "\n",
    "## discrete only .. 9.2611671999797824\n",
    "## Continous + discrete .. 8.9385375000014289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "# writer = pd.ExcelWriter('test.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# # Convert the dataframe to an XlsxWriter Excel object.\n",
    "# Q_optimal.to_excel(writer, sheet_name='Sheet1')\n",
    "\n",
    "# # Close the Pandas Excel writer and output the Excel file.\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing best_actions by train['a']:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.19200000000001"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0 \n",
    "for i in xrange(np.shape(best_action)[0]):\n",
    "    if best_action[i] == train['a'].values[i]:\n",
    "        counter = counter + 1\n",
    "        \n",
    "counter, np.shape(best_action)[0]\n",
    "(1 - 9808./100000)*100\n",
    "# \"%.4f\" % (counter/np.shape(best_action)[0])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,)\n",
      "Freq.\n",
      "[[    0     3]\n",
      " [    7     9]\n",
      " [    4   742]\n",
      " [    3  3603]\n",
      " [    6  5362]\n",
      " [    9 90281]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(best_action, return_counts=True)\n",
    "\n",
    "print np.shape(unique)  # law el len b 4 yeb2a 5las .. law la2 .. yeb2a try to append 3la el vector\n",
    "\n",
    "print \"Freq.\"\n",
    "best_actions_list = np.asarray((unique, counts)).T\n",
    "print best_actions_list[np.argsort(best_actions_list[:, 1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proportion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion in %\n",
      "[3, '0.0029']\n",
      "[3603, '3.4329']\n",
      "[742, '0.7070']\n",
      "[5362, '5.1089']\n",
      "[9, '0.0086']\n",
      "[90281, '86.0196']\n"
     ]
    }
   ],
   "source": [
    "train, _ = df_split()\n",
    "\n",
    "print \"Proportion in %\"\n",
    "# print np.asarray((unique, counts/np.float(len(best_action)))) #.T\n",
    "for i in best_actions_list[:,1]:\n",
    "    print [i, \"%.4f\" % round((i/np.float(len(train))*100), 4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average by the client group:\n",
    "\n",
    "### 1. Avg. Frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(train['f0'].iloc[best_action == 2]) #avg freq of clients taken action 2 \n",
    "\n",
    "# el mafrood law run-et a repeat it 3la ba2e el actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_action = [1, 2, 3, 3, 3, 1, 1, 1, 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c1 = c2 = c3 = c4 = c5 = c6 = c7 = c8 = c9 = c10 = c11 = 0\n",
    "\n",
    "# for i in xrange(np.shape(best_action)[0]):\n",
    "#     if best_action [i] == 1:\n",
    "#         c1 = c1 + train.iloc[[i]['f0']]\n",
    "# #     elif best_action[i] == 3:\n",
    "# #         f3.append(train['f0'].iloc[i])\n",
    "# #     elif best_action[i] == 4:\n",
    "# #         f4.append(train['f0'].iloc[i])\n",
    "# #     elif best_action[i] == 5:\n",
    "# #         f5.append(train['f0'].iloc[i])\n",
    "# #     elif best_action[i] == 6:\n",
    "# #         f6.append(train['f0'].iloc[i])\n",
    "# #     elif best_action[i] == 7:\n",
    "# #         f7.append(train['f0'].iloc[i])\n",
    "# #     elif best_action[i] == 8:\n",
    "# #         f8.append(train['f0'].iloc[i])\n",
    "# #     elif best_action[i] == 9:\n",
    "# #         f9.append(train['f0'].iloc[i])\n",
    "# #     elif best_action[i] == 10:\n",
    "# #         f10.append(train['f0'].iloc[i])\n",
    "# #     elif best_action[i] == 11:\n",
    "# #         f11.append(train['f0'].iloc[i])\n",
    "# c2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Avg. Recency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avg. Monetary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation: \n",
    "\n",
    "### Policy 2: DQN model trained on the discrete action space\n",
    "\n",
    "1. Avg reponse probability and avg donnation amount (before the model) ==> BaseCase\n",
    "2. Avg reponse probability and avg donnation amount (for the model) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.81269513682\n",
      "9.03041831258\n"
     ]
    }
   ],
   "source": [
    "## basecase avg donnation amount:\n",
    "print np.mean(train['rew'])\n",
    "\n",
    "## avg donnation for the model\n",
    "print np.mean(Q_optimal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment:\n",
    "Increasing batch size .. increases the output non zero values \n",
    "\n",
    "## Further modifications:\n",
    "Roger also implemented the below code that simulates the whole customer's donnation process .. instead of applying DQN .. \n",
    "\n",
    "https://github.com/sisl/CustomerSim/blob/master/simulate_vs.py\n",
    "\n",
    "As well as these guys .. \n",
    "\n",
    "https://github.com/ugo-nama-kun/DQN-chainer/blob/master/dqn_agent_nature.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-157-d38199d8cdce>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-157-d38199d8cdce>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ya3ni now el steps are done as follows:\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "ya3ni now el steps are done as follows:\n",
    "1. predict next states using LSTM (error in dims)\n",
    "2. predict long term reward using DQN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
