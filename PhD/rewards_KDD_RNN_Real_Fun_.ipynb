{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "Main Goals:\n",
    "\n",
    "1. Identify the recipients that will engage with the campaign.\n",
    "2. Maximise the campaignâ€™s revenue.\n",
    "\n",
    "\n",
    "Comments\n",
    "\n",
    "- The dataset contains only 5% of donors.\n",
    "- The donations are usually smaller than $20.\n",
    "- This data is quite noisy, high dimensional.\n",
    "- There is an inverse relationship between the probability to donate and the amount donated.\n",
    "\n",
    "\n",
    "Link for dataset and some analysis ==> \n",
    "\n",
    "https://github.com/rebordao/kdd98cup\n",
    "\n",
    "https://github.com/bobbyantonio/KDD98/blob/master/CleanData.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eman\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "# from sknn.mlp import Regressor, Layer\n",
    "import pandas as pd\n",
    "\n",
    "## RNN\n",
    "from tensorflow.contrib import rnn \n",
    "from keras.models import Sequential\n",
    "from keras.layers import recurrent\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "\n",
    "## plotting .. \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "## warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    return pd.read_csv('tuple.csv', header = 0, nrows = 25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r0</th>\n",
       "      <th>f0</th>\n",
       "      <th>m0</th>\n",
       "      <th>ir0</th>\n",
       "      <th>if0</th>\n",
       "      <th>a</th>\n",
       "      <th>r1</th>\n",
       "      <th>f1</th>\n",
       "      <th>m1</th>\n",
       "      <th>ir1</th>\n",
       "      <th>if1</th>\n",
       "      <th>rew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   r0  f0  m0  ir0  if0  a  r1  f1   m1  ir1  if1  rew\n",
       "0   0   0   0    0    0  5   0   1  9.0    0    1  9.0\n",
       "1   0   0   0    0    0  5   1   0  0.0    0    1  0.0\n",
       "2   0   0   0    0    0  5   0   1  6.0    0    1  6.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## I have to run it over all the data not just 100 records\n",
    "df = load_data()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_split():\n",
    "    \n",
    "    df = load_data()\n",
    "    \n",
    "    train, test = train_test_split(df, test_size = 0.30)  # split data to 50-50 cross validate, Roger 1.6*1000,000\n",
    "    \n",
    "    train_x = train[train.columns.difference(['a', 'r0', 'f0', 'm0', 'ir0', 'if0'])]\n",
    "    train_y = train[train.columns.difference(['rew', 'a', 'r0', 'f0', 'm0', 'ir0', 'if0'])]\n",
    "    \n",
    "    test_x = test[test.columns.difference(['a', 'r0', 'f0', 'm0', 'ir0', 'if0'])]\n",
    "    test_y = test[test.columns.difference(['rew', 'a', 'r0', 'f0', 'm0', 'ir0', 'if0'])]\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x, train_y, test_x, test_y = df_split()\n",
    "# np.shape(train_x), np.shape(train_y), np.shape(test_x), np.shape(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_(predicted_states):\n",
    "        \n",
    "    next_actions = np.zeros([len(predicted_states), 12])\n",
    "    \n",
    "    for i in range(11):\n",
    "        next_actions[:, i] = i\n",
    "\n",
    "    tuplesMx0 = np.column_stack((predicted_states, next_actions[:,0]))\n",
    "    tuplesMx1 = np.column_stack((predicted_states, next_actions[:,1]))\n",
    "    tuplesMx2 = np.column_stack((predicted_states, next_actions[:,2]))\n",
    "    tuplesMx3 = np.column_stack((predicted_states, next_actions[:,3]))\n",
    "    tuplesMx4 = np.column_stack((predicted_states, next_actions[:,4]))\n",
    "    tuplesMx5 = np.column_stack((predicted_states, next_actions[:,5]))\n",
    "    tuplesMx6 = np.column_stack((predicted_states, next_actions[:,6]))\n",
    "    tuplesMx7 = np.column_stack((predicted_states, next_actions[:,7]))\n",
    "    tuplesMx8 = np.column_stack((predicted_states, next_actions[:,8]))\n",
    "    tuplesMx9 = np.column_stack((predicted_states, next_actions[:,9]))\n",
    "    tuplesMx10 = np.column_stack((predicted_states, next_actions[:,10]))\n",
    "    tuplesMx11 = np.column_stack((predicted_states, next_actions[:,11]))\n",
    "    \n",
    "    return tuplesMx0, tuplesMx1, tuplesMx2, tuplesMx3, tuplesMx4, tuplesMx5, tuplesMx6, tuplesMx7, tuplesMx8, tuplesMx9, tuplesMx10, tuplesMx11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression phase:\n",
    "\n",
    "Before performing the prediction task .. let's split the data to training and validation sets .. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid any problems in prediction by having string variables .. let's binarize (catergorize) all the variables .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9\n",
    "Num_itrs = 2  # no loop 3leha ( w dah el sa7) .. we just have to run the whole algo. 10 times and report the avg. results\n",
    "\n",
    "num_epoch = 1 #23 #epochs are cycles of Feedforward and Backprob\n",
    "batch_size = 100\n",
    "chunkSize = 100\n",
    "\n",
    "train_x, train_y, test_x, test_y = df_split()\n",
    "\n",
    "n_nodes_hl1 = 40 #np.shape(train)[1]\n",
    "n_nodes_hl2 = 15 #np.shape(train)[0]\n",
    "# NUM_STATES = np.shape(train)[1]\n",
    "NUM_DIM =  np.shape(train_x)[1]\n",
    "num_nodes = np.shape(train_x)[0]\n",
    "NUM_DIM_output = np.shape(train_y)[1]\n",
    "\n",
    "num_unrollings = 5\n",
    "\n",
    "best_actions = np.zeros([np.shape(train_x)[0], batch_size])\n",
    "Q_optimal = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_137:0' shape=(17500, 5) dtype=float32>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for training \n",
    "x = tf.placeholder(\"float\", [np.shape(train_x)[0], None, np.shape(train_x)[1]]) \n",
    "y = tf.placeholder(\"float\", [np.shape(train_y)[0], np.shape(train_y)[1]])  \n",
    "\n",
    "\n",
    "## for testing\n",
    "x_ = tf.placeholder(\"float\", [np.shape(test_x)[0], None, np.shape(test_x)[1]]) \n",
    "y_ = tf.placeholder(\"float\", [np.shape(test_y)[0], np.shape(test_y)[1]])  \n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/tensorflow/tensorflow/issues/9699\n",
    "def lstm_model(train_x, train_y, test_x, test_y):\n",
    "    hidden_dim = 50\n",
    "    time_step_size = 5\n",
    "    lstm_size = 480\n",
    "    rolling = train_x.values.shape[1]\n",
    "    output_count = 5\n",
    "    RNN = recurrent.SimpleRNN\n",
    "    \n",
    "    with tf.variable_scope(\"RNN\", reuse = True):\n",
    "    \n",
    "        train_x = np.reshape(train_x.values, (train_x.shape[0], 1, train_x.shape[1]))\n",
    "        test_x = np.reshape(test_x.values, (test_x.shape[0], 1, test_x.shape[1]))\n",
    "        \n",
    "#         ## model compilation \n",
    "        model = Sequential()\n",
    "        model.add(RNN(hidden_dim,  input_dim = rolling))\n",
    "        model.add(Dense(output_count))\n",
    "\n",
    "        model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "        \n",
    "        ## model running\n",
    "        model.fit(train_x, train_y, batch_size = batch_size, \n",
    "          nb_epoch = num_epoch, verbose = 0,\n",
    "        validation_data = (test_x, test_y))\n",
    "        \n",
    "        train_predict = model.predict(train_x.astype(int))\n",
    "        test_predict = model.predict(test_x.astype(int))\n",
    "        \n",
    "        return train_predict.astype(int) ## predicted_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predict = lstm_model(train_x, train_y, test_x, test_y)\n",
    "train_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning the rewards:\n",
    "Now, the LSTM_RNN output (from validation phase) is considered as input for DQN model, to be able to select the action that has the maximum longtime reward for the customer (highest CLV) .. \n",
    "\n",
    "https://arxiv.org/pdf/1602.01580.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Deep Neural Network (DQN):\n",
    "\n",
    "https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/blob/master/contents/5_Deep_Q_Network/RL_brain.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN_train(x_inputs, y_outputs):\n",
    "\n",
    "#     print np.shape(y_outputs)\n",
    "    \n",
    "    # Placeholder\n",
    "    X = tf.placeholder(dtype=tf.float32, shape=[None, np.shape(x_inputs)[1] ])\n",
    "    Y = tf.placeholder(dtype=tf.float32, shape=[None])\n",
    "\n",
    "\n",
    "    # Model architecture parameters\n",
    "    n_dim = np.shape(x_inputs)[1] \n",
    "    n_neurons_1 = 40\n",
    "    n_neurons_2 = 15\n",
    "    n_target = 1 #np.shape(x_inputs)[0]\n",
    "    \n",
    "    batch_size = 500 \n",
    "    epochs = 100\n",
    "    \n",
    "    predicted_output = []\n",
    "    \n",
    "        # Initializers\n",
    "    sigma = 1\n",
    "    \n",
    "    #First Q Network\n",
    "    w1 = tf.Variable(tf.random_uniform([n_dim, n_neurons_1], 0, 0.1))\n",
    "    bias1 = tf.Variable(tf.random_uniform([n_neurons_1], 0, 0.1))\n",
    "    \n",
    "    w2 = tf.Variable(tf.random_uniform([n_neurons_1, n_neurons_2], 0, 0.1))\n",
    "    bias2 = tf.Variable(tf.random_uniform([n_neurons_2], 0, 0.1))\n",
    "    \n",
    "    w3 = tf.Variable(tf.random_uniform([n_neurons_2, n_target], 0, 0.1))\n",
    "    bias3 = tf.Variable(tf.random_uniform([n_target], 0, 0.1))\n",
    "    \n",
    "    \n",
    "    hidden_1 = tf.nn.relu(tf.matmul(X, w1) + bias1)\n",
    "    hidden_2 = tf.nn.relu(tf.matmul(hidden_1, w2) + bias2)\n",
    "    y_ = tf.matmul(hidden_2, w3) + bias3\n",
    "    \n",
    "    # initialize variables\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    # Cost function\n",
    "    mse = tf.reduce_mean(tf.squared_difference(y_, Y))\n",
    "\n",
    "    # Optimizer\n",
    "    opt = tf.train.RMSPropOptimizer(0.0001, 0.99).minimize(mse)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        num_itr = int(np.shape(y_outputs)[0] / batch_size)\n",
    "        \n",
    "#         for epoch in range(epochs):\n",
    "#             for i in range(num_itr):\n",
    "        predicted_output = sess.run(y_, feed_dict={X: x_inputs, Y: y_outputs})\n",
    "#     print predicted_output\n",
    "#         print np.shape(predicted_output)       \n",
    "#         _, c = sess.run([opt, mse], feed_dict={X: x_inputs, Y: y_outputs})\n",
    "#         print predicted_output\n",
    "    return predicted_output.astype(int) #[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_learning():\n",
    "    \n",
    "    avg_Q = []  \n",
    "    gamma = 0.9\n",
    "#     actions = actions_prep(df)\n",
    "\n",
    "# nepisode > https://stats.stackexchange.com/questions/250943/what-is-the-difference-between-episode-and-epoch-in-deep-q-learning\n",
    "# means one complete path from state, action, next_s, next_a, reward upuntil terminal state\n",
    "\n",
    "    nepisod = 30 #2 #np.shape(actions)[1]  ##22+ \n",
    "    \n",
    "    predicted_states = lstm_model(train_x, train_y, test_x, test_y)\n",
    "\n",
    "    \n",
    "    tuplesMx0, tuplesMx1, tuplesMx2, tuplesMx3, tuplesMx4, tuplesMx5, tuplesMx6, tuplesMx7, tuplesMx8, tuplesMx9, tuplesMx10, tuplesMx11 = tuple_(predicted_states) \n",
    "    \n",
    "    num_rows = np.shape(tuplesMx0)[0] #-1\n",
    "    \n",
    "    Q_predicted = np.zeros([num_rows, 12]) #num_rows, num_columns\n",
    "    \n",
    "    best_action = np.zeros([num_rows, 1])\n",
    "#     Q_optimal = np.zeros([nepisod, num_rows])\n",
    "    \n",
    "    for i in range(nepisod):\n",
    "        Q_optimal = train_x['rew'].values.astype(np.float32) + gamma*Q_predicted.max(axis=1) #np.max(Q_predicted) # returns max value per row !\n",
    "        Q_predicted0 = DQN_train(tuplesMx0, Q_optimal)\n",
    "        Q_predicted1 = DQN_train(tuplesMx1, Q_optimal)\n",
    "        Q_predicted2 = DQN_train(tuplesMx2, Q_optimal)\n",
    "        Q_predicted3 = DQN_train(tuplesMx3, Q_optimal)\n",
    "        Q_predicted4 = DQN_train(tuplesMx4, Q_optimal)\n",
    "        Q_predicted5 = DQN_train(tuplesMx5, Q_optimal)\n",
    "        Q_predicted6 = DQN_train(tuplesMx6, Q_optimal)\n",
    "        Q_predicted7 = DQN_train(tuplesMx7, Q_optimal)\n",
    "        Q_predicted8 = DQN_train(tuplesMx8, Q_optimal)\n",
    "        Q_predicted9 = DQN_train(tuplesMx9, Q_optimal)\n",
    "        Q_predicted10 = DQN_train(tuplesMx10, Q_optimal)\n",
    "        Q_predicted11 = DQN_train(tuplesMx11, Q_optimal)\n",
    "        Q_predicted = np.column_stack((Q_predicted0, Q_predicted1, Q_predicted2, Q_predicted3,\n",
    "                                          Q_predicted4, Q_predicted5, Q_predicted6, Q_predicted7,\n",
    "                                          Q_predicted8, Q_predicted9, Q_predicted10, Q_predicted11))\n",
    "\n",
    "            \n",
    "    best_action = np.argmax(Q_predicted, axis = 1) \n",
    "         \n",
    "    return best_action, Q_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_action, Q_optimal = Q_learning()\n",
    "best_action, Q_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(Q_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('test.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "pd.DataFrame(Q_optimal).to_excel(writer, sheet_name='Sheet1')\n",
    "pd.DataFrame(best_action).to_excel(writer, sheet_name='Sheet2')\n",
    "\n",
    "# # Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhancements:\n",
    "\n",
    "1. We can use RELU activation function to generate better results in RNN case \n",
    "\n",
    "Ref: http://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/\n",
    "\n",
    "2. DDQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
