{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "Main Goals:\n",
    "\n",
    "1. Identify the recipients that will engage with the campaign.\n",
    "2. Maximise the campaign’s revenue.\n",
    "\n",
    "\n",
    "Comments\n",
    "\n",
    "- The dataset contains only 5% of donors.\n",
    "- The donations are usually smaller than $20.\n",
    "- This data is quite noisy, high dimensional.\n",
    "- There is an inverse relationship between the probability to donate and the amount donated.\n",
    "\n",
    "\n",
    "Link for dataset and some analysis ==> \n",
    "\n",
    "https://github.com/rebordao/kdd98cup\n",
    "\n",
    "https://github.com/bobbyantonio/KDD98/blob/master/CleanData.py\n",
    "\n",
    "- Github solutions ==>\n",
    "https://github.com/rebordao/kdd98cup\n",
    "\n",
    "\n",
    "- Siraj notebook for a better data visualization:\n",
    "\n",
    "https://www.youtube.com/watch?v=yQsOFWqpjkE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "from sklearn.model_selection import train_test_split\n",
    "from array_split import array_split, shape_split\n",
    "from sklearn import preprocessing\n",
    "# from sknn.mlp import Regressor, Layer\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "## plotting .. \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "## warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    list_of_lists = []\n",
    "\n",
    "    ## works correctly but takes too much running time ..\n",
    "    with open('cup98LRN.txt', 'r') as f:# open the file for reading\n",
    "        df = []\n",
    "        for row_num, line in enumerate(f):\n",
    "            # Remove the new line at the end and then split the string based on\n",
    "            # tabs. This creates a python list of the values.\n",
    "            values = line.strip().split(',')\n",
    "            if row_num == 0: # first line is the header\n",
    "                 header = values\n",
    "            else:\n",
    "                df.append([v for v in values])\n",
    "\n",
    "        df = pd.DataFrame(df)\n",
    "        df.columns = header\n",
    "        df.drop(df.index[0], inplace=True)\n",
    "        \n",
    "        df = df[0:50]  ## to save time .. I gonna work on only 100 records ..\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I have to run it over all the data not just 100 records\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(df['ADATE_3']) # 3 empty cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9602'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ADATE_7'].values.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only ADATE is valid .. \n",
    "\n",
    "RFA ==> only 3 characters not 4\n",
    "\n",
    "RAMNT_3, RDATE ==> are empty !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADATE_2</th>\n",
       "      <th>ADATE_3</th>\n",
       "      <th>ADATE_4</th>\n",
       "      <th>ADATE_5</th>\n",
       "      <th>ADATE_6</th>\n",
       "      <th>ADATE_7</th>\n",
       "      <th>ADATE_8</th>\n",
       "      <th>ADATE_9</th>\n",
       "      <th>ADATE_10</th>\n",
       "      <th>ADATE_11</th>\n",
       "      <th>...</th>\n",
       "      <th>ADATE_16</th>\n",
       "      <th>ADATE_16</th>\n",
       "      <th>ADATE_17</th>\n",
       "      <th>ADATE_18</th>\n",
       "      <th>ADATE_19</th>\n",
       "      <th>ADATE_20</th>\n",
       "      <th>ADATE_12</th>\n",
       "      <th>ADATE_22</th>\n",
       "      <th>ADATE_23</th>\n",
       "      <th>ADATE_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9706</td>\n",
       "      <td>9606</td>\n",
       "      <td>9604</td>\n",
       "      <td>9604</td>\n",
       "      <td>9603</td>\n",
       "      <td>9602</td>\n",
       "      <td>9601</td>\n",
       "      <td>9511</td>\n",
       "      <td>9510</td>\n",
       "      <td>9510</td>\n",
       "      <td>...</td>\n",
       "      <td>9503</td>\n",
       "      <td>9503</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9411</td>\n",
       "      <td>9411</td>\n",
       "      <td>9509</td>\n",
       "      <td>9409</td>\n",
       "      <td></td>\n",
       "      <td>9406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9706</td>\n",
       "      <td>9606</td>\n",
       "      <td>9604</td>\n",
       "      <td>9604</td>\n",
       "      <td>9603</td>\n",
       "      <td>9602</td>\n",
       "      <td>9601</td>\n",
       "      <td>9511</td>\n",
       "      <td></td>\n",
       "      <td>9510</td>\n",
       "      <td>...</td>\n",
       "      <td>9503</td>\n",
       "      <td>9503</td>\n",
       "      <td></td>\n",
       "      <td>9501</td>\n",
       "      <td>9411</td>\n",
       "      <td></td>\n",
       "      <td>9508</td>\n",
       "      <td>9409</td>\n",
       "      <td>9407</td>\n",
       "      <td>9406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9706</td>\n",
       "      <td>9606</td>\n",
       "      <td>9604</td>\n",
       "      <td>9604</td>\n",
       "      <td>9603</td>\n",
       "      <td>9602</td>\n",
       "      <td>9601</td>\n",
       "      <td>9511</td>\n",
       "      <td></td>\n",
       "      <td>9510</td>\n",
       "      <td>...</td>\n",
       "      <td>9503</td>\n",
       "      <td>9503</td>\n",
       "      <td>9502</td>\n",
       "      <td>9501</td>\n",
       "      <td>9411</td>\n",
       "      <td>9411</td>\n",
       "      <td>9508</td>\n",
       "      <td>9409</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9706</td>\n",
       "      <td>9606</td>\n",
       "      <td>9604</td>\n",
       "      <td>9604</td>\n",
       "      <td>9603</td>\n",
       "      <td>9512</td>\n",
       "      <td>9601</td>\n",
       "      <td>9511</td>\n",
       "      <td>9510</td>\n",
       "      <td>9509</td>\n",
       "      <td>...</td>\n",
       "      <td>9503</td>\n",
       "      <td>9503</td>\n",
       "      <td>9502</td>\n",
       "      <td>9412</td>\n",
       "      <td>9411</td>\n",
       "      <td>9411</td>\n",
       "      <td>9508</td>\n",
       "      <td>9506</td>\n",
       "      <td>9407</td>\n",
       "      <td>9406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9706</td>\n",
       "      <td>9606</td>\n",
       "      <td>9604</td>\n",
       "      <td>9604</td>\n",
       "      <td>9603</td>\n",
       "      <td>9602</td>\n",
       "      <td>9601</td>\n",
       "      <td>9511</td>\n",
       "      <td>9510</td>\n",
       "      <td>9510</td>\n",
       "      <td>...</td>\n",
       "      <td>9503</td>\n",
       "      <td>9503</td>\n",
       "      <td>9502</td>\n",
       "      <td>9501</td>\n",
       "      <td>9411</td>\n",
       "      <td>9411</td>\n",
       "      <td>9509</td>\n",
       "      <td>9409</td>\n",
       "      <td></td>\n",
       "      <td>9406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ADATE_2 ADATE_3 ADATE_4 ADATE_5 ADATE_6 ADATE_7 ADATE_8 ADATE_9 ADATE_10  \\\n",
       "1    9706    9606    9604    9604    9603    9602    9601    9511     9510   \n",
       "2    9706    9606    9604    9604    9603    9602    9601    9511            \n",
       "3    9706    9606    9604    9604    9603    9602    9601    9511            \n",
       "4    9706    9606    9604    9604    9603    9512    9601    9511     9510   \n",
       "5    9706    9606    9604    9604    9603    9602    9601    9511     9510   \n",
       "\n",
       "  ADATE_11   ...    ADATE_16 ADATE_16 ADATE_17 ADATE_18 ADATE_19 ADATE_20  \\\n",
       "1     9510   ...        9503     9503                       9411     9411   \n",
       "2     9510   ...        9503     9503              9501     9411            \n",
       "3     9510   ...        9503     9503     9502     9501     9411     9411   \n",
       "4     9509   ...        9503     9503     9502     9412     9411     9411   \n",
       "5     9510   ...        9503     9503     9502     9501     9411     9411   \n",
       "\n",
       "  ADATE_12 ADATE_22 ADATE_23 ADATE_24  \n",
       "1     9509     9409              9406  \n",
       "2     9508     9409     9407     9406  \n",
       "3     9508     9409                    \n",
       "4     9508     9506     9407     9406  \n",
       "5     9509     9409              9406  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_data = ['ADATE_2', 'ADATE_3', 'ADATE_4', 'ADATE_5', 'ADATE_6', 'ADATE_7', 'ADATE_8', \n",
    "            'ADATE_9', 'ADATE_10', 'ADATE_11', 'ADATE_12', 'ADATE_13', 'ADATE_14', 'ADATE_15',\n",
    "            'ADATE_16', 'ADATE_16', 'ADATE_17', 'ADATE_18', 'ADATE_19', 'ADATE_20', 'ADATE_12',\n",
    "            'ADATE_22', 'ADATE_23', 'ADATE_24']\n",
    "df[date_data].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06</td>\n",
       "      <td>06</td>\n",
       "      <td>04</td>\n",
       "      <td>04</td>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>03</td>\n",
       "      <td>03</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>09</td>\n",
       "      <td>09</td>\n",
       "      <td></td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06</td>\n",
       "      <td>06</td>\n",
       "      <td>04</td>\n",
       "      <td>04</td>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>03</td>\n",
       "      <td>03</td>\n",
       "      <td></td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>08</td>\n",
       "      <td>09</td>\n",
       "      <td>07</td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06</td>\n",
       "      <td>06</td>\n",
       "      <td>04</td>\n",
       "      <td>04</td>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>03</td>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>08</td>\n",
       "      <td>09</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06</td>\n",
       "      <td>06</td>\n",
       "      <td>04</td>\n",
       "      <td>04</td>\n",
       "      <td>03</td>\n",
       "      <td>12</td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>09</td>\n",
       "      <td>...</td>\n",
       "      <td>03</td>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>08</td>\n",
       "      <td>06</td>\n",
       "      <td>07</td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06</td>\n",
       "      <td>06</td>\n",
       "      <td>04</td>\n",
       "      <td>04</td>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>03</td>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>09</td>\n",
       "      <td>09</td>\n",
       "      <td></td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9  ...  14  15  16  17  18  19  20  21  \\\n",
       "0  06  06  04  04  03  02  01  11  10  10 ...  03  03          11  11  09  09   \n",
       "1  06  06  04  04  03  02  01  11      10 ...  03  03      01  11      08  09   \n",
       "2  06  06  04  04  03  02  01  11      10 ...  03  03  02  01  11  11  08  09   \n",
       "3  06  06  04  04  03  12  01  11  10  09 ...  03  03  02  12  11  11  08  06   \n",
       "4  06  06  04  04  03  02  01  11  10  10 ...  03  03  02  01  11  11  09  09   \n",
       "\n",
       "   22  23  \n",
       "0      06  \n",
       "1  07  06  \n",
       "2          \n",
       "3  07  06  \n",
       "4      06  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = []\n",
    "temp = np.transpose(df[date_data])\n",
    "\n",
    "for j in xrange(len(temp)):\n",
    "    for i in xrange(np.shape(df)[0]):\n",
    "         t.append(temp.iloc[j].iloc[i][2:])\n",
    "\n",
    "np.shape(t) ## correct ! .. but make sure that the step size is 23 ! i.e. every 23 step .. corresponds to new ADATE \n",
    "actions = np.reshape(t, [24, 50])\n",
    "actions = pd.DataFrame(np.transpose(actions))\n",
    "actions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration:\n",
    "\n",
    "http://beyondvalence.blogspot.com.eg/2014/05/kdd-cup-profit-optimization-in-r-part-1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_explore():\n",
    "    df = load_data()\n",
    "    print df.TARGET_B.value_counts().plot(x=None, y=None, kind = 'pie', autopct='%1.1f%%')\n",
    "    \n",
    "    # % of donors\n",
    "    print 'Percentage of donors: %s' % (100.0 * sum(df.TARGET_B.astype('float'))/df.shape[0]) #about only 5% of the samples are doners .. \n",
    "    plt.hist(df.TARGET_D.value_counts(), bins = 7)   \n",
    "    plt.plot(df[df.TARGET_D > 0].TARGET_D) #Histogram is not the best choice .. let's try another plot .. \n",
    "    \n",
    "    # % of donors\n",
    "    print 'Percentage of donors: %s' % (100.0 * sum(df.TARGET_D.astype('float'))/df.shape[0])\n",
    "    #about 79% of the continous predictor are doners .. are there any donation amounts of zero ?!\n",
    "    print df.TARGET_D.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender data imputation ..\n",
    "It's very strange to have gender rather than M and F !! .. \n",
    "\n",
    "Let's impute any other value with the mode of this variable .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_impute():\n",
    "    df = load_data()\n",
    "    df['GENDER'] = np.where(df['GENDER'] == 'C', df['GENDER'].mode(), df['GENDER'])\n",
    "    df['GENDER'] = np.where(df['GENDER'] == 'U', df['GENDER'].mode(), df['GENDER'])\n",
    "    df['GENDER'] = np.where(df['GENDER'] == 'J', df['GENDER'].mode(), df['GENDER'])\n",
    "    df['GENDER'] = np.where(df['GENDER'] == 'A', df['GENDER'].mode(), df['GENDER'])\n",
    "    df['GENDER'] = np.where(df['GENDER'] == ' ', df['GENDER'].mode(), df['GENDER'])\n",
    "    \n",
    "#     print df['GENDER'].unique()\n",
    "    \n",
    "    ## how donations are distributed per gender\n",
    "    df['GENDER'].value_counts().plot(kind='barh', stacked=True, fontsize=7, figsize=[9,8], colormap='gist_ncar')\n",
    "    plt.title('donations are distributed among age groups', fontsize=14, color='black') \n",
    "    plt.xlabel('Number of doners', fontsize=14, color='black') \n",
    "    plt.ylabel('Gender of doner', fontsize=14, color='black') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing:\n",
    "\n",
    "1. Gets some redundant variables .. by calculating the correlation between all the variables .. \n",
    "those of high correlation coeffecient are redundant .. \n",
    "\n",
    "__NOTE:__\n",
    "In this implementation .. \n",
    "\n",
    "https://github.com/EAboelhamd/kdd98cup/blob/master/donors.py\n",
    "\n",
    "They tried to figure out redundant variables to remove them .. to be able to decrease the dimentionality of the problem .. however, in my case, there is no need to do .. as I'm gonna implement deep learning not a shallow solution .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preperation():\n",
    "    df = load_data()\n",
    "    df = df[df.columns.difference(['TARGET_B'])]\n",
    "    data = ['TARGET_D', 'ODATEDW','OSOURCE','TCODE','STATE','ZIP','MAILCODE','PVASTATE','DOB','NOEXCH','RECINHSE','RECP3','RECPGVG','RECSWEEP','MDMAUD','DOMAIN','CLUSTER','AGE','AGEFLAG','HOMEOWNR','CHILD03','CHILD07','CHILD12',\n",
    "      'CHILD18','NUMCHLD','INCOME','GENDER','WEALTH1','HIT','MBCRAFT','MBGARDEN','MBBOOKS','MBCOLECT','MAGFAML','MAGFEM','MAGMALE',\n",
    "      'PUBGARDN','PUBCULIN','PUBHLTH','PUBDOITY','PUBNEWFN','PUBPHOTO','PUBOPP','DATASRCE','MALEMILI','MALEVET','VIETVETS','WWIIVETS','LOCALGOV','STATEGOV','FEDGOV','SOLP3','SOLIH',\n",
    "      'MAJOR','WEALTH2','GEOCODE','COLLECT1','VETERANS','BIBLE','CATLG','HOMEE','PETS','CDPLAY','STEREO','PCOWNERS','PHOTO','CRAFTS','FISHER','GARDENIN','BOATS','WALKER','KIDSTUFF','CARDS','PLATES','LIFESRC','PEPSTRFL','POP901','POP902','POP903','POP90C1','POP90C2','POP90C3','POP90C4','POP90C5','ETH1','ETH2','ETH3','ETH4','ETH5','ETH6','ETH7','ETH8','ETH9','ETH10','ETH11','ETH12','ETH13',\n",
    "      'ETH14','ETH15','ETH16','AGE901','AGE902','AGE903','AGE904','AGE905','AGE906','AGE907','CHIL1','CHIL2','CHIL3','AGEC1','AGEC2','AGEC3','AGEC4','AGEC5','AGEC6','AGEC7','CHILC1','CHILC2','CHILC3','CHILC4','CHILC5','HHAGE1','HHAGE2','HHAGE3','HHN1','HHN2','HHN3','HHN4','HHN5','HHN6','MARR1','MARR2','MARR3','MARR4','HHP1','HHP2','DW1','DW2','DW3','DW4','DW5','DW6','DW7','DW8','DW9','HV1','HV2','HV3','HV4','HU1','HU2','HU3','HU4','HU5','HHD1',\n",
    "      'HHD2','HHD3','HHD4','HHD5','HHD6','HHD7','HHD8','HHD9','HHD10','HHD11','HHD12','ETHC1','ETHC2','ETHC3','ETHC4','ETHC5','ETHC6','HVP1','HVP2','HVP3','HVP4',\n",
    "      'HVP5','HVP6','HUR1','HUR2','RHP1','RHP2','RHP3','RHP4','HUPA1','HUPA2','HUPA3','HUPA4','HUPA5','HUPA6',\n",
    "      'HUPA7','RP1','RP2', 'RP3','RP4','MSA','ADI','DMA','IC1','IC2','IC3','IC4','IC5','IC6','IC7','IC8','IC9','IC10','IC11','IC12','IC13','IC14','IC15','IC16','IC17','IC18','IC19','IC20','IC21','IC22','IC23','HHAS1','HHAS2','HHAS3','HHAS4','MC1','MC2','MC3',\n",
    "      'TPE1','TPE2','TPE3','TPE4','TPE5','TPE6','TPE7','TPE8','TPE9','PEC1','PEC2','TPE10','TPE11','TPE12','TPE13','LFC1','LFC2','LFC3','LFC4','LFC5','LFC6','LFC7','LFC8','LFC9','LFC10','OCC1','OCC2','OCC3','OCC4','OCC5','OCC6','OCC7','OCC8','OCC9',\n",
    "      'OCC10','OCC11','OCC12','OCC13','EIC1','EIC2','EIC3','EIC4','EIC5','EIC6','EIC7','EIC8','EIC9','EIC10','EIC11','EIC12','EIC13','EIC14','EIC15',\n",
    "      'EIC16','OEDC1','OEDC2','OEDC3','OEDC4','OEDC5','OEDC6','OEDC7','EC1','EC2','EC3',\n",
    "      'EC4','EC5','EC6','EC7','EC8','SEC1','SEC2','SEC3','SEC4','SEC5','AFC1','AFC2','AFC3','AFC4','AFC5','AFC6','VC1','VC2','VC3','VC4','ANC1','ANC2','ANC3','ANC4','ANC5','ANC6','ANC7','ANC8','ANC9','ANC10','ANC11','ANC12','ANC13','ANC14','ANC15','POBC1','POBC2','LSC1','LSC2','LSC3','LSC4',\n",
    "      'VOC1','VOC2', 'VOC3','HC1','HC2','HC3', 'HC4','HC5','HC6','HC7','HC8','HC9','HC10','HC11','HC12','HC13','HC14','HC15','HC16',\n",
    "      'HC17','HC18','HC19','HC20','HC21','MHUC1','MHUC2','AC1','AC2','RFA_2','RFA_3','RFA_4','RFA_5','RFA_6','RFA_7','RFA_8','RFA_9','RFA_10','RFA_11','RFA_12','RFA_13','RFA_14','RFA_15','RFA_16','RFA_17','RFA_18','RFA_19','RFA_20','RFA_21','RFA_22','RFA_23','RFA_24','CARDPROM','MAXADATE','NUMPROM',\n",
    "      'CARDPM12', 'NUMPRM12','RDATE_3','RDATE_4','RDATE_5','RDATE_6','RDATE_7','RDATE_8','RDATE_9','RDATE_10','RDATE_11',\n",
    "      'RDATE_12','RDATE_13','RDATE_14','RDATE_15','RDATE_16','RDATE_17','RDATE_18','RDATE_19','RDATE_20','RDATE_21','RDATE_22','RDATE_23','RDATE_24','RAMNT_3', 'RAMNT_4','RAMNT_5','RAMNT_6', 'RAMNT_7','RAMNT_8','RAMNT_9', 'RAMNT_10',\n",
    "      'RAMNT_11','RAMNT_12','RAMNT_13','RAMNT_14','RAMNT_15','RAMNT_16','RAMNT_17','RAMNT_18','RAMNT_19','RAMNT_20','RAMNT_21',\n",
    "      'RAMNT_22','RAMNT_23','RAMNT_24','RAMNTALL','NGIFTALL','CARDGIFT','MINRAMNT','MINRDATE', 'MAXRAMNT','MAXRDATE','LASTGIFT','LASTDATE','FISTDATE','NEXTDATE','TIMELAG','AVGGIFT','CONTROLN', 'HPHONE_D','RFA_2R','RFA_2F','RFA_2A','MDMAUD_R','MDMAUD_F','MDMAUD_A','CLUSTER2','GEOCODE2']\n",
    "    \n",
    "    for i in xrange(len(data)):\n",
    "        df[data[i]] = pd.Categorical((pd.factorize(df[data[i]])[0] + 1).astype(str))\n",
    "    \n",
    "    return df[data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_split():  \n",
    "    df = data_preperation()\n",
    "    train, test = train_test_split(df, test_size = 0.5)  # split data to 50-50 cross validate \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df_split()\n",
    "rewards = ['TARGET_D']\n",
    "for i in xrange(len(rewards)):\n",
    "    train[rewards[i]] = pd.Categorical((pd.factorize(train[rewards[i]])[0] + 1).astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current State variables ..\n",
    "Recency, Frequancy, Montery variables .. ['RFA_2R', 'RFA_2F', 'RFA_2A']\n",
    "\n",
    "## Rewards:\n",
    "- Donation amount \n",
    "- These are the target variables as well .. \n",
    "- TARGET_D, TARGET_B \n",
    "\n",
    "\n",
    "## Actions: \n",
    "- 11 mailing type\n",
    "\n",
    "Actions mapping .. \n",
    "https://github.com/EAboelhamd/kdd98-1/tree/master/notebooks\n",
    "\n",
    "## Actions:\n",
    "\n",
    "- mailing types ..\n",
    "action_mapping = {\n",
    "\n",
    "                                    2: 'NK',  3: 'NK',\n",
    "                                    4: 'TK',  5: 'SK',\n",
    "                                    6: 'LL',  7: 'G1',\n",
    "                                    8: 'GK',  9: 'CC',\n",
    "                                    10: 'WL', 11: 'X1',\n",
    "                                    12: 'XK', 13: 'FS',\n",
    "                                    14: 'NK', 15: 'TK',\n",
    "                                    16: 'LL', 17: 'G1',\n",
    "                                    18: 'GK', 19: 'CC',\n",
    "                                    20: 'WL', 21: 'X1',\n",
    "                                    22: 'XK', 23: 'FS', 24: 'NK'\n",
    "                                }\n",
    "\n",
    "this list contains 11 unique values (NK, TK,LL,GK,WL,XK,SK,G1,CC,X1,FS)\n",
    "\n",
    "                                        NK ==> 2, 14, 23, 24\n",
    "                                        LL ==> 2, 16\n",
    "                                        TK ==> 4, 15\n",
    "                                        GK ==> 8, 18\n",
    "                                        WL ==> 10, 20\n",
    "                                        SK ==> 5\n",
    "                                        G1 ==> 7, 17\n",
    "                                        CC ==> 9, 19\n",
    "                                        X1 ==> 11, 21\n",
    "                                        FS ==> 13, 23\n",
    "\n",
    "Their corresponding meanings are:\n",
    "\n",
    "                                        LL mailings had labels only                                        \n",
    "                                        WL mailings had labels only\n",
    "                                        CC mailings are calendars with stickers but do\n",
    "                                           not have labels\n",
    "                                        FS mailings are blank cards that fold into\n",
    "                                           thirds with labels\n",
    "                                        NK mailings are blank cards with labels\n",
    "                                        SK mailings are blank cards with labels\n",
    "                                        TK mailings have thank you printed on the\n",
    "                                           outside with labels\n",
    "                                        GK mailings are general greeting cards (an\n",
    "                                           assortment of birthday, sympathy, blank, & get\n",
    "                                           well) with labels\n",
    "                                        XK mailings are Christmas cards with labels\n",
    "                                        X1 mailings have labels and a notepad\n",
    "                                        G1 mailings have labels and a notepad\n",
    "\n",
    "- This is why I'm gonna extract the last two digits from the sequance to represent mailing type (unique values are 11 .. NK, TK, SK, LL, G1, GK, CC, WL, X1, XK, FS) + no action .. total action are 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## States:\n",
    "\n",
    "In the cited paper .. they defined the states as follows: \n",
    "\n",
    "It is a 5-dimensional vector consisting of \n",
    "\n",
    "(1) how recently the donor donated last (R)\n",
    "\n",
    "(2) how frequently she donates (F)\n",
    "\n",
    "(3) her average donation amount (M)\n",
    "\n",
    "(4) how many times PVA sends her a mail in the last six months\n",
    "\n",
    "(5) how many times PVA has sent her mails.\n",
    "\n",
    "\n",
    "This implementation is considered as a POMPD .. \n",
    "where:\n",
    "b: belief state that is a probability distribution over all states\n",
    "b(s): prob. that the agent in state s \n",
    "after taking action a and observing the state O .. the update rule for the belief state o(s) is using Bayes rule .. \n",
    "\n",
    "## Next States:\n",
    "\n",
    "As mentioned in the paper ==> the 5-dimensional observation is discrete in this problem, and individual dimensions evolve\n",
    "independently of each other. We therefore build an observation probability table for each observation dimension,\n",
    "and the sample next observations using these tables.\n",
    "\n",
    "Hence, Let's create an n*5 dim observations table .. \n",
    "\n",
    "http://www-anw.cs.umass.edu/~barto/courses/cs687/PartialObs-printable.pdf\n",
    "\n",
    "\n",
    "### These researchers proposed other types of state space ==>\n",
    "\n",
    "https://www.cs.cmu.edu/~ebrun/15889e/hw1.pdf\n",
    "\n",
    "as 9 vars (try it out) ;) .. \n",
    "and others consider (belief, observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET_D</th>\n",
       "      <th>ODATEDW</th>\n",
       "      <th>OSOURCE</th>\n",
       "      <th>TCODE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>MAILCODE</th>\n",
       "      <th>PVASTATE</th>\n",
       "      <th>DOB</th>\n",
       "      <th>NOEXCH</th>\n",
       "      <th>...</th>\n",
       "      <th>CONTROLN</th>\n",
       "      <th>HPHONE_D</th>\n",
       "      <th>RFA_2R</th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>RFA_2A</th>\n",
       "      <th>MDMAUD_R</th>\n",
       "      <th>MDMAUD_F</th>\n",
       "      <th>MDMAUD_A</th>\n",
       "      <th>CLUSTER2</th>\n",
       "      <th>GEOCODE2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 457 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET_D ODATEDW OSOURCE TCODE STATE ZIP MAILCODE PVASTATE DOB NOEXCH  \\\n",
       "20        1       3      20     3    10  20        1        1  12      1   \n",
       "44        2       8      39     2    18  44        1        1  26      1   \n",
       "50        2       5      30     2    13  50        1        1  31      1   \n",
       "41        2       3      37     3    12  41        1        1   2      1   \n",
       "36        2      10      33     1    15  36        1        1  21      1   \n",
       "\n",
       "     ...    CONTROLN HPHONE_D RFA_2R RFA_2F RFA_2A MDMAUD_R MDMAUD_F MDMAUD_A  \\\n",
       "20   ...          20        2      1      4      4        1        1        1   \n",
       "44   ...          44        2      1      4      3        1        1        1   \n",
       "50   ...          50        1      1      1      3        1        1        1   \n",
       "41   ...          41        1      1      1      2        1        1        1   \n",
       "36   ...          36        2      1      3      1        1        1        1   \n",
       "\n",
       "   CLUSTER2 GEOCODE2  \n",
       "20       18        1  \n",
       "44       36        4  \n",
       "50       37        4  \n",
       "41       35        4  \n",
       "36       31        4  \n",
       "\n",
       "[5 rows x 457 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_():\n",
    "    train, test = df_split()\n",
    "    \n",
    "    RFA = ['RFA_2']  # don't know if it is NUMPRM12 or CARDPM12 \n",
    "\n",
    "    ## next state\n",
    "    ## next_states are random selection from the current states\n",
    "    RFA_next = ['RFA_3', 'RFA_4', 'RFA_5', 'RFA_6', 'RFA_7', 'RFA_8', 'RFA_9', 'RFA_10',\n",
    "                'RFA_11', 'RFA_12', 'RFA_13', 'RFA_14', 'RFA_15', 'RFA_16', 'RFA_17', 'RFA_18',\n",
    "                'RFA_19', 'RFA_20', 'RFA_21', 'RFA_22', 'RFA_23', 'RFA_24']\n",
    "#     next_states = [[random.random() for e in train[RFA].values[0]] for e in xrange(len(train[RFA].values))]\n",
    "#     next_states = pd.DataFrame(next_states)\n",
    "\n",
    "    current_states = train['RFA_2']\n",
    "    next_states = train[RFA_next]\n",
    "    \n",
    "    rewards = ['TARGET_D']\n",
    "    \n",
    "    train_rewards = train[rewards].values\n",
    "    \n",
    "    for i in xrange(len(rewards)):\n",
    "        train[rewards[i]] = pd.Categorical((pd.factorize(train[rewards[i]])[0] + 1).astype(str))\n",
    "    \n",
    "    for j in xrange(np.shape(actions)[1]):\n",
    "        curr_state_current_action = pd.DataFrame(np.column_stack((current_states.values, actions[:25][j])))\n",
    "\n",
    "        # next actions \n",
    "        next_actions = np.zeros([len(next_states), max(actions.max(axis = 0).astype(int)) + 1])\n",
    "        next_actions = np.delete(next_actions, -1, axis=1) ## remove last column .. \n",
    "\n",
    "        next_state_next_action = np.zeros([np.shape(next_states)[0], np.shape(next_states)[1] + max(actions.max(axis = 0).astype(int))])\n",
    "\n",
    "\n",
    "    #     # fill in next_actions  \n",
    "        for i in xrange(np.shape(next_actions)[1]):\n",
    "            next_actions[:, i] = i\n",
    "\n",
    "        Mxa = np.column_stack((next_states.values, next_actions))  # (25,2) \n",
    "\n",
    "        tuplesMx = np.column_stack((Mxa,curr_state_current_action.values, train_rewards))\n",
    "\n",
    "    \n",
    "    return Mxa, tuplesMx #next_states, next_actions, curr_state_current_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mxa, tuplesMx = tuple_()\n",
    "type(Mxa), type(tuplesMx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression phase:\n",
    "\n",
    "Before performing the prediction task .. let's split the data to training and validation sets .. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid any problems in prediction by having string variables .. let's binarize (catergorize) all the variables .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9\n",
    "Num_itrs = 2  # no loop 3leha ( w dah el sa7) .. we just have to run the whole algo. 10 times and report the avg. results\n",
    "\n",
    "num_epoch = 1 #23 #epochs are cycles of Feedforward and Backprob\n",
    "## el mafrood yeb2a feh loop 3la el epochs elli heyya el steps .. w avg. reward per step is calculated \n",
    "batch_size = 5\n",
    "chunkSize = 1\n",
    "\n",
    "n_nodes_hl1 = np.shape(train)[0]\n",
    "n_nodes_hl2 = np.shape(train)[0]\n",
    "NUM_STATES = np.shape(train)[1]\n",
    "NUM_DIM =  np.shape(train)[1]\n",
    "num_nodes = np.shape(train)[0]\n",
    "num_unrollings = 5\n",
    "\n",
    "best_actions = np.zeros([np.shape(train)[0], batch_size])\n",
    "Q_optimal = [] #np.zeros([np.shape(curr_state_current_action)[0], len(df['ACCOUNT_STATUS'].unique())])\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "## for training \n",
    "x = tf.placeholder(tf.float32, shape=[NUM_DIM, num_nodes])\n",
    "y =  tf.placeholder(tf.float32, shape=[num_nodes, 1])\n",
    "\n",
    "## for testing\n",
    "x_ = tf.placeholder(tf.float32, shape=[np.shape(test)[0], NUM_DIM])\n",
    "y_ =  tf.placeholder(tf.float32, shape=[np.shape(test)[0], 1])\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "# Input gate: input, previous output, and bias.\n",
    "ix = tf.Variable(tf.truncated_normal([NUM_DIM, num_nodes], 0, 1, dtype = tf.float32))# init_weights_RNN([n_nodes_hl1, NUM_ACTIONS])\n",
    "im = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], 0, 1, dtype = tf.float32))\n",
    "ib = tf.Variable(tf.zeros([1, num_nodes], dtype = tf.float32))\n",
    "\n",
    "# Forget gate: input, previous output, and bias.\n",
    "fx = tf.Variable(tf.truncated_normal([NUM_DIM, num_nodes], 0, 1, dtype = tf.float32))\n",
    "fm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], 0, 1, dtype = tf.float32))\n",
    "fb = tf.Variable(tf.zeros([1, num_nodes], dtype = tf.float32))\n",
    "\n",
    "# Memory cell: input, state and bias.                             \n",
    "cx = tf.Variable(tf.truncated_normal([NUM_DIM, num_nodes], 0, 1, dtype = tf.float32))\n",
    "cm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], 0, 1, dtype = tf.float32))\n",
    "cb = tf.Variable(tf.zeros([1, num_nodes], dtype = tf.float32))\n",
    "\n",
    "# Output gate: input, previous output, and bias.\n",
    "ox = tf.Variable(tf.truncated_normal([NUM_DIM, num_nodes], 0, 1, dtype = tf.float32))\n",
    "om = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], 0, 1, dtype = tf.float32))\n",
    "ob = tf.Variable(tf.zeros([1, num_nodes], dtype = tf.float32))\n",
    "\n",
    "# Variables saving state across unrollings.\n",
    "saved_output = tf.Variable(tf.zeros([1, num_nodes], dtype = tf.float32), trainable=False) #reversed\n",
    "\n",
    "saved_state = tf.Variable(tf.zeros([1, num_nodes], dtype = tf.float32), trainable=False) #reversed\n",
    "\n",
    "# Classifier weights and biases.\n",
    "w = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], 0, 1, dtype = tf.float32))\n",
    "b = tf.Variable(tf.zeros([num_nodes], dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the cell computation.\n",
    "# this method takes single cell and returns single number \n",
    "def lstm_cell(i, o, state):\n",
    "    input_gate = tf.sigmoid(tf.matmul(i, ix) + tf.matmul(o, im) + ib)\n",
    "    forget_gate = tf.sigmoid(tf.matmul(i, fx) + tf.matmul(o, fm) + fb)\n",
    "    update = tf.matmul(i, cx) + tf.matmul(o, cm) + cb\n",
    "    state = forget_gate * state + input_gate * tf.tanh(update)\n",
    "    output_gate = tf.sigmoid(tf.matmul(i, ox) + tf.matmul(o, om) + ob)\n",
    "    return output_gate * tf.tanh(state), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(train, saved_output, saved_state):\n",
    "    # Unrolled LSTM loop.    \n",
    "    outputs = list()\n",
    "    output = saved_output  # row !\n",
    "    state = saved_state  # row !\n",
    "    \n",
    "    # astype('U') .. to convert numpy array to string ..\n",
    "    for i in xrange(np.shape(train)[0]):## el loop faydetha to copy the next line that is just for single unit \n",
    "        output_, state = lstm_cell(tf.string_to_number(train.values[i, None].astype('U')), tf.cast(output, tf.float32), tf.cast(state, tf.float32)) \n",
    "\n",
    "    ## in case the last values are saved !\n",
    "    with tf.control_dependencies([saved_output.assign(output), saved_state.assign(state)]):\n",
    "        model_output = tf.matmul(output_, w) + b # outputs single value\n",
    "        \n",
    "    return model_output  ## the output for the whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_model():\n",
    "    loss_RNN = []\n",
    "    model_output = lstm_model(train, saved_output, saved_state) #output here is a vector\n",
    "    model_output = tf.transpose(model_output)\n",
    "    cost = tf.reduce_mean(tf.square(y - model_output))\n",
    "    optimize = tf.train.GradientDescentOptimizer(0.01).minimize(cost) \n",
    "\n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()  ## updated version from initialize_all_variables :) \n",
    "    sess.run(init)\n",
    "\n",
    "    predicted_reward = sess.run(model_output, feed_dict={x:np.transpose(train.values), y:train[rewards].values})\n",
    "    \n",
    "    # Cost calculation\n",
    "    for step in xrange(1000):\n",
    "        l,_ = sess.run([cost, optimize], feed_dict={x:np.transpose(train.values), y:train[rewards]})\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            loss_RNN.append(l)\n",
    "\n",
    "    Y_pred = tf.zeros([len(test[rewards]),1])\n",
    "\n",
    "    # predict \n",
    "    test_pred2 = sess.run(Y_pred, feed_dict={x_: test.values})\n",
    "\n",
    "   ## rms to test ..\n",
    "    cost_test = tf.reduce_mean(tf.square(test[rewards].values.astype(np.float32) - test_pred2))\n",
    "    \n",
    "    \n",
    "    rmse_val = sess.run(cost_test, feed_dict={x_:test.values.astype(np.float32), y_: test_pred2})\n",
    "     \n",
    "    sess.close()\n",
    "    \n",
    "    return loss_RNN, predicted_reward #saved_state, saved_output, cost_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_prediction(train):\n",
    "    loss_RNN, predicted_reward = train_lstm_model()\n",
    "    plt.plot(loss_RNN)\n",
    "    plt.xlabel('Step number')\n",
    "    plt.ylabel('Prediction Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAHnpJREFUeJzt3Xt0XOV57/HvMzO6WLKskbHs2NYI\nm5vBAVsCBUw4J5cCJWlo0pUmBKekJG1jciskaZNFz2mbrHOaNslKyO00BHMLLQTCIZyVGyW3hqTJ\n4hIb3/AVMGDLF2xjJMs3XZ/zx2yJsWJJg62Zd2b277PWLM3s2bP3wyzkn9797vd9zd0REZH4SoQu\nQEREwlIQiIjEnIJARCTmFAQiIjGnIBARiTkFgYhIzBUsCMzsDjPbY2ZP5WybbmY/M7Ono59NhTq/\niIjkp5Atgm8Dbxm17UbgF+5+JvCL6LWIiARkhRxQZmbzgB+5+7nR683Am9x9l5nNBh5x9wUFK0BE\nRCaUKvL5Zrn7ruj5bmBWPh+aMWOGz5s3r2BFiYhUopUrV+5z9+aJ9it2EIxwdzezMZsjZrYMWAbQ\n2trKihUrilabiEglMLMX8tmv2HcNvRhdEiL6uWesHd19ubt3uHtHc/OEgSYiIieo2EHwA+Da6Pm1\nwPeLfH4RERmlkLeP3gs8Ciwws04z+0vg88DlZvY0cFn0WkREAipYH4G7Lx3jrUsLdU4REXn1NLJY\nRCTmFAQiIjGnIBARibmKDoLvr97B3Y/ldRutiEhsVXQQPPzUbpb/emvoMkRESlpFB0F7a5pt+w/z\n0sHe0KWIiJSsig6Ctkx2luvV27sCVyIiUroqOgjOm9tIMmGs2qYgEBEZS0UHwZTqJGe/pkEtAhGR\ncVR0EEC2n2DN9i6Ghgq37oKISDmr+CBoyzTR0zvAs3sPhi5FRKQkxSAI0gDqJxARGUPFB8FpM+qZ\nVptilfoJRESOq+KDIJEwFmfS6jAWERlDxQcBQHtrE5t3H+BQ70DoUkRESk48giCTZshh3Y7u0KWI\niJScWASBOoxFRMYWiyBoqq9m3il1rN7+cuhSRERKTiyCALL9BKu2deGugWUiIrliEwRtmTR7enrZ\n1X00dCkiIiUlVkEA6icQERktNkFwzuxpVKcS6icQERklNkFQnUpw7pxpGlgmIjJKbIIAsh3Gazu7\n6R8cCl2KiEjJiFUQtGXS9A4MsXl3T+hSRERKRqyCoL11uMNY/QQiIsNiFQRz01OYMbVGM5GKiOSI\nVRCYGe2taVbrFlIRkRGxCgLI9hNs3XeIrsN9oUsRESkJsQuC9mhgmW4jFRHJil0QLMqkMVMQiIgM\ni10QTK1JcdbMBgWBiEgkdkEA2dtIV2/XTKQiIhAoCMzsE2a23syeMrN7zay2mOdvy6TpOtzP8y8d\nLuZpRURKUtGDwMzmAtcDHe5+LpAEri5mDe2tTYAGlomIQLhLQylgipmlgDpgZzFPfsbMqdRXJ9VP\nICJCgCBw9x3Al4BtwC6g291/Ono/M1tmZivMbMXevXsntYZkwlicSWttAhERwlwaagLeAcwH5gD1\nZnbN6P3cfbm7d7h7R3Nz86TX0ZZJs3HXAY72D076sUVEykmIS0OXAc+5+1537wceBF5f7CLaMmkG\nhpyndnQX+9QiIiUlRBBsA5aYWZ2ZGXApsLHYRbS1aoSxiAiE6SN4HHgAeBJYF9WwvNh1zGyoZW56\nimYiFZHYS4U4qbt/BvhMiHPnam9Vh7GISCxHFg9ry6TZ0XWEPQeOhi5FRCSYWAfByMAyXR4SkRiL\ndRC8ds40qpKmDmMRibVYB0FtVZKFs6dpqgkRibVYBwFk+wnWdnYzOKSZSEUknhQErWkO9w2y5cWe\n0KWIiAQR+yBoz2Q7jNVPICJxFfsgOPWUOprqqlit8QQiElOxDwIzoy2TZtV2dRiLSDzFPggA2jJN\nPL3nID1H+0OXIiJSdAoCslNNuMPaTs1EKiLxoyAAFmc0E6mIxJeCAGicUsVpzfUaWCYisaQgiLRn\nmli9vQt3DSwTkXhREETaWtPsO9hH58tHQpciIlJUCoJIe9RPoJlIRSRuFASRs1/TQG1VQgPLRCR2\nFASRVDLBorkaWCYi8aMgyNHWmmb9zgP0DgyGLkVEpGgUBDnaM2n6BobYuEszkYpIfCgIcrS1RgPL\nNJ5ARGJEQZBjduMUZk2r0Z1DIhIrCoJRhgeWiYjEhYJglLbWNC+8dJiXDvaGLkVEpCgUBKMMDyxb\n06lWgYjEw4RBYGbvNrOG6Pnfm9mDZnZ+4UsL47yWRpIJ08AyEYmNfFoE/+DuPWb234DLgNuBmwtb\nVjh11SkWzGpQh7GIxEY+QTA8uuptwHJ3/zFQXbiSwmtrTbN6exdDQ5qJVEQqXz5BsMPMbgHeAzxk\nZjV5fq5stWfS9BwdYOu+g6FLEREpuHz+Qb8K+Alwhbt3AdOBTxW0qsDao4Flq9RPICIxkE8QzAZ+\n7O5Pm9mbgHcDTxS0qsBOmzGVhtqU+glEJBbyCYLvAYNmdgawHMgA3yloVYElEkZbJq07h0QkFvIJ\ngiF3HwDeCXzD3T9FtpVwwswsbWYPmNkmM9toZhefzPEKoS2TZtPuAxzuGwhdiohIQeUTBP1mthT4\nc+BH0baqkzzv14CH3f1sYDGw8SSPN+naW9MMOazr7A5diohIQeUTBB8ALgY+5+7Pmdl84N9P9IRm\n1gi8gex4BNy9L+qELimLW6KZSNVPICIVbsIgcPcNwN8C68zsXKDT3b9wEuecD+wF7jSzVWZ2m5nV\nn8TxCuKUqTWcekqd7hwSkYqXzxQTbwKeBv4V+CawxczecBLnTAHnAze7eztwCLjxOOddZmYrzGzF\n3r17T+J0J64tk1aLQEQqXj6Xhr4M/KG7v9Hd3wBcAXzlJM7ZSbZV8Xj0+gGywXAMd1/u7h3u3tHc\n3HwSpztx7Zk0uw8cZVf3kSDnFxEphnyCoMrdNw+/cPctnERnsbvvBrab2YJo06XAhhM9XiG1tTYB\n6DZSEalo+QTBiug6/puix63AipM8718D95jZWqAN+OeTPF5BnDO7gepkQgPLRKSipfLY58PAR4Hr\no9f/Rba/4IS5+2qg42SOUQw1qSSvnTtNLQIRqWj53DXU6+43ufs7o8dXOInbR8tNWybN2h1d9A8O\nhS5FRKQgTnQW0ZIbCVwo7a1NHO0fYvPuntCliIgUREVPJz0Zhpeu1G2kIlKpxuwjGGc5SuPkp5go\nGy1NU5gxtZpV27q4ZsmpocsREZl043UWf3mc9zZNdiGlyiyaiXT7y6FLEREpiDGDwN3fXMxCSll7\naxM/37iH7sP9NNbFpjEkIjGhPoI8tEX9BGs61U8gIpVHQZCHRS2NmGnpShGpTAqCPDTUVnHmzKnq\nJxCRipTPyGLMbC5wau7+7v7rQhVVitoyaX624UXcHTMLXY6IyKSZMAjM7AvAe8hODDcYbXYgVkHQ\n3trE/Ss6eeGlw8ybUXLLJ4iInLB8WgR/Aixw995CF1PK2nIGlikIRKSS5NNHsJUYDSAby1mzGqir\nTrJqm/oJRKSy5NMiOAysNrNfACOtAne/fuyPVJ5kwljU0qipJkSk4uQTBD+IHrHX3trEbf+1laP9\ng9RWJUOXIyIyKSYMAne/y8yqgbOiTZvdvb+wZZWmtkya/kFn/c4DXHBqU+hyREQmRYjF68vW8Eyk\n6icQkUqSz6Wh4cXrNwOY2VnAvcAFhSysFM2cVsvc9BT1E4hIRSn64vXlri2T1lQTIlJRQi1eX7ba\nW9Ps6DrC3p5YD6sQkQqSTxB8mOyo4uujx4ZoWyy1acUyEakw+dw11AvcFD1i79y5jaQSxqptL3P5\nwlmhyxEROWnjLVV5v7tfZWbryM4tdAx3X1TQykpUbVWSc2ZPU4tARCrGeC2CG6KfVxajkHLS3prm\neys7GRxykgnNRCoi5W3MPgJ33xU9/Yi7v5D7AD5SnPJKU1smzaG+QZ7ZczB0KSIiJy2fzuLLj7Pt\nrZNdSDlp08AyEakgYwaBmX046h8428zW5jyeA9YVr8TSM39GPY1TqtRPICIVYbw+gu8A/wH8C3Bj\nzvYed99f0KpKnJlpYJmIVIzx+gi63f154GvA/pz+gQEzu6hYBZaq9tY0W/b0cLB3IHQpIiInJZ8+\ngpuB3F7Rg9G2WGvLpHGHtZ1qFYhIecsnCMzdR8YRuPsQeS56X8le6TBWEIhIectrqUozu97MqqLH\nDWSXr4y1dF01p82oV4exiJS9fILgQ8DrgR1AJ3ARsOxkT2xmSTNbZWY/OtljhTLcYZzTYBIRKTsT\nBoG773H3q919prvPcvf3uvueSTj3DcDGSThOMO2tafYd7GVH15HQpYiInLDx5hr6tLt/0cy+wfHn\nGjrhxevNrAV4G/A54JMnepzQ2jLZ5SpXbeuipakucDUiIidmvE7f4b/WC7H2wFeBTwMNBTh20Zw9\nu4GaVILV27v448VzQpcjInJCxgwCd/9h9POuyTyhmV0J7HH3ldF6yGPtt4yoL6K1tXUyS5g0VckE\n581t1FQTIlLWxrs09EOOc0lomLu//QTPeQnwdjP7I6AWmGZmd7v7NaOOvxxYDtDR0VGyvbHtrWnu\nevQF+gaGqE7l0/cuIlJaxvuX60tkF65/DjgC3Bo9DgLPnugJ3f3v3L3F3ecBVwP/OToEyklbpom+\ngSE27joQuhQRkRMy3qWhXwGY2ZfdvSPnrR+aWWzXLB6tvfWVpSsXR4PMRETKST7XMurN7LThF2Y2\nH6ifjJO7+yPuXtYL38xurGVmQ40GlolI2cpnqohPAI+Y2VbAgFOB6wpaVRl5ZSZSdRiLSHnKZ/H6\nh83sTODsaNOmaEF7ibS3NvHTDS/y8qE+muqrQ5cjIvKqTHhpyMzqgE8BH3P3NUBrdAuoRIYnoNPl\nIREpR/n0EdwJ9AEXR693AP9UsIrK0KKWRhIGqxQEIlKG8gmC0939i0A/gLsfJttXIJH6mhRnzWpQ\nP4GIlKV8gqDPzKYQDS4zs9MB9RGM0t7axJrtXQwNlezYNxGR48onCD4DPAxkzOwe4Bdk5wmSHO2Z\nNAeODrB136HQpYiIvCrj3jVkZgZsAt4JLCF7SegGd99XhNrKSu7AsjNmTg1cjYhI/sZtEURLVD7k\n7i+5+4/d/UcKgeM7vXkqDTUpVm9XP4GIlJd8Lg09aWavK3glZS6RMBZlGrWGsYiUnXyC4CLgMTN7\n1szWmtk6M1tb6MLKUXumiU27ezjSNxi6FBGRvOUzxcQVBa+iQrRl0gwOOet2dHPh/OmhyxERyct4\n6xHUkl24/gxgHXC7uw8Uq7By1DbSYfyygkBEysZ4l4buAjrIhsBbya5NIOOYMbWGzPQp6icQkbIy\n3qWhhe5+HoCZ3Q48UZySylt7ponfPb8/dBkiInkbr0XQP/xEl4Ty15ZJs6v7KLu7j4YuRUQkL+MF\nwWIzOxA9eoBFw8/NTOsyjqE9p59ARKQcjBkE7p5092nRo8HdUznPpxWzyHKycM40qpMJzUQqImUj\nn3EE8irUpJKcM2eaOoxFpGwoCAqgPZNmXWc3A4NDoUsREZmQgqAA2lvTHOkfZPOLPaFLERGZkIKg\nANozTYCWrhSR8qAgKIDM9ClMr69WP4GIlAUFQQGYGe2ZtFoEIlIWFAQF0pZJ88yeg3Qf6Z94ZxGR\ngBQEBdLemu0nWNupVoGIlDYFQYEsyjRiBqvVTyAiJU5BUCDTaqs4vXmqRhiLSMlTEBTQcIdxduln\nEZHSpCAooLbWNPsP9bFt/+HQpYiIjElBUEAaWCYi5UBBUEBnzZrKlKqkBpaJSElTEBRQKplgUUuj\nOoxFpKQVPQjMLGNmvzSzDWa23sxuKHYNxdTWmmbDzm6O9g+GLkVE5LhCtAgGgL9x94XAEuCjZrYw\nQB1F0Z5pon/Q2bBLi7qJSGkqehC4+y53fzJ63gNsBOYWu45iGVm6Uv0EIlKigvYRmNk8oB14PGQd\nhTRrWi2nzajnW796lmf2aH0CESk9wYLAzKYC3wM+7u6/d93EzJaZ2QozW7F3797iFziJvvW+Cxhy\neM8tj7FRl4hEpMQECQIzqyIbAve4+4PH28fdl7t7h7t3NDc3F7fASXbWrAbuv24J1akES299jHWd\n3aFLEhEZEeKuIQNuBza6+03FPn8opzVP5f7rLmZqTYr33voYK194OXRJIiJAmBbBJcD7gD8ws9XR\n448C1FF0mel13H/dxcxoqOF9tz/Oo8++FLokEZEgdw39xt3N3Re5e1v0eKjYdYQyJz2F7y5bwtz0\nFN5/5xP8ekt593+ISPnTyOIAZk6r5b5lSziteSp/ddcKfr7hxdAliUiMKQgCOWVqDfd9cAnnzG7g\nQ3ev5KF1u0KXJCIxpSAIqLGuirv/6iLaMmk+9p0n+X+rOkOXJCIxpCAIrKG2irv+4kIumn8Kn7x/\nDfc9sS10SSISMwqCElBfk+LOD7yON5zZzI0PruPfHn0+dEkiEiMKghJRW5Vk+Z9fwOULZ/GP31/P\n8l8/G7okEYkJBUEJqUkl+eafnc+Vi2bzzw9t4uu/eFrrHYtIwaVCFyDHqkom+NrV7VSnEtz0sy0c\n7R/kU1csIDsgW0Rk8ikISlAyYXzpXYuprUryzUee5Wj/EP9w5TkKAxEpCAVBiUokjM/9ybnUpBLc\n8dvn6B0Y5H+/41wSCYWBiEwuBUEJMzP+8cqF1FYlufmRZ+kdGOILf7qIpMJARCaRgqDEmRmfvmIB\ntakkX/n5FnoHhrjpqsVUJdXPLyKTQ0FQBsyMGy47k5qqBJ//j030DQzy9aXt1KSSoUsTkQqgPyvL\nyIfeeDqf/eOF/GT9i3zo31dytH8wdEkiUgEUBGXm/ZfM51/eeR6PbNnLX971Ow73DYQuSUTKnIKg\nDC29sJUvv3sxjz77Etfe8QQ9R/tDlyQiZUxBUKbeeX4L31h6Pqu2dXHN7U/QfVhhICInRkFQxt62\naDY3X3MBG3ceYOmtj7H/UF/okkSkDCkIytzlC2dx67UdPLv3IFcvf5Q9PUdDlyQiZUZBUAHeeFYz\nd37gdXS+fISrb3mMXd1HQpckImVEQVAhXn/6DP7tLy5kb08vV93yKNv3Hw5dkoiUCQVBBemYN517\nPngRB44McNUtj/LcvkOhSxKRMqAgqDCLWtLc+8El9A0McdUtj/L0iz2hSxKREqcgqEAL50zjvmVL\nMOA9yx9j/c7u0CWJSAlTEFSoM2c18N3rLqY2lWDp8sdYs70rdEkiUqIUBBVs/ox6vnvdxaTrqvmz\n2x5nxfP7Q5ckIiVIQVDhMtPruP+6i5nZUMP7bn+Cz/5gPQ8+2ckzew4yNKT1kEUErBwWR+/o6PAV\nK1aELqOs7e3p5VMPrOHxrfs5Es1a2lCT4ty5jSzKNLK4Jc15cxtpaZqiJTFFKoSZrXT3jon203oE\nMdHcUMO3P3Ahg0POM3sOsqazi7WdXazt7OaO3zxH/2D2D4JT6qs5r6WRRS1pFkc/mxtqAlcvIoWk\nIIiZZMJY8JoGFrymgas6MgD0DgyyaVfPSDCs7ezm11ueZvjK0ZzGWha1pFmUaWTR3DTntTTSOKUq\n4H+FiEwmBYFQk0qyOJNmcSY9su1Q7wDrdx5gbWcXazq7WdvZxcPrd4+8P39GPYtyWg6vndPIlGqt\nmCZSjhQEclz1NSkunD+dC+dPH9nWdbiPdTuyLYY127t4fOt+vr96J5BtaZw5c2pOOKRZ8JoGqlO6\nH0Gk1AXpLDaztwBfA5LAbe7++fH2V2dx6dpz4OhIi2Ft9PPlaG2E6lSCc2ZPG+lrWNzSyGnNU0km\n1BktUgz5dhYXPQjMLAlsAS4HOoHfAUvdfcNYn1EQlA93p/PlI1FndLbl8NSObg71Ze9Uqq9Ocs7s\naaTrqqirTlFXnWRKdZL66hRTqpPUjTyOfW/4+fD2mlRCdzeJTKCU7xq6EHjG3bcCmNl9wDuAMYNA\nyoeZkZleR2Z6HVcumgPA4JDz3L6DrNmebTFs3N3Djq6jHOkb4HDfIEf6BjnUN8CrGdaQMEZCIRsS\nKepHwiJ53PeGnw9vr61KkkwYCTMSBgkzkgnDjJzt+b2XSGSfD79nBsnhfdQCkhIXIgjmAttzXncC\nFwWoQ4okmTDOmNnAGTMb+NMLWo67j7vTOzA0EgpH+gY5PPI4NjByn4/er+foAHsO9B7z3vC4iZCG\nQ8Ki8MgNCTMYjgozy3k+/Gk75vXo9y3n/dzj5BrZ9zifGT5mPi2sCffII/Mm2kUtvWPdce3raD2l\nrqDnKNnOYjNbBiwDaG1tDVyNFJqZUVuV/Su9qb56Uo89NOQc6R/8vTDp7R9k0J0hhyF3hoayzweH\nHHcfec/dGYzey+4z8XsevR45fvRe7rlG9osuz7qD88pzgOFG0itXcEe9P7Kfj/mZ4WPye+/7yOt8\nrhBPtEs+l5kn3KP0x7cWXTFuuAgRBDuATM7rlmjbMdx9ObAcsn0ExSlNKlEiYdTXpKivKdm/e0SC\nCnFv3++AM81svplVA1cDPwhQh4iIEKBF4O4DZvYx4Cdkbx+9w93XF7sOERHJCtJWdveHgIdCnFtE\nRI6lYZ8iIjGnIBARiTkFgYhIzCkIRERiTkEgIhJzZbFUpZntBV44wY/PAPZNYjnlTt/HK/RdHEvf\nx7Eq4fs41d2bJ9qpLILgZJjZinxm34sLfR+v0HdxLH0fx4rT96FLQyIiMacgEBGJuTgEwfLQBZQY\nfR+v0HdxLH0fx4rN91HxfQQiIjK+OLQIRERkHBUdBGb2FjPbbGbPmNmNoesJxcwyZvZLM9tgZuvN\n7IbQNZUCM0ua2Soz+1HoWkIzs7SZPWBmm8xso5ldHLqmUMzsE9HvyVNmdq+Z1YauqdAqNgjMLAn8\nK/BWYCGw1MwWhq0qmAHgb9x9IbAE+GiMv4tcNwAbQxdRIr4GPOzuZwOLien3YmZzgeuBDnc/l+xU\n+VeHrarwKjYIgAuBZ9x9q7v3AfcB7whcUxDuvsvdn4ye95D9JZ8btqqwzKwFeBtwW+haQjOzRuAN\nwO0A7t7n7l1hqwoqBUwxsxRQB+wMXE/BVXIQzAW257zuJOb/+AGY2TygHXg8bCXBfRX4NDAUupAS\nMB/YC9wZXSq7zczqQxcVgrvvAL4EbAN2Ad3u/tOwVRVeJQeBjGJmU4HvAR939wOh6wnFzK4E9rj7\nytC1lIgUcD5ws7u3A4eAWPapmVkT2SsH84E5QL2ZXRO2qsKr5CDYAWRyXrdE22LJzKrIhsA97v5g\n6HoCuwR4u5k9T/aS4R+Y2d1hSwqqE+h09+FW4gNkgyGOLgOec/e97t4PPAi8PnBNBVfJQfA74Ewz\nm29m1WQ7fH4QuKYgzMzIXv/d6O43ha4nNHf/O3dvcfd5ZP+/+E93r/i/+sbi7ruB7Wa2INp0KbAh\nYEkhbQOWmFld9HtzKTHoOA+yZnExuPuAmX0M+AnZnv873H194LJCuQR4H7DOzFZH2/5HtHa0CMBf\nA/dEfzRtBT4QuJ4g3P1xM3sAeJLs3XariMEIY40sFhGJuUq+NCQiInlQEIiIxJyCQEQk5hQEIiIx\npyAQEYk5BYGUPTP7n9FskWvNbLWZXRRt/7iZ1YWubzxmNs/Mngpdh8RbxY4jkHiIpku+Ejjf3XvN\nbAZQHb39ceBu4HCo+grNzFLuPhC6DilvahFIuZsN7HP3XgB33+fuO83serJzxfzSzH4JYGZ/aGaP\nmtmTZvZ/o7mXMLPnzeyLZrbOzJ4wszNGn8TMPmtmd5jZI2a2NTr+7/1Fb2Z/a2afjZ4/YmZfMbMV\n0Rz/rzOzB83saTP7p5zDp8zsnmifB4ZbMWZ2gZn9ysxWmtlPzGx2znG/amYryE6lLXJSFARS7n4K\nZMxsi5l908zeCODuXyc7ffCb3f3NUUvh74HL3P18YAXwyZzjdLv7ecD/ITsz6fGcDVxBdorzz0Tz\nN02kz907gG8B3wc+CpwLvN/MTon2WQB8093PAQ4AH4mO/Q3gXe5+AXAH8Lmc41a7e4e7fzmPGkTG\npUtDUtbc/aCZXQD8d+DNwHfN7EZ3//aoXZeQXaDot9kpZKgGHs15/96cn18Z43Q/jloevWa2B5iV\nR4nD81utA9a7+y4AM9tKdlLELmC7u/822u9usgujPEw2MH4W1ZskOy3ysO/mcW6RvCgIpOy5+yDw\nCPCIma0DrgW+PWo3A37m7kvHOswYz3P15jwfJPv7M8CxLevRyxoOf2Zo1OeHeOX3b/T5PKp3vbuP\ntWTkoTG2i7xqujQkZc3MFpjZmTmb2oAXouc9QEP0/DHgkuHr/2ZWb2Zn5XzuPTk/c1sKE3kRmGlm\np5hZDdmO61erNWeN4PcCvwE2A83D282sysxeewLHFpmQWgRS7qYC3zCzNNm/zp8BlkXvLQceNrOd\nUT/B+4F7o3+wIdtnsCV63mRma8n+1T5Wq+H3uHu/mf0v4Amy611sOoH/hs1k15G+g+z0zze7e5+Z\nvQv4erSUZIps30VcZ9CVAtLsoxJ70QI1He6+L3QtIiHo0pCISMypRSAiEnNqEYiIxJyCQEQk5hQE\nIiIxpyAQEYk5BYGISMwpCEREYu7/A2DD5Ov4W8D9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f786cd6ea90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reward_prediction(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning the rewards:\n",
    "Now, the LSTM_RNN output (from validation phase) is considered as input for DQN model, to be able to select the action that has the maximum longtime reward for the customer (highest CLV) .. \n",
    "\n",
    "https://arxiv.org/pdf/1602.01580.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Deep Neural Network (DQN):\n",
    "\n",
    "https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/blob/master/contents/5_Deep_Q_Network/RL_brain.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Definition of the cell computation.\n",
    "# this method takes single cell and returns single number \n",
    "def lstm_cell(i, o, state):\n",
    "    input_gate = tf.sigmoid(tf.matmul(i, ix) + tf.matmul(o, im) + ib)\n",
    "    forget_gate = tf.sigmoid(tf.matmul(i, fx) + tf.matmul(o, fm) + fb)\n",
    "    update = tf.matmul(i, cx) + tf.matmul(o, cm) + cb\n",
    "    state = forget_gate * state + input_gate * tf.tanh(update)\n",
    "    output_gate = tf.sigmoid(tf.matmul(i, ox) + tf.matmul(o, om) + ob)\n",
    "    return output_gate * tf.tanh(state), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN_model(X, w_h_1, w_h_2, w_o, bias_I_1, bias_I_2, bias_h):\n",
    "\n",
    "    X = np.transpose(X)\n",
    "    layer_1 = tf.matmul(X, w_h_1) + bias_I_1\n",
    "    layer_1 = tf.nn.relu(layer_1)  ## el performance of softmax outperforms relu!!\n",
    "    \n",
    "    layer_2 = tf.matmul(layer_1, w_h_2) + bias_I_2\n",
    "    layer_2 = tf.nn.sigmoid(layer_2) \n",
    "\n",
    "    py_x = tf.matmul(layer_2, w_o) + bias_h\n",
    "    \n",
    "    return py_x  #predicted output\n",
    "    # note that we dont take the softmax at the end because our cost fn does that for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN_training(X, output):\n",
    "    \n",
    "    w_h_1 = init_weights([len(X), n_nodes_hl1]) # create symbolic variables\\n\",\n",
    "    w_h_2 = init_weights([n_nodes_hl1, n_nodes_hl2]) # create symbolic variables\\n\",\n",
    "    w_o = init_weights([n_nodes_hl2, 1])\n",
    "    \n",
    "    bias_I_1=init_weights([n_nodes_hl1])\n",
    "    bias_I_2=init_weights([n_nodes_hl2])\n",
    "    bias_h=init_weights([1])\n",
    "    \n",
    "    X = pd.DataFrame(X)\n",
    "    \n",
    "    py_x = DQN_model(X.convert_objects(convert_numeric=True).astype(np.float32), w_h_1, w_h_2, w_o, bias_I_1, bias_I_2,bias_h)  #model training  \n",
    "    \n",
    "# #     print type(X.convert_objects(convert_numeric=True).astype(np.float32))\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.square(py_x - output)) # compute costs\",  # excpect float32\n",
    "\n",
    "    train_op = tf.train.GradientDescentOptimizer(0.01).minimize(cost) # construct an optimizer\\n\",\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "#      # Cost calculation\n",
    "#     for step in xrange(1000):\n",
    "#         l,_ = sess.run([cost, train_op], feed_dict={x:np.transpose(X), y:np.transpose(output)})\n",
    "        \n",
    "#         if step % 100 == 0:\n",
    "#             loss_RNN.append(l)\n",
    "            \n",
    "#     plt.plot(loss_RNN)\n",
    "    \n",
    "    sess.close()    \n",
    "    return w_h_1, w_h_2, w_o,bias_I_1, bias_I_2,bias_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction phase: \n",
    "def DQN_predict(tuplesMx, output):\n",
    "    \n",
    "#     print type(tuplesMx)\n",
    "\n",
    "    w_h_1, w_h_2, w_o,bias_I_1, bias_I_2,bias_h = DQN_training(tuplesMx, output)\n",
    "    \n",
    "    tuplesMx = pd.DataFrame(tuplesMx)\n",
    "    predict_op_0 = DQN_model(tuplesMx.convert_objects(convert_numeric=True).astype(np.float32), w_h_1, w_h_2, w_o,bias_I_1, bias_I_2,bias_h)\n",
    "        \n",
    "    sess2 = tf.Session()\n",
    "    init2 = tf.global_variables_initializer()\n",
    "    sess2.run(init2)\n",
    "\n",
    "    l0=sess2.run(predict_op_0)\n",
    "        \n",
    "    Q_predicted = l0  #, l1, l2, l3, l4, l5, l6]\n",
    "    \n",
    "#     Q_predicted = np.reshape(Q_predicted, [25, 5])\n",
    "    \n",
    "#     print np.shape(Q_predicted)\n",
    "    \n",
    "    sess2.close()\n",
    "    \n",
    "    return Q_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q(s,a) representing the (Quality) of action a at state is .. \n",
    "\n",
    "this Q value depends on the immediate reward r .. however, it'll be more effective if it takes the future rewards Q(s', a') into consideration .. \n",
    "\n",
    "the future rewards are discounted by probability gama .. cause the evironment is stochastic hence, it is uncertain that each time you select action a you gonna get the same reward r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_tuplemx(nepisod, num_actions, next_states, next_actions, curr_state_current_action, train_rewards):\n",
    "    \n",
    "    \n",
    "#     tuplesMx = []\n",
    "    \n",
    "#     print type(next_states.values)\n",
    "    \n",
    "    \n",
    "#     return tuplesMx\n",
    "\n",
    "## check el calls ll functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_reward = np.transpose(predicted_reward) \n",
    "def Q_learning():\n",
    "    \n",
    "    Mxa, tuplesMx = tuple_()\n",
    "       \n",
    "#     nepisod = np.shape(next_states)[1]  ##22\n",
    "#     num_actions = np.shape(next_actions)[1]\n",
    "    \n",
    "    Q_predicted = np.zeros([np.shape(train)[0], 12])\n",
    "    best_action = list() #np.zeros([np.shape(train)[0], batch_size])\n",
    "\n",
    "    \n",
    "    _, predicted_reward = train_lstm_model()\n",
    "\n",
    "    for j in xrange(len(tuplesMx)): #(0, len(tuplesMx), batch_size):\n",
    "        Q_optimal = predicted_reward[j].astype(float) + gamma*np.max(Q_predicted) # returns max value per row !\n",
    "        Q_optimal = np.array(Q_optimal, dtype = np.float32) # convert output to float32 to match py_x\n",
    "        \n",
    "# #         Q_predicted = np.array(Q_predicted, dtype=np.float32)\n",
    "        Q_predicted = DQN_predict(tuplesMx, Q_optimal) \n",
    "    \n",
    "        print Q_predicted\n",
    "        \n",
    "    return np.mean(Q_optimal)\n",
    "        \n",
    "#     print type(Q_optimal)\n",
    "\n",
    "#             best_action.append(np.argmax(Q_predicted, axis=1))\n",
    "        #     print type(best_action)\n",
    "\n",
    "#     return np.mean(Q_optimal), best_action \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.74192876]\n",
      " [ 0.74192876]\n",
      " [-0.39720464]\n",
      " [ 0.46535605]\n",
      " [-0.27807379]\n",
      " [ 1.23171163]\n",
      " [ 1.80435872]\n",
      " [-1.44870341]\n",
      " [-1.24615049]\n",
      " [ 1.80435824]\n",
      " [-0.18798316]\n",
      " [-0.40621376]\n",
      " [ 1.22134352]\n",
      " [ 0.46535689]\n",
      " [-1.06921184]\n",
      " [ 0.4653694 ]\n",
      " [ 1.16248751]\n",
      " [ 1.06168699]\n",
      " [-0.58243895]\n",
      " [-0.37871993]\n",
      " [ 0.66247255]\n",
      " [ 1.16922736]\n",
      " [ 1.70197892]\n",
      " [ 0.51127297]\n",
      " [ 1.0586617 ]\n",
      " [ 1.4215734 ]\n",
      " [ 1.55327868]\n",
      " [ 1.5915575 ]\n",
      " [ 1.60198545]\n",
      " [ 1.60477591]\n",
      " [ 1.60551906]\n",
      " [ 1.60571671]\n",
      " [ 1.60576916]\n",
      " [ 1.60578322]\n",
      " [-0.42350364]\n",
      " [        nan]\n",
      " [ 1.68454957]]\n",
      "[[-5.95062065]\n",
      " [-5.95062065]\n",
      " [-2.60258341]\n",
      " [-3.40593863]\n",
      " [-4.28081703]\n",
      " [-5.71108103]\n",
      " [-4.97760153]\n",
      " [-4.42946005]\n",
      " [-4.56636143]\n",
      " [-6.20771122]\n",
      " [-3.34727764]\n",
      " [-3.01372433]\n",
      " [-4.15846157]\n",
      " [-6.71941566]\n",
      " [-0.80633533]\n",
      " [-3.07101822]\n",
      " [-4.27441406]\n",
      " [-0.32956612]\n",
      " [-4.11360312]\n",
      " [-4.44761944]\n",
      " [-1.31416309]\n",
      " [-0.30808544]\n",
      " [-0.40883696]\n",
      " [-4.43593693]\n",
      " [-4.38894653]\n",
      " [-4.31328392]\n",
      " [-4.20580387]\n",
      " [-4.07932281]\n",
      " [-3.9635787 ]\n",
      " [-3.88010597]\n",
      " [-3.82973003]\n",
      " [-3.80253506]\n",
      " [-3.78873253]\n",
      " [-3.78194666]\n",
      " [-4.09979916]\n",
      " [        nan]\n",
      " [-5.6686635 ]]\n",
      "[[-5.52222443]\n",
      " [-5.52222443]\n",
      " [-5.47379732]\n",
      " [-3.98230052]\n",
      " [-5.52355623]\n",
      " [-5.52355623]\n",
      " [-5.50681257]\n",
      " [-4.54441261]\n",
      " [-3.98233247]\n",
      " [-5.52355623]\n",
      " [-3.91604066]\n",
      " [-2.14605427]\n",
      " [-2.99750924]\n",
      " [-3.98233247]\n",
      " [-6.01842117]\n",
      " [-3.98233247]\n",
      " [-3.29520345]\n",
      " [-7.5745821 ]\n",
      " [-6.03440857]\n",
      " [-6.03440857]\n",
      " [-4.54441214]\n",
      " [-3.98231626]\n",
      " [-2.56802464]\n",
      " [-5.2493906 ]\n",
      " [-5.2875185 ]\n",
      " [-4.76967764]\n",
      " [-4.57140017]\n",
      " [-4.5470376 ]\n",
      " [-4.544662  ]\n",
      " [-4.54443598]\n",
      " [-4.54441452]\n",
      " [-4.54441261]\n",
      " [-4.54441261]\n",
      " [-4.54441261]\n",
      " [-5.52355623]\n",
      " [        nan]\n",
      " [-6.16976833]]\n",
      "[[-4.91566706]\n",
      " [-4.91566706]\n",
      " [-4.86712074]\n",
      " [ 1.56692231]\n",
      " [-0.50637865]\n",
      " [-2.00461411]\n",
      " [-4.0069046 ]\n",
      " [-2.03783536]\n",
      " [-4.20488739]\n",
      " [-6.24558592]\n",
      " [-0.51684797]\n",
      " [-0.99134386]\n",
      " [-0.36940491]\n",
      " [-1.15738297]\n",
      " [-5.18018198]\n",
      " [-0.06644011]\n",
      " [-2.49108529]\n",
      " [-3.39941716]\n",
      " [-2.73283482]\n",
      " [ 0.08859062]\n",
      " [ 1.71676719]\n",
      " [ 1.62343514]\n",
      " [-0.06927919]\n",
      " [-0.92039979]\n",
      " [-1.40028405]\n",
      " [-1.43345785]\n",
      " [-1.38280344]\n",
      " [-1.32348204]\n",
      " [-1.26558161]\n",
      " [-1.21234286]\n",
      " [-1.16578722]\n",
      " [-1.12684894]\n",
      " [-1.09549546]\n",
      " [-1.07100868]\n",
      " [-4.91631794]\n",
      " [        nan]\n",
      " [-4.43970203]]\n",
      "[[-1.5787096 ]\n",
      " [-1.5787096 ]\n",
      " [ 1.505077  ]\n",
      " [ 1.2463001 ]\n",
      " [-1.20790553]\n",
      " [-1.5788641 ]\n",
      " [ 2.40472364]\n",
      " [ 1.75864351]\n",
      " [ 1.27099454]\n",
      " [ 1.27099454]\n",
      " [ 1.8512851 ]\n",
      " [ 1.2463001 ]\n",
      " [ 3.01520872]\n",
      " [ 0.72729588]\n",
      " [ 0.03670979]\n",
      " [ 1.61990654]\n",
      " [ 2.38275528]\n",
      " [-0.31530249]\n",
      " [ 0.17709422]\n",
      " [ 1.6123451 ]\n",
      " [ 1.86326158]\n",
      " [ 2.17239571]\n",
      " [ 0.14705122]\n",
      " [ 1.38139093]\n",
      " [ 1.40896738]\n",
      " [ 1.42146671]\n",
      " [ 1.42940152]\n",
      " [ 1.43439472]\n",
      " [ 1.43749797]\n",
      " [ 1.43941104]\n",
      " [ 1.4405843 ]\n",
      " [ 1.44130123]\n",
      " [ 1.44173896]\n",
      " [ 1.44200528]\n",
      " [-1.58061111]\n",
      " [        nan]\n",
      " [-0.42325079]]\n",
      "[[-3.33929777]\n",
      " [-3.33929777]\n",
      " [-7.02353716]\n",
      " [-2.75402784]\n",
      " [-4.93387175]\n",
      " [-4.58681345]\n",
      " [-4.44295502]\n",
      " [-7.56223726]\n",
      " [-4.20138693]\n",
      " [-5.55675173]\n",
      " [-8.32719517]\n",
      " [-0.81304747]\n",
      " [-1.80931699]\n",
      " [-5.56882954]\n",
      " [-3.90329742]\n",
      " [-2.76804447]\n",
      " [-5.79037046]\n",
      " [-4.71156979]\n",
      " [-4.63686419]\n",
      " [-4.61419344]\n",
      " [-2.99478102]\n",
      " [-4.77573824]\n",
      " [-0.39986485]\n",
      " [-2.539011  ]\n",
      " [-2.82927132]\n",
      " [-2.85852957]\n",
      " [-2.84324455]\n",
      " [-2.829072  ]\n",
      " [-2.81855106]\n",
      " [-2.81050444]\n",
      " [-2.80422544]\n",
      " [-2.79931116]\n",
      " [-2.79547548]\n",
      " [-2.79249382]\n",
      " [-3.01244259]\n",
      " [        nan]\n",
      " [-2.42093372]]\n",
      "[[ 0.98426187]\n",
      " [ 0.98426187]\n",
      " [ 1.09526408]\n",
      " [ 1.19420302]\n",
      " [ 0.9629674 ]\n",
      " [ 0.74090707]\n",
      " [ 1.90041041]\n",
      " [-0.57808363]\n",
      " [-0.72643471]\n",
      " [ 0.82565975]\n",
      " [-0.57806623]\n",
      " [ 1.17113209]\n",
      " [-0.84145927]\n",
      " [ 1.55199623]\n",
      " [-1.55677748]\n",
      " [ 0.73718262]\n",
      " [ 1.66781259]\n",
      " [ 1.00964808]\n",
      " [-0.09126174]\n",
      " [ 1.57262635]\n",
      " [ 1.11131787]\n",
      " [ 0.07029045]\n",
      " [ 0.19901377]\n",
      " [ 2.93679333]\n",
      " [ 3.17100358]\n",
      " [ 3.25130463]\n",
      " [ 3.27868271]\n",
      " [ 3.28829646]\n",
      " [ 3.29176259]\n",
      " [ 3.29304051]\n",
      " [ 3.29352069]\n",
      " [ 3.29370332]\n",
      " [ 3.29377341]\n",
      " [ 3.29380012]\n",
      " [ 1.09526408]\n",
      " [        nan]\n",
      " [ 2.62595248]]\n",
      "[[ 4.27151394]\n",
      " [ 4.27151394]\n",
      " [ 3.93006754]\n",
      " [ 4.34764338]\n",
      " [ 3.47536469]\n",
      " [ 4.14478111]\n",
      " [ 1.97213304]\n",
      " [ 3.95328927]\n",
      " [ 1.01098943]\n",
      " [ 1.97213876]\n",
      " [ 1.02089596]\n",
      " [ 2.75856709]\n",
      " [ 2.44551349]\n",
      " [ 4.00940466]\n",
      " [ 2.61355758]\n",
      " [ 3.29924488]\n",
      " [ 4.34486008]\n",
      " [ 3.42371321]\n",
      " [ 2.86826277]\n",
      " [ 2.72850752]\n",
      " [ 3.81740499]\n",
      " [ 3.27294469]\n",
      " [ 2.56964731]\n",
      " [ 1.56830585]\n",
      " [ 1.84085   ]\n",
      " [ 2.13795233]\n",
      " [ 2.31729627]\n",
      " [ 2.34116173]\n",
      " [ 2.34485841]\n",
      " [ 2.34588599]\n",
      " [ 2.34669662]\n",
      " [ 2.34693193]\n",
      " [ 2.34688258]\n",
      " [ 2.34669399]\n",
      " [ 1.72319758]\n",
      " [        nan]\n",
      " [ 2.0671854 ]]\n",
      "[[-1.38398314]\n",
      " [-1.38398314]\n",
      " [-1.60304856]\n",
      " [-1.37804651]\n",
      " [ 1.57330966]\n",
      " [ 0.82116073]\n",
      " [-0.90987068]\n",
      " [-0.44143397]\n",
      " [-3.47426987]\n",
      " [ 0.17299789]\n",
      " [-0.90965229]\n",
      " [-0.90965039]\n",
      " [-2.96725702]\n",
      " [-1.37804556]\n",
      " [ 1.00158978]\n",
      " [-1.68924904]\n",
      " [-2.60853314]\n",
      " [ 2.11995506]\n",
      " [-1.20876503]\n",
      " [-2.81115723]\n",
      " [ 0.13351537]\n",
      " [-0.90965229]\n",
      " [-6.41008902]\n",
      " [-3.56166863]\n",
      " [-3.28960752]\n",
      " [-3.26215959]\n",
      " [-3.16760612]\n",
      " [-3.04721355]\n",
      " [-2.92802072]\n",
      " [-2.83057737]\n",
      " [-2.75209451]\n",
      " [-2.68209124]\n",
      " [-2.6133039 ]\n",
      " [-2.54236436]\n",
      " [-3.79982328]\n",
      " [        nan]\n",
      " [-1.28778744]]\n",
      "[[  1.80702019e+00]\n",
      " [  1.80702019e+00]\n",
      " [  1.08654499e-02]\n",
      " [  7.29095221e-01]\n",
      " [ -1.58739090e-03]\n",
      " [ -7.34472275e-03]\n",
      " [ -1.12421513e+00]\n",
      " [ -1.68337202e+00]\n",
      " [ -1.14000368e+00]\n",
      " [  7.35496521e-01]\n",
      " [  5.95895529e-01]\n",
      " [  9.21405554e-01]\n",
      " [ -1.43308330e+00]\n",
      " [  2.54259634e+00]\n",
      " [  1.31722879e+00]\n",
      " [ -5.98437786e-02]\n",
      " [  1.85479116e+00]\n",
      " [  1.00296307e+00]\n",
      " [  6.25059843e-01]\n",
      " [  1.85507774e+00]\n",
      " [  7.65820026e-01]\n",
      " [ -1.74538565e+00]\n",
      " [  1.09511018e-02]\n",
      " [  2.13278592e-01]\n",
      " [ -1.42987132e-01]\n",
      " [ -1.96673989e-01]\n",
      " [ -2.05835819e-01]\n",
      " [ -2.07652569e-01]\n",
      " [ -2.08166957e-01]\n",
      " [ -2.08382607e-01]\n",
      " [ -2.08495140e-01]\n",
      " [ -2.08558559e-01]\n",
      " [ -2.08595514e-01]\n",
      " [ -2.08616734e-01]\n",
      " [  1.86750722e+00]\n",
      " [             nan]\n",
      " [  2.61293197e+00]]\n",
      "[[ 1.55624962]\n",
      " [ 1.55624962]\n",
      " [-0.77576995]\n",
      " [ 1.28413725]\n",
      " [ 2.52990246]\n",
      " [ 2.52990246]\n",
      " [ 2.52990246]\n",
      " [ 1.38596487]\n",
      " [ 4.08754444]\n",
      " [ 4.52984715]\n",
      " [-0.74848151]\n",
      " [ 0.82027471]\n",
      " [ 1.81291068]\n",
      " [ 2.52990246]\n",
      " [ 0.06348395]\n",
      " [ 2.47724605]\n",
      " [ 0.02413213]\n",
      " [-2.18308735]\n",
      " [ 1.15886021]\n",
      " [-0.10360789]\n",
      " [-4.45939159]\n",
      " [ 0.59566188]\n",
      " [ 0.85923398]\n",
      " [ 2.20996523]\n",
      " [ 1.18420196]\n",
      " [ 1.11874664]\n",
      " [ 1.09105253]\n",
      " [ 1.07263029]\n",
      " [ 1.06027877]\n",
      " [ 1.05175686]\n",
      " [ 1.0454607 ]\n",
      " [ 1.04024804]\n",
      " [ 1.03528512]\n",
      " [ 1.02994084]\n",
      " [ 4.47339439]\n",
      " [        nan]\n",
      " [ 4.4263587 ]]\n",
      "[[ 0.47365475]\n",
      " [ 0.47365475]\n",
      " [-0.18870902]\n",
      " [ 0.47365642]\n",
      " [-0.35245371]\n",
      " [ 0.92586303]\n",
      " [-0.58455276]\n",
      " [-0.58455276]\n",
      " [-0.58455276]\n",
      " [-0.58455276]\n",
      " [-0.58443308]\n",
      " [-0.58455276]\n",
      " [-0.50478137]\n",
      " [ 0.50960064]\n",
      " [-1.92525113]\n",
      " [ 1.75256562]\n",
      " [ 0.70575547]\n",
      " [ 0.86400104]\n",
      " [-0.71044433]\n",
      " [ 0.83412099]\n",
      " [ 0.81195426]\n",
      " [ 0.06821704]\n",
      " [ 0.84945083]\n",
      " [ 1.5664227 ]\n",
      " [ 1.00452256]\n",
      " [ 0.81612277]\n",
      " [ 0.34733081]\n",
      " [-0.06177163]\n",
      " [-0.1945045 ]\n",
      " [-0.22231936]\n",
      " [-0.22754645]\n",
      " [-0.22850776]\n",
      " [-0.22868371]\n",
      " [-0.22871566]\n",
      " [-0.58362198]\n",
      " [        nan]\n",
      " [-0.3919872 ]]\n",
      "[[ 1.6602447 ]\n",
      " [ 1.6602447 ]\n",
      " [ 1.24254417]\n",
      " [ 0.78638989]\n",
      " [ 3.8038063 ]\n",
      " [ 3.8069849 ]\n",
      " [ 2.77939034]\n",
      " [ 2.08754182]\n",
      " [ 2.31711888]\n",
      " [ 2.76841021]\n",
      " [ 2.60675502]\n",
      " [-1.20086551]\n",
      " [ 1.83391547]\n",
      " [ 4.48640966]\n",
      " [ 1.80950332]\n",
      " [ 0.32960397]\n",
      " [ 3.60931563]\n",
      " [ 2.62724829]\n",
      " [-2.01823139]\n",
      " [ 1.97866297]\n",
      " [ 2.39968824]\n",
      " [ 0.52141291]\n",
      " [ 2.08213139]\n",
      " [ 2.96851635]\n",
      " [ 2.79724145]\n",
      " [ 2.76904154]\n",
      " [ 2.76820254]\n",
      " [ 2.76832986]\n",
      " [ 2.76838541]\n",
      " [ 2.76840258]\n",
      " [ 2.76840758]\n",
      " [ 2.76840925]\n",
      " [ 2.76840949]\n",
      " [ 2.76840973]\n",
      " [ 2.84466362]\n",
      " [        nan]\n",
      " [ 4.50687122]]\n",
      "[[-3.13770151]\n",
      " [-3.13770151]\n",
      " [-5.69571018]\n",
      " [-4.77321482]\n",
      " [-6.56152964]\n",
      " [-4.20813417]\n",
      " [-6.56169271]\n",
      " [-7.21380711]\n",
      " [-8.19927979]\n",
      " [-6.37021685]\n",
      " [-5.58146429]\n",
      " [-6.25620794]\n",
      " [-6.90834951]\n",
      " [-4.89306355]\n",
      " [-0.50727451]\n",
      " [-4.320189  ]\n",
      " [-6.60239363]\n",
      " [-0.37118363]\n",
      " [-6.02381992]\n",
      " [-6.60239363]\n",
      " [-6.60239363]\n",
      " [-6.75464249]\n",
      " [-6.16339922]\n",
      " [-5.04031992]\n",
      " [-5.27389765]\n",
      " [-5.22481155]\n",
      " [-5.10958672]\n",
      " [-4.99062872]\n",
      " [-4.89706373]\n",
      " [-4.83776474]\n",
      " [-4.805161  ]\n",
      " [-4.78862286]\n",
      " [-4.78057623]\n",
      " [-4.77674103]\n",
      " [-3.00943613]\n",
      " [        nan]\n",
      " [-5.90953445]]\n",
      "[[ -5.95851755]\n",
      " [ -5.95851755]\n",
      " [ -8.74691868]\n",
      " [ -9.85147476]\n",
      " [ -5.86951256]\n",
      " [ -3.18146467]\n",
      " [ -3.70015335]\n",
      " [ -5.59360981]\n",
      " [ -3.77981186]\n",
      " [ -3.17064953]\n",
      " [ -7.32068253]\n",
      " [ -9.16162205]\n",
      " [-10.75039768]\n",
      " [ -3.31526756]\n",
      " [ -5.63482475]\n",
      " [ -4.65948725]\n",
      " [ -9.96743679]\n",
      " [ -5.83410215]\n",
      " [ -5.95806408]\n",
      " [ -7.75240612]\n",
      " [-11.56308937]\n",
      " [-10.67183399]\n",
      " [-11.57304955]\n",
      " [ -5.80278063]\n",
      " [ -6.95436668]\n",
      " [ -6.88346767]\n",
      " [ -6.14397144]\n",
      " [ -4.4936614 ]\n",
      " [ -4.26579428]\n",
      " [ -4.21956825]\n",
      " [ -4.19921112]\n",
      " [ -4.19002628]\n",
      " [ -4.18598461]\n",
      " [ -4.18422985]\n",
      " [ -4.84679413]\n",
      " [         nan]\n",
      " [ -4.94085169]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.074296  ]\n",
      " [-5.074296  ]\n",
      " [-3.02967358]\n",
      " [-2.13392353]\n",
      " [-2.84698677]\n",
      " [ 0.67388892]\n",
      " [-2.0489676 ]\n",
      " [-1.36997414]\n",
      " [-2.3342824 ]\n",
      " [-2.33266473]\n",
      " [-1.37561643]\n",
      " [-2.11497116]\n",
      " [-1.81299663]\n",
      " [-4.29397631]\n",
      " [-4.40484667]\n",
      " [-2.30556965]\n",
      " [-1.96519971]\n",
      " [-3.50010252]\n",
      " [-2.90439034]\n",
      " [-3.04781985]\n",
      " [ 0.05861044]\n",
      " [ 0.02547789]\n",
      " [-1.94887602]\n",
      " [-1.68091345]\n",
      " [-0.26355541]\n",
      " [-0.08650327]\n",
      " [-0.07810295]\n",
      " [-0.07740569]\n",
      " [-0.07697594]\n",
      " [-0.07638073]\n",
      " [-0.0755105 ]\n",
      " [-0.07425869]\n",
      " [-0.07251275]\n",
      " [-0.07018256]\n",
      " [-2.52994633]\n",
      " [        nan]\n",
      " [-1.33698237]]\n",
      "[[ 3.53662801]\n",
      " [ 3.53662801]\n",
      " [ 3.54958797]\n",
      " [ 3.55811381]\n",
      " [-0.37581137]\n",
      " [ 0.20417711]\n",
      " [ 3.10276389]\n",
      " [ 4.55576563]\n",
      " [ 5.88820934]\n",
      " [ 2.24755478]\n",
      " [ 3.23854327]\n",
      " [-0.39642182]\n",
      " [ 3.07685614]\n",
      " [ 3.0677979 ]\n",
      " [-0.89539075]\n",
      " [ 2.27358007]\n",
      " [ 3.80914044]\n",
      " [ 1.83593893]\n",
      " [ 2.83809066]\n",
      " [ 2.83795547]\n",
      " [ 2.93325996]\n",
      " [ 0.41468164]\n",
      " [ 0.61980319]\n",
      " [ 3.11728692]\n",
      " [ 3.07984543]\n",
      " [ 3.06858563]\n",
      " [ 3.06219554]\n",
      " [ 3.05984545]\n",
      " [ 3.05902743]\n",
      " [ 3.05872369]\n",
      " [ 3.05864525]\n",
      " [ 3.05862498]\n",
      " [ 3.05861974]\n",
      " [ 3.05861831]\n",
      " [ 3.00959945]\n",
      " [        nan]\n",
      " [ 3.01702356]]\n",
      "[[-6.12870026]\n",
      " [-6.12870026]\n",
      " [-5.3598609 ]\n",
      " [-4.04059076]\n",
      " [-6.1513381 ]\n",
      " [-6.14695978]\n",
      " [-6.40283537]\n",
      " [-6.19035244]\n",
      " [-6.95854139]\n",
      " [-6.18382406]\n",
      " [-5.42715502]\n",
      " [-5.80126953]\n",
      " [-7.17436743]\n",
      " [-6.84060574]\n",
      " [-6.4946332 ]\n",
      " [-5.59453535]\n",
      " [-5.61223364]\n",
      " [-6.26577568]\n",
      " [-7.21434546]\n",
      " [-5.66908312]\n",
      " [-5.50793028]\n",
      " [-5.17743921]\n",
      " [-2.22935271]\n",
      " [-5.63771057]\n",
      " [-6.02314711]\n",
      " [-6.14883518]\n",
      " [-6.15107918]\n",
      " [-6.15109444]\n",
      " [-6.1510725 ]\n",
      " [-6.15104771]\n",
      " [-6.15102053]\n",
      " [-6.15099096]\n",
      " [-6.15095854]\n",
      " [-6.15092993]\n",
      " [-5.01682758]\n",
      " [        nan]\n",
      " [-5.20490742]]\n",
      "[[ 0.00610626]\n",
      " [ 0.00610626]\n",
      " [ 0.0061031 ]\n",
      " [ 0.0061031 ]\n",
      " [ 0.0061031 ]\n",
      " [ 0.0061031 ]\n",
      " [ 0.38899183]\n",
      " [ 1.3636564 ]\n",
      " [ 0.76124448]\n",
      " [ 0.76124448]\n",
      " [ 1.29461432]\n",
      " [ 1.85723686]\n",
      " [ 1.84615493]\n",
      " [ 0.0061031 ]\n",
      " [ 2.0808084 ]\n",
      " [ 0.41067874]\n",
      " [-0.37964606]\n",
      " [ 0.11835933]\n",
      " [-0.75262344]\n",
      " [ 0.37800199]\n",
      " [ 0.0061031 ]\n",
      " [-0.3822279 ]\n",
      " [-0.63319993]\n",
      " [ 0.26702613]\n",
      " [ 0.56199574]\n",
      " [ 0.58268452]\n",
      " [ 0.61145318]\n",
      " [ 0.65488553]\n",
      " [ 0.71156085]\n",
      " [ 0.77291906]\n",
      " [ 0.82726681]\n",
      " [ 0.86748981]\n",
      " [ 0.89346993]\n",
      " [ 0.90880799]\n",
      " [ 0.01125926]\n",
      " [        nan]\n",
      " [-0.2869699 ]]\n",
      "[[-0.58343649]\n",
      " [-0.58343649]\n",
      " [-0.36639261]\n",
      " [-1.28253579]\n",
      " [ 0.60031223]\n",
      " [ 0.60218763]\n",
      " [-2.74536395]\n",
      " [-3.51306486]\n",
      " [-2.81053495]\n",
      " [-2.77978182]\n",
      " [-1.92315936]\n",
      " [ 0.60031223]\n",
      " [-3.81863189]\n",
      " [ 0.60098577]\n",
      " [ 1.47774458]\n",
      " [-1.75401115]\n",
      " [ 0.16844392]\n",
      " [ 0.33182216]\n",
      " [-2.74203944]\n",
      " [ 0.64810443]\n",
      " [ 0.04459608]\n",
      " [ 1.57262611]\n",
      " [-3.26892042]\n",
      " [-1.52151752]\n",
      " [ 0.7913878 ]\n",
      " [ 1.03391981]\n",
      " [ 1.19271469]\n",
      " [ 1.29167151]\n",
      " [ 1.34835768]\n",
      " [ 1.38326836]\n",
      " [ 1.40482473]\n",
      " [ 1.41853952]\n",
      " [ 1.42777348]\n",
      " [ 1.43450165]\n",
      " [-1.06044936]\n",
      " [        nan]\n",
      " [ 0.87601471]]\n",
      "[[ 2.76428127]\n",
      " [ 2.76428127]\n",
      " [ 4.42268085]\n",
      " [ 4.8316083 ]\n",
      " [ 3.57950306]\n",
      " [ 7.54038954]\n",
      " [ 4.44908667]\n",
      " [ 5.42664909]\n",
      " [ 4.64274502]\n",
      " [ 4.64274502]\n",
      " [ 5.04003572]\n",
      " [ 2.27547455]\n",
      " [ 5.10355949]\n",
      " [ 6.07553482]\n",
      " [-0.45553339]\n",
      " [ 4.59858704]\n",
      " [ 3.66896725]\n",
      " [ 4.82332516]\n",
      " [ 5.63696098]\n",
      " [ 3.29026937]\n",
      " [ 2.64781618]\n",
      " [ 3.91922522]\n",
      " [ 4.65243769]\n",
      " [ 6.25991392]\n",
      " [ 8.14799213]\n",
      " [ 7.93338394]\n",
      " [ 6.87754917]\n",
      " [ 5.74609852]\n",
      " [ 5.01023579]\n",
      " [ 4.61275816]\n",
      " [ 4.45097923]\n",
      " [ 4.39192152]\n",
      " [ 4.36919165]\n",
      " [ 4.35907316]\n",
      " [ 4.63238144]\n",
      " [        nan]\n",
      " [ 3.76150274]]\n",
      "[[-0.73860538]\n",
      " [-0.73860538]\n",
      " [-1.1648525 ]\n",
      " [-0.63084376]\n",
      " [ 1.87186563]\n",
      " [ 1.6647023 ]\n",
      " [ 0.36113608]\n",
      " [-3.40235376]\n",
      " [-1.29793036]\n",
      " [ 1.29325116]\n",
      " [-1.03731072]\n",
      " [-1.03405988]\n",
      " [-2.3483367 ]\n",
      " [ 1.61174703]\n",
      " [ 0.88857853]\n",
      " [ 1.39696479]\n",
      " [ 0.32702339]\n",
      " [ 0.53267241]\n",
      " [ 1.68150508]\n",
      " [ 0.08512437]\n",
      " [-1.17134416]\n",
      " [ 0.63504195]\n",
      " [-0.28287053]\n",
      " [-1.15221059]\n",
      " [-1.2257086 ]\n",
      " [-1.23678529]\n",
      " [-1.24185598]\n",
      " [-1.24461067]\n",
      " [-1.24501526]\n",
      " [-1.24533451]\n",
      " [-1.24560845]\n",
      " [-1.24585521]\n",
      " [-1.24608314]\n",
      " [-1.24629629]\n",
      " [ 0.85705602]\n",
      " [        nan]\n",
      " [ 0.51388896]]\n",
      "[[-0.19340801]\n",
      " [-0.19340801]\n",
      " [-6.8749609 ]\n",
      " [-1.60250592]\n",
      " [-5.82569122]\n",
      " [-2.76940036]\n",
      " [-1.45435882]\n",
      " [-5.30134296]\n",
      " [-6.00578785]\n",
      " [-2.29946923]\n",
      " [-5.0977087 ]\n",
      " [-3.98076653]\n",
      " [-5.59836197]\n",
      " [-3.09384799]\n",
      " [-4.33745956]\n",
      " [-3.83619332]\n",
      " [ 0.10591626]\n",
      " [-1.41271806]\n",
      " [-1.96430707]\n",
      " [ 0.10591626]\n",
      " [-5.72607994]\n",
      " [-3.94466281]\n",
      " [-0.43497014]\n",
      " [-1.45272732]\n",
      " [-1.43469048]\n",
      " [-1.44625068]\n",
      " [-1.50071359]\n",
      " [-1.54950929]\n",
      " [-1.56065583]\n",
      " [-1.55785394]\n",
      " [-1.55372596]\n",
      " [-1.55082035]\n",
      " [-1.54903221]\n",
      " [-1.54794526]\n",
      " [-1.12975955]\n",
      " [        nan]\n",
      " [-1.30105972]]\n",
      "[[-4.04094601]\n",
      " [-4.04094601]\n",
      " [-3.57987332]\n",
      " [-2.73994255]\n",
      " [-1.29459834]\n",
      " [-1.59597921]\n",
      " [-3.41517711]\n",
      " [-2.96536231]\n",
      " [-3.02327323]\n",
      " [-3.96382356]\n",
      " [-1.67876124]\n",
      " [-3.15695286]\n",
      " [-3.01185107]\n",
      " [-2.59967566]\n",
      " [-3.27781892]\n",
      " [-3.664639  ]\n",
      " [-2.71513438]\n",
      " [-0.43257976]\n",
      " [-2.69212818]\n",
      " [-1.74949837]\n",
      " [-0.78247428]\n",
      " [-3.22623205]\n",
      " [-3.5630765 ]\n",
      " [-1.91387784]\n",
      " [-1.00968313]\n",
      " [-0.56538415]\n",
      " [-0.29649138]\n",
      " [-0.25917816]\n",
      " [-0.32308316]\n",
      " [-0.37973309]\n",
      " [-0.41130018]\n",
      " [-0.42757893]\n",
      " [-0.43666649]\n",
      " [-0.44249249]\n",
      " [-2.50364161]\n",
      " [        nan]\n",
      " [-2.55140591]]\n",
      "[[ 5.84316778]\n",
      " [ 5.84316778]\n",
      " [ 5.85819387]\n",
      " [ 4.93167353]\n",
      " [ 1.3946023 ]\n",
      " [ 1.4934212 ]\n",
      " [ 2.55013633]\n",
      " [ 2.20419788]\n",
      " [ 1.2501533 ]\n",
      " [ 0.23452333]\n",
      " [ 4.27799416]\n",
      " [ 3.25071692]\n",
      " [ 6.06481695]\n",
      " [ 2.84014869]\n",
      " [-0.04617181]\n",
      " [ 5.10225821]\n",
      " [ 5.31642008]\n",
      " [ 0.49979749]\n",
      " [ 1.3435905 ]\n",
      " [ 2.47567725]\n",
      " [ 3.34528899]\n",
      " [ 2.31331515]\n",
      " [ 2.21200633]\n",
      " [ 2.74854088]\n",
      " [ 2.67626715]\n",
      " [ 2.49905849]\n",
      " [ 2.2751646 ]\n",
      " [ 2.03327298]\n",
      " [ 1.83224297]\n",
      " [ 1.6779654 ]\n",
      " [ 1.54841661]\n",
      " [ 1.43973684]\n",
      " [ 1.3503381 ]\n",
      " [ 1.28190804]\n",
      " [ 3.29916668]\n",
      " [        nan]\n",
      " [-0.99631399]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     avg_Q, best_action = Q_learning()\n",
    "# #     best_action = pd.DataFrame(best_action)\n",
    "# #     return avg_Q, best_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_action = np.transpose(best_action)\n",
    "# best_action[0].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above .. \n",
    "\n",
    "the actions order (from highest to lowest) \n",
    "1. Action # 7 (Thank you printed with labels)\n",
    "2. Action # 6 \n",
    "3. Action # 4 (Blank cards that fold into thirds with labels)\n",
    "4. Action # 1 \n",
    "\n",
    "This differs a bit the order of Stanford paper in two points:\n",
    "1. Their starting index is 1 .. while Python's is zeros based .. this is why I'm adding 1 in the index .. \n",
    "2. I'm working on just a sample (with a size less than their size) this is why there are some actions I even didn't have as an output (i.e. action # 11) !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "\n",
    "an enhancement for this implementation is to change the states to be the whole doner state instead of just RFM ..\n",
    "\n",
    "https://github.com/EAboelhamd/kdd98-1/blob/master/notebooks/exploratory.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do I apply experience replay .. \n",
    "\n",
    "The algorithm is mentioned here .. \n",
    "\n",
    "https://www.intelnervana.com/demystifying-deep-reinforcement-learning/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
