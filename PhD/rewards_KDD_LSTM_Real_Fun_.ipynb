{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "Main Goals:\n",
    "\n",
    "1. Identify the recipients that will engage with the campaign.\n",
    "2. Maximise the campaign’s revenue.\n",
    "\n",
    "\n",
    "Comments\n",
    "\n",
    "- The dataset contains only 5% of donors.\n",
    "- The donations are usually smaller than $20.\n",
    "- This data is quite noisy, high dimensional.\n",
    "- There is an inverse relationship between the probability to donate and the amount donated.\n",
    "\n",
    "\n",
    "Link for dataset and some analysis ==> \n",
    "\n",
    "https://github.com/rebordao/kdd98cup\n",
    "\n",
    "https://github.com/bobbyantonio/KDD98/blob/master/CleanData.py\n",
    "\n",
    "- Github solutions ==>\n",
    "https://github.com/rebordao/kdd98cup\n",
    "\n",
    "\n",
    "- Siraj notebook for a better data visualization:\n",
    "\n",
    "https://www.youtube.com/watch?v=yQsOFWqpjkE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "from sklearn.model_selection import train_test_split\n",
    "from array_split import array_split, shape_split\n",
    "from sklearn import preprocessing\n",
    "# from sknn.mlp import Regressor, Layer\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "## plotting .. \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "## warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    list_of_lists = []\n",
    "\n",
    "    ## works correctly but takes too much running time ..\n",
    "    with open('cup98LRN.txt', 'r') as f:# open the file for reading\n",
    "        df = []\n",
    "        for row_num, line in enumerate(f):\n",
    "            # Remove the new line at the end and then split the string based on\n",
    "            # tabs. This creates a python list of the values.\n",
    "            values = line.strip().split(',')\n",
    "            if row_num == 0: # first line is the header\n",
    "                 header = values\n",
    "            else:\n",
    "                df.append([v for v in values])\n",
    "\n",
    "        df = pd.DataFrame(df)\n",
    "        df.columns = header\n",
    "        df.drop(df.index[0], inplace=True)\n",
    "        \n",
    "        df = df[0:50]  ## to save time .. I gonna work on only 100 records ..\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I have to run it over all the data not just 100 records\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(df['ADATE_3']) # 3 empty cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9602'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ADATE_7'].values.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only ADATE is valid .. \n",
    "\n",
    "RFA ==> only 3 characters not 4\n",
    "\n",
    "RAMNT_3, RDATE ==> are empty !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADATE_2</th>\n",
       "      <th>ADATE_3</th>\n",
       "      <th>ADATE_4</th>\n",
       "      <th>ADATE_5</th>\n",
       "      <th>ADATE_6</th>\n",
       "      <th>ADATE_7</th>\n",
       "      <th>ADATE_8</th>\n",
       "      <th>ADATE_9</th>\n",
       "      <th>ADATE_10</th>\n",
       "      <th>ADATE_11</th>\n",
       "      <th>...</th>\n",
       "      <th>ADATE_16</th>\n",
       "      <th>ADATE_16</th>\n",
       "      <th>ADATE_17</th>\n",
       "      <th>ADATE_18</th>\n",
       "      <th>ADATE_19</th>\n",
       "      <th>ADATE_20</th>\n",
       "      <th>ADATE_12</th>\n",
       "      <th>ADATE_22</th>\n",
       "      <th>ADATE_23</th>\n",
       "      <th>ADATE_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9706</td>\n",
       "      <td>9606</td>\n",
       "      <td>9604</td>\n",
       "      <td>9604</td>\n",
       "      <td>9603</td>\n",
       "      <td>9602</td>\n",
       "      <td>9601</td>\n",
       "      <td>9511</td>\n",
       "      <td>9510</td>\n",
       "      <td>9510</td>\n",
       "      <td>...</td>\n",
       "      <td>9503</td>\n",
       "      <td>9503</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9411</td>\n",
       "      <td>9411</td>\n",
       "      <td>9509</td>\n",
       "      <td>9409</td>\n",
       "      <td></td>\n",
       "      <td>9406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9706</td>\n",
       "      <td>9606</td>\n",
       "      <td>9604</td>\n",
       "      <td>9604</td>\n",
       "      <td>9603</td>\n",
       "      <td>9602</td>\n",
       "      <td>9601</td>\n",
       "      <td>9511</td>\n",
       "      <td></td>\n",
       "      <td>9510</td>\n",
       "      <td>...</td>\n",
       "      <td>9503</td>\n",
       "      <td>9503</td>\n",
       "      <td></td>\n",
       "      <td>9501</td>\n",
       "      <td>9411</td>\n",
       "      <td></td>\n",
       "      <td>9508</td>\n",
       "      <td>9409</td>\n",
       "      <td>9407</td>\n",
       "      <td>9406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9706</td>\n",
       "      <td>9606</td>\n",
       "      <td>9604</td>\n",
       "      <td>9604</td>\n",
       "      <td>9603</td>\n",
       "      <td>9602</td>\n",
       "      <td>9601</td>\n",
       "      <td>9511</td>\n",
       "      <td></td>\n",
       "      <td>9510</td>\n",
       "      <td>...</td>\n",
       "      <td>9503</td>\n",
       "      <td>9503</td>\n",
       "      <td>9502</td>\n",
       "      <td>9501</td>\n",
       "      <td>9411</td>\n",
       "      <td>9411</td>\n",
       "      <td>9508</td>\n",
       "      <td>9409</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9706</td>\n",
       "      <td>9606</td>\n",
       "      <td>9604</td>\n",
       "      <td>9604</td>\n",
       "      <td>9603</td>\n",
       "      <td>9512</td>\n",
       "      <td>9601</td>\n",
       "      <td>9511</td>\n",
       "      <td>9510</td>\n",
       "      <td>9509</td>\n",
       "      <td>...</td>\n",
       "      <td>9503</td>\n",
       "      <td>9503</td>\n",
       "      <td>9502</td>\n",
       "      <td>9412</td>\n",
       "      <td>9411</td>\n",
       "      <td>9411</td>\n",
       "      <td>9508</td>\n",
       "      <td>9506</td>\n",
       "      <td>9407</td>\n",
       "      <td>9406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9706</td>\n",
       "      <td>9606</td>\n",
       "      <td>9604</td>\n",
       "      <td>9604</td>\n",
       "      <td>9603</td>\n",
       "      <td>9602</td>\n",
       "      <td>9601</td>\n",
       "      <td>9511</td>\n",
       "      <td>9510</td>\n",
       "      <td>9510</td>\n",
       "      <td>...</td>\n",
       "      <td>9503</td>\n",
       "      <td>9503</td>\n",
       "      <td>9502</td>\n",
       "      <td>9501</td>\n",
       "      <td>9411</td>\n",
       "      <td>9411</td>\n",
       "      <td>9509</td>\n",
       "      <td>9409</td>\n",
       "      <td></td>\n",
       "      <td>9406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ADATE_2 ADATE_3 ADATE_4 ADATE_5 ADATE_6 ADATE_7 ADATE_8 ADATE_9 ADATE_10  \\\n",
       "1    9706    9606    9604    9604    9603    9602    9601    9511     9510   \n",
       "2    9706    9606    9604    9604    9603    9602    9601    9511            \n",
       "3    9706    9606    9604    9604    9603    9602    9601    9511            \n",
       "4    9706    9606    9604    9604    9603    9512    9601    9511     9510   \n",
       "5    9706    9606    9604    9604    9603    9602    9601    9511     9510   \n",
       "\n",
       "  ADATE_11   ...    ADATE_16 ADATE_16 ADATE_17 ADATE_18 ADATE_19 ADATE_20  \\\n",
       "1     9510   ...        9503     9503                       9411     9411   \n",
       "2     9510   ...        9503     9503              9501     9411            \n",
       "3     9510   ...        9503     9503     9502     9501     9411     9411   \n",
       "4     9509   ...        9503     9503     9502     9412     9411     9411   \n",
       "5     9510   ...        9503     9503     9502     9501     9411     9411   \n",
       "\n",
       "  ADATE_12 ADATE_22 ADATE_23 ADATE_24  \n",
       "1     9509     9409              9406  \n",
       "2     9508     9409     9407     9406  \n",
       "3     9508     9409                    \n",
       "4     9508     9506     9407     9406  \n",
       "5     9509     9409              9406  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_data = ['ADATE_2', 'ADATE_3', 'ADATE_4', 'ADATE_5', 'ADATE_6', 'ADATE_7', 'ADATE_8', \n",
    "            'ADATE_9', 'ADATE_10', 'ADATE_11', 'ADATE_12', 'ADATE_13', 'ADATE_14', 'ADATE_15',\n",
    "            'ADATE_16', 'ADATE_16', 'ADATE_17', 'ADATE_18', 'ADATE_19', 'ADATE_20', 'ADATE_12',\n",
    "            'ADATE_22', 'ADATE_23', 'ADATE_24']\n",
    "df[date_data].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06</td>\n",
       "      <td>06</td>\n",
       "      <td>04</td>\n",
       "      <td>04</td>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>03</td>\n",
       "      <td>03</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>09</td>\n",
       "      <td>09</td>\n",
       "      <td></td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06</td>\n",
       "      <td>06</td>\n",
       "      <td>04</td>\n",
       "      <td>04</td>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>03</td>\n",
       "      <td>03</td>\n",
       "      <td></td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>08</td>\n",
       "      <td>09</td>\n",
       "      <td>07</td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06</td>\n",
       "      <td>06</td>\n",
       "      <td>04</td>\n",
       "      <td>04</td>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>03</td>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>08</td>\n",
       "      <td>09</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06</td>\n",
       "      <td>06</td>\n",
       "      <td>04</td>\n",
       "      <td>04</td>\n",
       "      <td>03</td>\n",
       "      <td>12</td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>09</td>\n",
       "      <td>...</td>\n",
       "      <td>03</td>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>08</td>\n",
       "      <td>06</td>\n",
       "      <td>07</td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06</td>\n",
       "      <td>06</td>\n",
       "      <td>04</td>\n",
       "      <td>04</td>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>03</td>\n",
       "      <td>03</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>09</td>\n",
       "      <td>09</td>\n",
       "      <td></td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9  ...  14  15  16  17  18  19  20  21  \\\n",
       "0  06  06  04  04  03  02  01  11  10  10 ...  03  03          11  11  09  09   \n",
       "1  06  06  04  04  03  02  01  11      10 ...  03  03      01  11      08  09   \n",
       "2  06  06  04  04  03  02  01  11      10 ...  03  03  02  01  11  11  08  09   \n",
       "3  06  06  04  04  03  12  01  11  10  09 ...  03  03  02  12  11  11  08  06   \n",
       "4  06  06  04  04  03  02  01  11  10  10 ...  03  03  02  01  11  11  09  09   \n",
       "\n",
       "   22  23  \n",
       "0      06  \n",
       "1  07  06  \n",
       "2          \n",
       "3  07  06  \n",
       "4      06  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = []\n",
    "temp = np.transpose(df[date_data])\n",
    "\n",
    "for j in xrange(len(temp)):\n",
    "    for i in xrange(np.shape(df)[0]):\n",
    "         t.append(temp.iloc[j].iloc[i][2:])\n",
    "\n",
    "np.shape(t) ## correct ! .. but make sure that the step size is 23 ! i.e. every 23 step .. corresponds to new ADATE \n",
    "actions = np.reshape(t, [24, 50])\n",
    "actions = pd.DataFrame(np.transpose(actions))\n",
    "actions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration:\n",
    "\n",
    "http://beyondvalence.blogspot.com.eg/2014/05/kdd-cup-profit-optimization-in-r-part-1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_explore():\n",
    "    df = load_data()\n",
    "    print df.TARGET_B.value_counts().plot(x=None, y=None, kind = 'pie', autopct='%1.1f%%')\n",
    "    \n",
    "    # % of donors\n",
    "    print 'Percentage of donors: %s' % (100.0 * sum(df.TARGET_B.astype('float'))/df.shape[0]) #about only 5% of the samples are doners .. \n",
    "    plt.hist(df.TARGET_D.value_counts(), bins = 7)   \n",
    "    plt.plot(df[df.TARGET_D > 0].TARGET_D) #Histogram is not the best choice .. let's try another plot .. \n",
    "    \n",
    "    # % of donors\n",
    "    print 'Percentage of donors: %s' % (100.0 * sum(df.TARGET_D.astype('float'))/df.shape[0])\n",
    "    #about 79% of the continous predictor are doners .. are there any donation amounts of zero ?!\n",
    "    print df.TARGET_D.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender data imputation ..\n",
    "It's very strange to have gender rather than M and F !! .. \n",
    "\n",
    "Let's impute any other value with the mode of this variable .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_impute():\n",
    "    df = load_data()\n",
    "    df['GENDER'] = np.where(df['GENDER'] == 'C', df['GENDER'].mode(), df['GENDER'])\n",
    "    df['GENDER'] = np.where(df['GENDER'] == 'U', df['GENDER'].mode(), df['GENDER'])\n",
    "    df['GENDER'] = np.where(df['GENDER'] == 'J', df['GENDER'].mode(), df['GENDER'])\n",
    "    df['GENDER'] = np.where(df['GENDER'] == 'A', df['GENDER'].mode(), df['GENDER'])\n",
    "    df['GENDER'] = np.where(df['GENDER'] == ' ', df['GENDER'].mode(), df['GENDER'])\n",
    "    \n",
    "#     print df['GENDER'].unique()\n",
    "    \n",
    "    ## how donations are distributed per gender\n",
    "    df['GENDER'].value_counts().plot(kind='barh', stacked=True, fontsize=7, figsize=[9,8], colormap='gist_ncar')\n",
    "    plt.title('donations are distributed among age groups', fontsize=14, color='black') \n",
    "    plt.xlabel('Number of doners', fontsize=14, color='black') \n",
    "    plt.ylabel('Gender of doner', fontsize=14, color='black') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing:\n",
    "\n",
    "1. Gets some redundant variables .. by calculating the correlation between all the variables .. \n",
    "those of high correlation coeffecient are redundant .. \n",
    "\n",
    "__NOTE:__\n",
    "In this implementation .. \n",
    "\n",
    "https://github.com/EAboelhamd/kdd98cup/blob/master/donors.py\n",
    "\n",
    "They tried to figure out redundant variables to remove them .. to be able to decrease the dimentionality of the problem .. however, in my case, there is no need to do .. as I'm gonna implement deep learning not a shallow solution .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preperation():\n",
    "    df = load_data()\n",
    "    df = df[df.columns.difference(['TARGET_B'])]\n",
    "    data = ['TARGET_D', 'ODATEDW','OSOURCE','TCODE','STATE','ZIP','MAILCODE','PVASTATE','DOB','NOEXCH','RECINHSE','RECP3','RECPGVG','RECSWEEP','MDMAUD','DOMAIN','CLUSTER','AGE','AGEFLAG','HOMEOWNR','CHILD03','CHILD07','CHILD12',\n",
    "      'CHILD18','NUMCHLD','INCOME','GENDER','WEALTH1','HIT','MBCRAFT','MBGARDEN','MBBOOKS','MBCOLECT','MAGFAML','MAGFEM','MAGMALE',\n",
    "      'PUBGARDN','PUBCULIN','PUBHLTH','PUBDOITY','PUBNEWFN','PUBPHOTO','PUBOPP','DATASRCE','MALEMILI','MALEVET','VIETVETS','WWIIVETS','LOCALGOV','STATEGOV','FEDGOV','SOLP3','SOLIH',\n",
    "      'MAJOR','WEALTH2','GEOCODE','COLLECT1','VETERANS','BIBLE','CATLG','HOMEE','PETS','CDPLAY','STEREO','PCOWNERS','PHOTO','CRAFTS','FISHER','GARDENIN','BOATS','WALKER','KIDSTUFF','CARDS','PLATES','LIFESRC','PEPSTRFL','POP901','POP902','POP903','POP90C1','POP90C2','POP90C3','POP90C4','POP90C5','ETH1','ETH2','ETH3','ETH4','ETH5','ETH6','ETH7','ETH8','ETH9','ETH10','ETH11','ETH12','ETH13',\n",
    "      'ETH14','ETH15','ETH16','AGE901','AGE902','AGE903','AGE904','AGE905','AGE906','AGE907','CHIL1','CHIL2','CHIL3','AGEC1','AGEC2','AGEC3','AGEC4','AGEC5','AGEC6','AGEC7','CHILC1','CHILC2','CHILC3','CHILC4','CHILC5','HHAGE1','HHAGE2','HHAGE3','HHN1','HHN2','HHN3','HHN4','HHN5','HHN6','MARR1','MARR2','MARR3','MARR4','HHP1','HHP2','DW1','DW2','DW3','DW4','DW5','DW6','DW7','DW8','DW9','HV1','HV2','HV3','HV4','HU1','HU2','HU3','HU4','HU5','HHD1',\n",
    "      'HHD2','HHD3','HHD4','HHD5','HHD6','HHD7','HHD8','HHD9','HHD10','HHD11','HHD12','ETHC1','ETHC2','ETHC3','ETHC4','ETHC5','ETHC6','HVP1','HVP2','HVP3','HVP4',\n",
    "      'HVP5','HVP6','HUR1','HUR2','RHP1','RHP2','RHP3','RHP4','HUPA1','HUPA2','HUPA3','HUPA4','HUPA5','HUPA6',\n",
    "      'HUPA7','RP1','RP2', 'RP3','RP4','MSA','ADI','DMA','IC1','IC2','IC3','IC4','IC5','IC6','IC7','IC8','IC9','IC10','IC11','IC12','IC13','IC14','IC15','IC16','IC17','IC18','IC19','IC20','IC21','IC22','IC23','HHAS1','HHAS2','HHAS3','HHAS4','MC1','MC2','MC3',\n",
    "      'TPE1','TPE2','TPE3','TPE4','TPE5','TPE6','TPE7','TPE8','TPE9','PEC1','PEC2','TPE10','TPE11','TPE12','TPE13','LFC1','LFC2','LFC3','LFC4','LFC5','LFC6','LFC7','LFC8','LFC9','LFC10','OCC1','OCC2','OCC3','OCC4','OCC5','OCC6','OCC7','OCC8','OCC9',\n",
    "      'OCC10','OCC11','OCC12','OCC13','EIC1','EIC2','EIC3','EIC4','EIC5','EIC6','EIC7','EIC8','EIC9','EIC10','EIC11','EIC12','EIC13','EIC14','EIC15',\n",
    "      'EIC16','OEDC1','OEDC2','OEDC3','OEDC4','OEDC5','OEDC6','OEDC7','EC1','EC2','EC3',\n",
    "      'EC4','EC5','EC6','EC7','EC8','SEC1','SEC2','SEC3','SEC4','SEC5','AFC1','AFC2','AFC3','AFC4','AFC5','AFC6','VC1','VC2','VC3','VC4','ANC1','ANC2','ANC3','ANC4','ANC5','ANC6','ANC7','ANC8','ANC9','ANC10','ANC11','ANC12','ANC13','ANC14','ANC15','POBC1','POBC2','LSC1','LSC2','LSC3','LSC4',\n",
    "      'VOC1','VOC2', 'VOC3','HC1','HC2','HC3', 'HC4','HC5','HC6','HC7','HC8','HC9','HC10','HC11','HC12','HC13','HC14','HC15','HC16',\n",
    "      'HC17','HC18','HC19','HC20','HC21','MHUC1','MHUC2','AC1','AC2','RFA_2','RFA_3','RFA_4','RFA_5','RFA_6','RFA_7','RFA_8','RFA_9','RFA_10','RFA_11','RFA_12','RFA_13','RFA_14','RFA_15','RFA_16','RFA_17','RFA_18','RFA_19','RFA_20','RFA_21','RFA_22','RFA_23','RFA_24','CARDPROM','MAXADATE','NUMPROM',\n",
    "      'CARDPM12', 'NUMPRM12','RDATE_3','RDATE_4','RDATE_5','RDATE_6','RDATE_7','RDATE_8','RDATE_9','RDATE_10','RDATE_11',\n",
    "      'RDATE_12','RDATE_13','RDATE_14','RDATE_15','RDATE_16','RDATE_17','RDATE_18','RDATE_19','RDATE_20','RDATE_21','RDATE_22','RDATE_23','RDATE_24','RAMNT_3', 'RAMNT_4','RAMNT_5','RAMNT_6', 'RAMNT_7','RAMNT_8','RAMNT_9', 'RAMNT_10',\n",
    "      'RAMNT_11','RAMNT_12','RAMNT_13','RAMNT_14','RAMNT_15','RAMNT_16','RAMNT_17','RAMNT_18','RAMNT_19','RAMNT_20','RAMNT_21',\n",
    "      'RAMNT_22','RAMNT_23','RAMNT_24','RAMNTALL','NGIFTALL','CARDGIFT','MINRAMNT','MINRDATE', 'MAXRAMNT','MAXRDATE','LASTGIFT','LASTDATE','FISTDATE','NEXTDATE','TIMELAG','AVGGIFT','CONTROLN', 'HPHONE_D','RFA_2R','RFA_2F','RFA_2A','MDMAUD_R','MDMAUD_F','MDMAUD_A','CLUSTER2','GEOCODE2']\n",
    "    \n",
    "    for i in xrange(len(data)):\n",
    "        df[data[i]] = pd.Categorical((pd.factorize(df[data[i]])[0] + 1).astype(str))\n",
    "    \n",
    "    return df[data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_split():  \n",
    "    df = data_preperation()\n",
    "    train, test = train_test_split(df, test_size = 0.5)  # split data to 50-50 cross validate \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df_split()\n",
    "rewards = ['TARGET_D']\n",
    "for i in xrange(len(rewards)):\n",
    "    train[rewards[i]] = pd.Categorical((pd.factorize(train[rewards[i]])[0] + 1).astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current State variables ..\n",
    "Recency, Frequancy, Montery variables .. ['RFA_2R', 'RFA_2F', 'RFA_2A']\n",
    "\n",
    "## Rewards:\n",
    "- Donation amount \n",
    "- These are the target variables as well .. \n",
    "- TARGET_D, TARGET_B \n",
    "\n",
    "\n",
    "## Actions: \n",
    "- 11 mailing type\n",
    "\n",
    "Actions mapping .. \n",
    "https://github.com/EAboelhamd/kdd98-1/tree/master/notebooks\n",
    "\n",
    "## Actions:\n",
    "\n",
    "- mailing types ..\n",
    "action_mapping = {\n",
    "\n",
    "                                    2: 'NK',  3: 'NK',\n",
    "                                    4: 'TK',  5: 'SK',\n",
    "                                    6: 'LL',  7: 'G1',\n",
    "                                    8: 'GK',  9: 'CC',\n",
    "                                    10: 'WL', 11: 'X1',\n",
    "                                    12: 'XK', 13: 'FS',\n",
    "                                    14: 'NK', 15: 'TK',\n",
    "                                    16: 'LL', 17: 'G1',\n",
    "                                    18: 'GK', 19: 'CC',\n",
    "                                    20: 'WL', 21: 'X1',\n",
    "                                    22: 'XK', 23: 'FS', 24: 'NK'\n",
    "                                }\n",
    "\n",
    "this list contains 11 unique values (NK, TK,LL,GK,WL,XK,SK,G1,CC,X1,FS)\n",
    "\n",
    "                                        NK ==> 2, 14, 23, 24\n",
    "                                        LL ==> 2, 16\n",
    "                                        TK ==> 4, 15\n",
    "                                        GK ==> 8, 18\n",
    "                                        WL ==> 10, 20\n",
    "                                        SK ==> 5\n",
    "                                        G1 ==> 7, 17\n",
    "                                        CC ==> 9, 19\n",
    "                                        X1 ==> 11, 21\n",
    "                                        FS ==> 13, 23\n",
    "\n",
    "Their corresponding meanings are:\n",
    "\n",
    "                                        LL mailings had labels only                                        \n",
    "                                        WL mailings had labels only\n",
    "                                        CC mailings are calendars with stickers but do\n",
    "                                           not have labels\n",
    "                                        FS mailings are blank cards that fold into\n",
    "                                           thirds with labels\n",
    "                                        NK mailings are blank cards with labels\n",
    "                                        SK mailings are blank cards with labels\n",
    "                                        TK mailings have thank you printed on the\n",
    "                                           outside with labels\n",
    "                                        GK mailings are general greeting cards (an\n",
    "                                           assortment of birthday, sympathy, blank, & get\n",
    "                                           well) with labels\n",
    "                                        XK mailings are Christmas cards with labels\n",
    "                                        X1 mailings have labels and a notepad\n",
    "                                        G1 mailings have labels and a notepad\n",
    "\n",
    "- This is why I'm gonna extract the last two digits from the sequance to represent mailing type (unique values are 11 .. NK, TK, SK, LL, G1, GK, CC, WL, X1, XK, FS) + no action .. total action are 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## States:\n",
    "\n",
    "In the cited paper .. they defined the states as follows: \n",
    "\n",
    "It is a 5-dimensional vector consisting of \n",
    "\n",
    "(1) how recently the donor donated last (R)\n",
    "\n",
    "(2) how frequently she donates (F)\n",
    "\n",
    "(3) her average donation amount (M)\n",
    "\n",
    "(4) how many times PVA sends her a mail in the last six months\n",
    "\n",
    "(5) how many times PVA has sent her mails.\n",
    "\n",
    "\n",
    "This implementation is considered as a POMPD .. \n",
    "where:\n",
    "b: belief state that is a probability distribution over all states\n",
    "b(s): prob. that the agent in state s \n",
    "after taking action a and observing the state O .. the update rule for the belief state o(s) is using Bayes rule .. \n",
    "\n",
    "## Next States:\n",
    "\n",
    "As mentioned in the paper ==> the 5-dimensional observation is discrete in this problem, and individual dimensions evolve\n",
    "independently of each other. We therefore build an observation probability table for each observation dimension,\n",
    "and the sample next observations using these tables.\n",
    "\n",
    "Hence, Let's create an n*5 dim observations table .. \n",
    "\n",
    "http://www-anw.cs.umass.edu/~barto/courses/cs687/PartialObs-printable.pdf\n",
    "\n",
    "\n",
    "### These researchers proposed other types of state space ==>\n",
    "\n",
    "https://www.cs.cmu.edu/~ebrun/15889e/hw1.pdf\n",
    "\n",
    "as 9 vars (try it out) ;) .. \n",
    "and others consider (belief, observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET_D</th>\n",
       "      <th>ODATEDW</th>\n",
       "      <th>OSOURCE</th>\n",
       "      <th>TCODE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>MAILCODE</th>\n",
       "      <th>PVASTATE</th>\n",
       "      <th>DOB</th>\n",
       "      <th>NOEXCH</th>\n",
       "      <th>...</th>\n",
       "      <th>CONTROLN</th>\n",
       "      <th>HPHONE_D</th>\n",
       "      <th>RFA_2R</th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>RFA_2A</th>\n",
       "      <th>MDMAUD_R</th>\n",
       "      <th>MDMAUD_F</th>\n",
       "      <th>MDMAUD_A</th>\n",
       "      <th>CLUSTER2</th>\n",
       "      <th>GEOCODE2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 457 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET_D ODATEDW OSOURCE TCODE STATE ZIP MAILCODE PVASTATE DOB NOEXCH  \\\n",
       "21        1       6      21     1    12  21        1        1  13      1   \n",
       "45        2       4       6     2     7  45        1        1  27      1   \n",
       "29        1      11      28     2    13  29        1        1   5      1   \n",
       "11        1       6      11     1     5  11        1        1   7      1   \n",
       "26        1       6      26     2    13  26        1        1  16      1   \n",
       "\n",
       "     ...    CONTROLN HPHONE_D RFA_2R RFA_2F RFA_2A MDMAUD_R MDMAUD_F MDMAUD_A  \\\n",
       "21   ...          21        2      1      3      1        1        1        1   \n",
       "45   ...          45        2      1      4      4        1        1        1   \n",
       "29   ...          29        2      1      4      2        1        1        1   \n",
       "11   ...          11        1      1      1      3        1        1        1   \n",
       "26   ...          26        1      1      3      1        1        1        1   \n",
       "\n",
       "   CLUSTER2 GEOCODE2  \n",
       "21       19        2  \n",
       "45       30        2  \n",
       "29       25        1  \n",
       "11       11        4  \n",
       "26       23        1  \n",
       "\n",
       "[5 rows x 457 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_():\n",
    "    train, test = df_split()\n",
    "    \n",
    "    RFA = ['RFA_2']  # don't know if it is NUMPRM12 or CARDPM12 \n",
    "\n",
    "    ## next state\n",
    "    ## next_states are random selection from the current states\n",
    "    RFA_next = ['RFA_3', 'RFA_4', 'RFA_5', 'RFA_6', 'RFA_7', 'RFA_8', 'RFA_9', 'RFA_10',\n",
    "                'RFA_11', 'RFA_12', 'RFA_13', 'RFA_14', 'RFA_15', 'RFA_16', 'RFA_17', 'RFA_18',\n",
    "                'RFA_19', 'RFA_20', 'RFA_21', 'RFA_22', 'RFA_23', 'RFA_24']\n",
    "#     next_states = [[random.random() for e in train[RFA].values[0]] for e in xrange(len(train[RFA].values))]\n",
    "#     next_states = pd.DataFrame(next_states)\n",
    "\n",
    "    current_states = train['RFA_2']\n",
    "    next_states = train[RFA_next]\n",
    "    \n",
    "    rewards = ['TARGET_D']\n",
    "    \n",
    "    for i in xrange(len(rewards)):\n",
    "        train[rewards[i]] = pd.Categorical((pd.factorize(train[rewards[i]])[0] + 1).astype(str))\n",
    "    \n",
    "    curr_state_current_action = pd.DataFrame(np.column_stack((current_states.values, actions[:25][1])))\n",
    "\n",
    "    # next actions \n",
    "    next_actions = np.zeros([len(next_states), max(actions.max(axis = 0).astype(int)) + 1])\n",
    "    next_actions = np.delete(next_actions, -1, axis=1) ## remove last column .. \n",
    "\n",
    "    next_state_next_action = np.zeros([np.shape(next_states)[0], np.shape(next_states)[1] + max(actions.max(axis = 0).astype(int))])\n",
    "\n",
    "#     # fill in next_actions  \n",
    "    for i in xrange(np.shape(next_actions)[1]):\n",
    "        next_actions[:, i] = i\n",
    "\n",
    "    return next_states, next_actions, curr_state_current_action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression phase:\n",
    "\n",
    "Before performing the prediction task .. let's split the data to training and validation sets .. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid any problems in prediction by having string variables .. let's binarize (catergorize) all the variables .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9\n",
    "Num_itrs = 2  # no loop 3leha ( w dah el sa7) .. we just have to run the whole algo. 10 times and report the avg. results\n",
    "\n",
    "num_epoch = 1 #23 #epochs are cycles of Feedforward and Backprob\n",
    "## el mafrood yeb2a feh loop 3la el epochs elli heyya el steps .. w avg. reward per step is calculated \n",
    "batch_size = 1\n",
    "chunkSize = 1\n",
    "\n",
    "n_nodes_hl1 = np.shape(train)[0]\n",
    "n_nodes_hl2 = np.shape(train)[0]\n",
    "NUM_STATES = np.shape(train)[1]\n",
    "NUM_DIM =  np.shape(train)[1]\n",
    "num_nodes = np.shape(train)[0]\n",
    "num_unrollings = 5\n",
    "\n",
    "best_actions = np.zeros([np.shape(train)[0], batch_size])\n",
    "Q_optimal = [] #np.zeros([np.shape(curr_state_current_action)[0], len(df['ACCOUNT_STATUS'].unique())])\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "## for training \n",
    "x = tf.placeholder(tf.float32, shape=[NUM_DIM, num_nodes])\n",
    "y =  tf.placeholder(tf.float32, shape=[num_nodes, 1])\n",
    "\n",
    "## for testing\n",
    "x_ = tf.placeholder(tf.float32, shape=[np.shape(test)[0], NUM_DIM])\n",
    "y_ =  tf.placeholder(tf.float32, shape=[np.shape(test)[0], 1])\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "# Input gate: input, previous output, and bias.\n",
    "ix = tf.Variable(tf.truncated_normal([NUM_DIM, num_nodes], 0, 1, dtype = tf.float32))# init_weights_RNN([n_nodes_hl1, NUM_ACTIONS])\n",
    "im = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], 0, 1, dtype = tf.float32))\n",
    "ib = tf.Variable(tf.zeros([1, num_nodes], dtype = tf.float32))\n",
    "\n",
    "# Forget gate: input, previous output, and bias.\n",
    "fx = tf.Variable(tf.truncated_normal([NUM_DIM, num_nodes], 0, 1, dtype = tf.float32))\n",
    "fm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], 0, 1, dtype = tf.float32))\n",
    "fb = tf.Variable(tf.zeros([1, num_nodes], dtype = tf.float32))\n",
    "\n",
    "# Memory cell: input, state and bias.                             \n",
    "cx = tf.Variable(tf.truncated_normal([NUM_DIM, num_nodes], 0, 1, dtype = tf.float32))\n",
    "cm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], 0, 1, dtype = tf.float32))\n",
    "cb = tf.Variable(tf.zeros([1, num_nodes], dtype = tf.float32))\n",
    "\n",
    "# Output gate: input, previous output, and bias.\n",
    "ox = tf.Variable(tf.truncated_normal([NUM_DIM, num_nodes], 0, 1, dtype = tf.float32))\n",
    "om = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], 0, 1, dtype = tf.float32))\n",
    "ob = tf.Variable(tf.zeros([1, num_nodes], dtype = tf.float32))\n",
    "\n",
    "# Variables saving state across unrollings.\n",
    "saved_output = tf.Variable(tf.zeros([1, num_nodes], dtype = tf.float32), trainable=False) #reversed\n",
    "\n",
    "saved_state = tf.Variable(tf.zeros([1, num_nodes], dtype = tf.float32), trainable=False) #reversed\n",
    "\n",
    "# Classifier weights and biases.\n",
    "w = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], 0, 1, dtype = tf.float32))\n",
    "b = tf.Variable(tf.zeros([num_nodes], dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the cell computation.\n",
    "# this method takes single cell and returns single number \n",
    "def lstm_cell(i, o, state):\n",
    "    input_gate = tf.sigmoid(tf.matmul(i, ix) + tf.matmul(o, im) + ib)\n",
    "    forget_gate = tf.sigmoid(tf.matmul(i, fx) + tf.matmul(o, fm) + fb)\n",
    "    update = tf.matmul(i, cx) + tf.matmul(o, cm) + cb\n",
    "    state = forget_gate * state + input_gate * tf.tanh(update)\n",
    "    output_gate = tf.sigmoid(tf.matmul(i, ox) + tf.matmul(o, om) + ob)\n",
    "    return output_gate * tf.tanh(state), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(train, saved_output, saved_state):\n",
    "    # Unrolled LSTM loop.    \n",
    "    outputs = list()\n",
    "    output = saved_output  # row !\n",
    "    state = saved_state  # row !\n",
    "    \n",
    "    # astype('U') .. to convert numpy array to string ..\n",
    "    for i in xrange(np.shape(train)[0]):## el loop faydetha to copy the next line that is just for single unit \n",
    "        output_, state = lstm_cell(tf.string_to_number(train.values[i, None].astype('U')), tf.cast(output, tf.float32), tf.cast(state, tf.float32)) \n",
    "\n",
    "    ## in case the last values are saved !\n",
    "    with tf.control_dependencies([saved_output.assign(output), saved_state.assign(state)]):\n",
    "        model_output = tf.matmul(output_, w) + b # outputs single value\n",
    "        \n",
    "    return model_output  ## the output for the whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_model():\n",
    "    loss_RNN = []\n",
    "    model_output = lstm_model(train, saved_output, saved_state) #output here is a vector\n",
    "    model_output = tf.transpose(model_output)\n",
    "    cost = tf.reduce_mean(tf.square(y - model_output))\n",
    "    optimize = tf.train.GradientDescentOptimizer(0.01).minimize(cost) \n",
    "\n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()  ## updated version from initialize_all_variables :) \n",
    "    sess.run(init)\n",
    "\n",
    "    predicted_reward = sess.run(model_output, feed_dict={x:np.transpose(train.values), y:train[rewards].values})\n",
    "    \n",
    "    # Cost calculation\n",
    "    for step in xrange(1000):\n",
    "        l,_ = sess.run([cost, optimize], feed_dict={x:np.transpose(train.values), y:train[rewards]})\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            loss_RNN.append(l)\n",
    "\n",
    "    Y_pred = tf.zeros([len(test[rewards]),1])\n",
    "\n",
    "    # predict \n",
    "    test_pred2 = sess.run(Y_pred, feed_dict={x_: test.values})\n",
    "\n",
    "   ## rms to test ..\n",
    "    cost_test = tf.reduce_mean(tf.square(test[rewards].values.astype(np.float32) - test_pred2))\n",
    "    \n",
    "    \n",
    "    rmse_val = sess.run(cost_test, feed_dict={x_:test.values.astype(np.float32), y_: test_pred2})\n",
    "     \n",
    "    sess.close()\n",
    "    \n",
    "    return loss_RNN, predicted_reward #saved_state, saved_output, cost_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_prediction(train):\n",
    "    loss_RNN, predicted_reward = train_lstm_model()\n",
    "    plt.plot(loss_RNN)\n",
    "    plt.xlabel('Step number')\n",
    "    plt.ylabel('Prediction Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e7ad9ec1e136>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreward_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-0fceff1c015b>\u001b[0m in \u001b[0;36mreward_prediction\u001b[0;34m(train)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreward_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mloss_RNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_lstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_RNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Step number'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Prediction Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-75e9ecaa7d1e>\u001b[0m in \u001b[0;36mtrain_lstm_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Cost calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reward_prediction(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning the rewards:\n",
    "Now, the LSTM_RNN output (from validation phase) is considered as input for DQN model, to be able to select the action that has the maximum longtime reward for the customer (highest CLV) .. \n",
    "\n",
    "https://arxiv.org/pdf/1602.01580.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Deep Neural Network (DQN):\n",
    "\n",
    "https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/blob/master/contents/5_Deep_Q_Network/RL_brain.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Definition of the cell computation.\n",
    "# this method takes single cell and returns single number \n",
    "def lstm_cell(i, o, state):\n",
    "    input_gate = tf.sigmoid(tf.matmul(i, ix) + tf.matmul(o, im) + ib)\n",
    "    forget_gate = tf.sigmoid(tf.matmul(i, fx) + tf.matmul(o, fm) + fb)\n",
    "    update = tf.matmul(i, cx) + tf.matmul(o, cm) + cb\n",
    "    state = forget_gate * state + input_gate * tf.tanh(update)\n",
    "    output_gate = tf.sigmoid(tf.matmul(i, ox) + tf.matmul(o, om) + ob)\n",
    "    return output_gate * tf.tanh(state), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN_model(X, w_h_1, w_h_2, w_o, bias_I_1, bias_I_2, bias_h):\n",
    "\n",
    "    layer_1 = tf.matmul(X, w_h_1) + bias_I_1\n",
    "    layer_1 = tf.nn.relu(layer_1)  ## el performance of softmax outperforms relu!!\n",
    "    \n",
    "    layer_2 = tf.matmul(layer_1, w_h_2) + bias_I_2\n",
    "    layer_2 = tf.nn.sigmoid(layer_2) \n",
    "\n",
    "    py_x = tf.matmul(layer_2, w_o) + bias_h\n",
    "    \n",
    "    return py_x  #predicted output\n",
    "    # note that we dont take the softmax at the end because our cost fn does that for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN_training(X, output):\n",
    " \n",
    "    w_h_1 = init_weights([np.shape(X)[1], n_nodes_hl1]) # create symbolic variables\\n\",\n",
    "    w_h_2 = init_weights([n_nodes_hl1, n_nodes_hl2]) # create symbolic variables\\n\",\n",
    "    w_o = init_weights([n_nodes_hl2, 1])\n",
    "    \n",
    "    bias_I_1=init_weights([n_nodes_hl1])\n",
    "    bias_I_2=init_weights([n_nodes_hl2])\n",
    "    bias_h=init_weights([1])\n",
    "    \n",
    "    py_x = DQN_model(tf.cast(X, tf.float32), w_h_1, w_h_2, w_o,bias_I_1, bias_I_2,bias_h)  #model training  \n",
    "        \n",
    "    cost = tf.reduce_mean(tf.square(py_x - output)) # compute costs\",  # excpect float32\n",
    "\n",
    "    train_op = tf.train.GradientDescentOptimizer(0.01).minimize(cost) # construct an optimizer\\n\",\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "#      # Cost calculation\n",
    "#     for step in xrange(1000):\n",
    "#         l,_ = sess.run([cost, train_op], feed_dict={x:np.transpose(X), y:np.transpose(output)})\n",
    "        \n",
    "#         if step % 100 == 0:\n",
    "#             loss_RNN.append(l)\n",
    "            \n",
    "#     plt.plot(loss_RNN)\n",
    "    \n",
    "    sess.close()    \n",
    "    return w_h_1, w_h_2, w_o,bias_I_1, bias_I_2,bias_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## split dataframe to smaller frames\n",
    "\n",
    "# def splitDataFrameIntoSmaller(tuplesMx, chunkSize = 10): \n",
    "#     listOfDf = []\n",
    "#     numberChunks = len(tuplesMx) // chunkSize + 1\n",
    "#     for i in range(numberChunks):\n",
    "#         listOfDf.append(tuplesMx[i*chunkSize:(i+1)*chunkSize])\n",
    "#         print np.shape(listOfDf)\n",
    "# #     listOfDf = random.sample(df, chunkSize)  ## in case df is an array not dataframe\n",
    "#     return listOfDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuplesMx, actions = tuple_()\n",
    "# listOfDf = splitDataFrameIntoSmaller(tuplesMx, chunkSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if only RFM in the state .. \n",
    "\n",
    "Mxa0 = (tuplesMx.iloc[:,0:24]).values \n",
    "Mxa1 = (tuplesMx.iloc[:,25:48]).values\n",
    "Mxa2 = (tuplesMx.iloc[:,49:72]).values\n",
    "Mxa3 = (tuplesMx.iloc[:,73:96]).values\n",
    "Mxa4 = (tuplesMx.iloc[:,97:120]).values\n",
    "Mxa5 = (tuplesMx.iloc[:,121:144]).values\n",
    "Mxa6 = (tuplesMx.iloc[:,145:168]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction phase: \n",
    "def DQN_predict(tuplesMx, output):\n",
    "    \n",
    "    Mxa0 = (tuplesMx.iloc[:,0:6]).values \n",
    "    Mxa1 = (tuplesMx.iloc[:,6:12]).values\n",
    "    Mxa2 = (tuplesMx.iloc[:,12:18]).values\n",
    "    Mxa3 = (tuplesMx.iloc[:,18:24]).values\n",
    "    Mxa4 = (tuplesMx.iloc[:,24:30]).values\n",
    "    Mxa5 = (tuplesMx.iloc[:,30:36]).values\n",
    "    Mxa6 = (tuplesMx.iloc[:,36:42]).values\n",
    "\n",
    "    [w_h_1, w_h_2, w_o,bias_I_1, bias_I_2,bias_h] = DQN_training(Mxa0, output)\n",
    "    predict_op_0 = DQN_model(Mxa0.astype(np.float32), w_h_1, w_h_2, w_o,bias_I_1, bias_I_2,bias_h)\n",
    "      \n",
    "        \n",
    "    #  print next_state_next_action2     \n",
    "    [w_h_1, w_h_2, w_o,bias_I_1, bias_I_2,bias_h] = DQN_training(Mxa1, output)\n",
    "    predict_op_1 = DQN_model(Mxa1.astype(np.float32), w_h_1, w_h_2, w_o,bias_I_1, bias_I_2, bias_h)   #optimal prediction\n",
    "    \n",
    "    \n",
    "    ## print next_state_next_action3\n",
    "    [w_h_1, w_h_2, w_o,bias_I_1, bias_I_2,bias_h] = DQN_training(Mxa2, output)\n",
    "    predict_op_2 = DQN_model(Mxa2.astype(np.float32), w_h_1, w_h_2, w_o,bias_I_1, bias_I_2,bias_h)\n",
    "     \n",
    "    [w_h_1, w_h_2, w_o,bias_I_1, bias_I_2,bias_h] = DQN_training(Mxa3, output)\n",
    "    predict_op_3 = DQN_model(Mxa3.astype(np.float32), w_h_1, w_h_2, w_o,bias_I_1, bias_I_2,bias_h)\n",
    "      \n",
    "        \n",
    "    #  print next_state_next_action4    \n",
    "    [w_h_1, w_h_2, w_o,bias_I_1, bias_I_2,bias_h] = DQN_training(Mxa4, output)\n",
    "    predict_op_4 = DQN_model(Mxa4.astype(np.float32), w_h_1, w_h_2, w_o,bias_I_1, bias_I_2, bias_h)   #optimal prediction\n",
    "    \n",
    "    \n",
    "    ## print next_state_next_action5\n",
    "    [w_h_1, w_h_2, w_o,bias_I_1, bias_I_2,bias_h] = DQN_training(Mxa5, output)\n",
    "    predict_op_5 = DQN_model(Mxa5.astype(np.float32), w_h_1, w_h_2, w_o,bias_I_1, bias_I_2,bias_h)\n",
    "     \n",
    "    ## print next_state_next_action6    \n",
    "    [w_h_1, w_h_2, w_o,bias_I_1, bias_I_2,bias_h] = DQN_training(Mxa6, output)\n",
    "    predict_op_6 = DQN_model(Mxa6.astype(np.float32), w_h_1, w_h_2, w_o,bias_I_1, bias_I_2,bias_h)\n",
    "\n",
    "        \n",
    "    sess2 = tf.Session()\n",
    "    init2 = tf.global_variables_initializer()\n",
    "    sess2.run(init2)\n",
    "\n",
    "    l0=sess2.run(predict_op_0)\n",
    "    l1=sess2.run(predict_op_1)\n",
    "    l2=sess2.run(predict_op_2)\n",
    "    l3=sess2.run(predict_op_3)\n",
    "    l4=sess2.run(predict_op_4)\n",
    "    l5=sess2.run(predict_op_5)\n",
    "    l6=sess2.run(predict_op_6)\n",
    "        \n",
    "    Q_predicted = [l0, l1, l2, l3, l4, l5, l6]\n",
    "    \n",
    "    Q_predicted = np.reshape(Q_predicted, [25, 7])\n",
    "    \n",
    "#     print np.shape(Q_predicted)\n",
    "    \n",
    "    sess2.close()\n",
    "    return Q_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q(s,a) representing the (Quality) of action a at state is .. \n",
    "\n",
    "this Q value depends on the immediate reward r .. however, it'll be more effective if it takes the future rewards Q(s', a') into consideration .. \n",
    "\n",
    "the future rewards are discounted by probability gama .. cause the evironment is stochastic hence, it is uncertain that each time you select action a you gonna get the same reward r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_reward = np.transpose(predicted_reward) \n",
    "def Q_learning():\n",
    "    next_states, next_actions, curr_state_current_action = tuple_()\n",
    "    \n",
    "    tuplesMx = []\n",
    "    \n",
    "    nepisod = np.shape(next_states)[1]  ##22\n",
    "    num_actions = np.shape(next_actions)[1]\n",
    "    \n",
    "    Q_predicted = np.zeros([np.shape(train)[0], 12])\n",
    "    best_action = list() #np.zeros([np.shape(train)[0], batch_size])\n",
    "\n",
    "        \n",
    "    for l in xrange(nepisod):\n",
    "        for k in xrange(num_actions):\n",
    "            Mxa = pd.DataFrame(np.column_stack((next_states.iloc[:,l], next_actions[:,k])))\n",
    "\n",
    "        tuplesMx.append(pd.DataFrame(np.column_stack((Mxa, curr_state_current_action, train[rewards].values))))\n",
    "\n",
    "        _, predicted_reward = train_lstm_model()\n",
    "\n",
    "        for j in xrange(batch_size):\n",
    "            Q_optimal = predicted_reward[j].astype(float) + gamma*np.max(Q_predicted) # returns max value per row !\n",
    "#             Q_optimal = np.array(Q_optimal, dtype=np.float32) # convert output to float32 to match py_x\n",
    "#             Q_predicted = DQN_predict(tuplesMx, Q_optimal)\n",
    "    print Q_optimal\n",
    "#             best_action.append(np.argmax(Q_predicted, axis=1))\n",
    "        #     print type(best_action)\n",
    "\n",
    "#     return np.mean(Q_optimal), best_action "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    avg_Q, best_action = Q_learning()\n",
    "#     best_action = pd.DataFrame(best_action)\n",
    "#     return avg_Q, best_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_action = np.transpose(best_action)\n",
    "best_action[0].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above .. \n",
    "\n",
    "the actions order (from highest to lowest) \n",
    "1. Action # 7 (Thank you printed with labels)\n",
    "2. Action # 6 \n",
    "3. Action # 4 (Blank cards that fold into thirds with labels)\n",
    "4. Action # 1 \n",
    "\n",
    "This differs a bit the order of Stanford paper in two points:\n",
    "1. Their starting index is 1 .. while Python's is zeros based .. this is why I'm adding 1 in the index .. \n",
    "2. I'm working on just a sample (with a size less than their size) this is why there are some actions I even didn't have as an output (i.e. action # 11) !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "\n",
    "an enhancement for this implementation is to change the states to be the whole doner state instead of just RFM ..\n",
    "\n",
    "https://github.com/EAboelhamd/kdd98-1/blob/master/notebooks/exploratory.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do I apply experience replay .. \n",
    "\n",
    "The algorithm is mentioned here .. \n",
    "\n",
    "https://www.intelnervana.com/demystifying-deep-reinforcement-learning/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
