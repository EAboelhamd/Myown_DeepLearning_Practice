{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "Main Goals:\n",
    "\n",
    "1. Identify the recipients that will engage with the campaign.\n",
    "2. Maximise the campaignâ€™s revenue.\n",
    "\n",
    "\n",
    "Comments\n",
    "\n",
    "- The dataset contains only 5% of donors.\n",
    "- The donations are usually smaller than $20.\n",
    "- This data is quite noisy, high dimensional.\n",
    "- There is an inverse relationship between the probability to donate and the amount donated.\n",
    "\n",
    "\n",
    "Link for dataset and some analysis ==> \n",
    "\n",
    "https://github.com/rebordao/kdd98cup\n",
    "\n",
    "https://github.com/bobbyantonio/KDD98/blob/master/CleanData.py\n",
    "\n",
    "- Github solutions ==>\n",
    "https://github.com/rebordao/kdd98cup\n",
    "\n",
    "\n",
    "- Siraj notebook for a better data visualization:\n",
    "\n",
    "https://www.youtube.com/watch?v=yQsOFWqpjkE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# import datetime as dt\n",
    "\n",
    "## warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    return pd.read_csv('tuple.csv', header = 0, nrows = 25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r0</th>\n",
       "      <th>f0</th>\n",
       "      <th>m0</th>\n",
       "      <th>ir0</th>\n",
       "      <th>if0</th>\n",
       "      <th>a</th>\n",
       "      <th>r1</th>\n",
       "      <th>f1</th>\n",
       "      <th>m1</th>\n",
       "      <th>ir1</th>\n",
       "      <th>if1</th>\n",
       "      <th>rew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   r0  f0  m0  ir0  if0  a  r1  f1   m1  ir1  if1  rew\n",
       "0   0   0   0    0    0  5   0   1  9.0    0    1  9.0\n",
       "1   0   0   0    0    0  5   1   0  0.0    0    1  0.0\n",
       "2   0   0   0    0    0  5   0   1  6.0    0    1  6.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## I have to run it over all the data not just 100 records\n",
    "df = load_data()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_split():\n",
    "    \n",
    "    df = load_data()\n",
    "#     train, test = train_test_split(df, test_size = 0.999)  # split data to 50-50 cross validate, Roger 1.6*1000,000\n",
    "    \n",
    "    train_x = df[df.columns.difference(['a', 'r0', 'f0', 'm0', 'ir0', 'if0'])]\n",
    "    train_y = df[df.columns.difference(['rew', 'a', 'r0', 'f0', 'm0', 'ir0', 'if0'])]\n",
    "    \n",
    "#     train_y = train_y.convert_objects(convert_numeric = True)\n",
    "    \n",
    "#     train_y = train_y.convert_objects(convert_numeric = True)\n",
    "    \n",
    "    return train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_(predicted_states):\n",
    "        \n",
    "    next_actions = np.zeros([len(predicted_states), 12])\n",
    "    \n",
    "    for i in xrange(11):\n",
    "        next_actions[:, i] = i\n",
    "\n",
    "    tuplesMx0 = np.column_stack((predicted_states, next_actions[:,0]))\n",
    "    tuplesMx1 = np.column_stack((predicted_states, next_actions[:,1]))\n",
    "    tuplesMx2 = np.column_stack((predicted_states, next_actions[:,2]))\n",
    "    tuplesMx3 = np.column_stack((predicted_states, next_actions[:,3]))\n",
    "    tuplesMx4 = np.column_stack((predicted_states, next_actions[:,4]))\n",
    "    tuplesMx5 = np.column_stack((predicted_states, next_actions[:,5]))\n",
    "    tuplesMx6 = np.column_stack((predicted_states, next_actions[:,6]))\n",
    "    tuplesMx7 = np.column_stack((predicted_states, next_actions[:,7]))\n",
    "    tuplesMx8 = np.column_stack((predicted_states, next_actions[:,8]))\n",
    "    tuplesMx9 = np.column_stack((predicted_states, next_actions[:,9]))\n",
    "    tuplesMx10 = np.column_stack((predicted_states, next_actions[:,10]))\n",
    "    tuplesMx11 = np.column_stack((predicted_states, next_actions[:,11]))\n",
    "    \n",
    "    return tuplesMx0, tuplesMx1, tuplesMx2, tuplesMx3, tuplesMx4, tuplesMx5, tuplesMx6, tuplesMx7, tuplesMx8, tuplesMx9, tuplesMx10, tuplesMx11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuplesMx0, tuplesMx1, tuplesMx2, tuplesMx3, tuplesMx4, tuplesMx5, tuplesMx6, tuplesMx7, tuplesMx8, tuplesMx9, tuplesMx10, tuplesMx11  = tuple_()\n",
    "# tuplesMx0, tuplesMx1, tuplesMx2, tuplesMx3, tuplesMx4, tuplesMx5, tuplesMx6, tuplesMx7, tuplesMx8, tuplesMx9, tuplesMx10, tuplesMx11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression phase:\n",
    "\n",
    "Before performing the prediction task .. let's split the data to training and validation sets .. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid any problems in prediction by having string variables .. let's binarize (catergorize) all the variables .. \n",
    "\n",
    "Guidance ==> https://pythonprogramming.net/rnn-tensorflow-python-machine-learning-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9\n",
    "Num_itrs = 2  # no loop 3leha ( w dah el sa7) .. we just have to run the whole algo. 10 times and report the avg. results\n",
    "\n",
    "num_epoch = 1 #23 #epochs are cycles of Feedforward and Backprob\n",
    "## el mafrood yeb2a feh loop 3la el epochs elli heyya el steps .. w avg. reward per step is calculated \n",
    "batch_size = 5\n",
    "chunkSize = 1\n",
    "\n",
    "train_x, train_y = df_split()\n",
    "\n",
    "n_nodes_hl1 = 40 #np.shape(train)[1]\n",
    "n_nodes_hl2 = 15 #np.shape(train)[0]\n",
    "# NUM_STATES = np.shape(train)[1]\n",
    "NUM_DIM =  np.shape(train_x)[1]\n",
    "num_nodes = np.shape(train_x)[0]\n",
    "NUM_DIM_output = np.shape(train_y)[1]\n",
    "\n",
    "num_unrollings = 5\n",
    "\n",
    "# best_actions = np.zeros([np.shape(train)[0], batch_size])\n",
    "Q_optimal = [] #np.zeros([np.shape(curr_state_current_action)[0], len(df['ACCOUNT_STATUS'].unique())])\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "## for training \n",
    "x = tf.placeholder(tf.float32, shape=[num_nodes, NUM_DIM])\n",
    "y =  tf.placeholder(tf.float32, shape=[num_nodes, NUM_DIM_output])\n",
    "\n",
    "# ## for testing\n",
    "# x_ = tf.placeholder(tf.float32, shape=[NUM_DIM, None])\n",
    "# y_ =  tf.placeholder(tf.float32, shape=[NUM_DIM, None])\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "# Input gate: input, previous output, and bias.\n",
    "ix = tf.Variable(tf.random_uniform([NUM_DIM, NUM_DIM_output],0,5, dtype = tf.float32))# init_weights_RNN([n_nodes_hl1, NUM_ACTIONS])\n",
    "im = tf.Variable(tf.random_uniform([NUM_DIM_output, NUM_DIM_output],0,5, dtype = tf.float32))\n",
    "ib = tf.Variable(tf.zeros([1, NUM_DIM_output], dtype = tf.float32))\n",
    "\n",
    "# Forget gate: input, previous output, and bias.\n",
    "fx = tf.Variable(tf.random_uniform([NUM_DIM, NUM_DIM_output],0,5, dtype = tf.float32))\n",
    "fm = tf.Variable(tf.random_uniform([NUM_DIM_output, NUM_DIM_output],0,5, dtype = tf.float32))\n",
    "fb = tf.Variable(tf.zeros([1, NUM_DIM_output], dtype = tf.float32))\n",
    "\n",
    "# Memory cell: input, state and bias.                             \n",
    "cx = tf.Variable(tf.random_uniform([NUM_DIM, NUM_DIM_output],0,5, dtype = tf.float32))\n",
    "cm = tf.Variable(tf.random_uniform([NUM_DIM_output, NUM_DIM_output],0,5, dtype = tf.float32))\n",
    "cb = tf.Variable(tf.zeros([1, NUM_DIM_output], dtype = tf.float32))\n",
    "\n",
    "# Output gate: input, previous output, and bias.\n",
    "ox = tf.Variable(tf.random_uniform([NUM_DIM, NUM_DIM_output],0,5, dtype = tf.float32))\n",
    "om = tf.Variable(tf.random_uniform([NUM_DIM_output, NUM_DIM_output],0,5, dtype = tf.float32))\n",
    "ob = tf.Variable(tf.zeros([NUM_DIM_output], dtype = tf.float32))\n",
    "\n",
    "# Variables saving state across unrollings.\n",
    "saved_output = tf.Variable(tf.zeros([num_nodes, NUM_DIM_output], dtype = tf.float32), trainable = False) \n",
    "\n",
    "saved_state = tf.Variable(tf.zeros([num_nodes, NUM_DIM_output], dtype = tf.float32), trainable = False) \n",
    "\n",
    "# Classifier weights and biases.\n",
    "w = tf.Variable(tf.random_uniform([NUM_DIM_output, NUM_DIM_output], 0, 5, dtype = tf.float32))\n",
    "b = tf.Variable(tf.zeros([NUM_DIM_output], dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the cell computation.\n",
    "# this method takes single cell and returns single number \n",
    "def lstm_cell(i, o, state):\n",
    "    input_gate = tf.sigmoid(tf.matmul(i, ix) + tf.matmul(o, im) + ib)\n",
    "    forget_gate = tf.sigmoid(tf.matmul(i, fx) + tf.matmul(o, fm) + fb)\n",
    "    update = tf.matmul(i, cx) + tf.matmul(o, cm) + cb\n",
    "    state = forget_gate * state + input_gate * tf.tanh(update)\n",
    "    output_gate = tf.sigmoid(tf.matmul(i, ox) + tf.matmul(o, om) + ob)\n",
    "    return output_gate*tf.tanh(state), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(train_x, saved_output, saved_state):\n",
    "    # Unrolled LSTM loop.    \n",
    "#     output_ = list()\n",
    "    output = saved_output  # row !\n",
    "    state = saved_state  # row !\n",
    "\n",
    "    \n",
    "    output_, state = lstm_cell(train_x.values.astype(np.float32), tf.cast(output, tf.float32), tf.cast(state, tf.float32)) \n",
    "    \n",
    "    # astype('U') .. to convert numpy array to string ..\n",
    "#     for i in xrange(np.shape(train_x)[0]):## el loop faydetha to copy the next line that is just for single unit \n",
    "#         output_, state = lstm_cell(train_x.values[i, None].astype(np.float32), output, state) \n",
    "\n",
    "    \n",
    "        # in case the last values are saved !\n",
    "    with tf.control_dependencies([saved_output.assign(output), saved_state.assign(state)]):\n",
    "        model_output = tf.matmul(output_, w) + b # outputs single value\n",
    "    \n",
    "    \n",
    "    return model_output ## the output for the whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_model():\n",
    "\n",
    "    loss_RNN = []\n",
    "    \n",
    "    model_output = lstm_model(train_x, saved_output, saved_state) #output here is a vector\n",
    "\n",
    "    cost = tf.reduce_mean(tf.square(y - model_output))\n",
    "\n",
    "    optimize = tf.train.GradientDescentOptimizer(0.001).minimize(cost) \n",
    "\n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()  ## updated version from initialize_all_variables :) \n",
    "    sess.run(init)\n",
    "\n",
    "    \n",
    "    Predicted_states = sess.run(model_output, feed_dict={x:train_x.values.astype(np.float32), y:train_y.values.astype(np.float32)})\n",
    "    \n",
    "    # Cost calculation\n",
    "    for step in xrange(1000):\n",
    "        l,_ = sess.run([cost, optimize], feed_dict={x:train_x.values, y:train_y.values})\n",
    "    \n",
    "        if step % 100 == 0:\n",
    "            loss_RNN.append(l)\n",
    "     \n",
    "    sess.close()            \n",
    "    \n",
    "#     print Predicted_states\n",
    "    \n",
    "    return Predicted_states, loss_RNN  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_lstm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reward_prediction():\n",
    "#     predicted_states, loss_RNN = train_lstm_model()\n",
    "#     print predicted_states\n",
    "#     plt.plot(loss_RNN)\n",
    "#     plt.xlabel('Step number')\n",
    "#     plt.ylabel('Prediction Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning the rewards:\n",
    "Now, the LSTM_RNN output (from validation phase) is considered as input for DQN model, to be able to select the action that has the maximum longtime reward for the customer (highest CLV) .. \n",
    "\n",
    "https://arxiv.org/pdf/1602.01580.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Deep Neural Network (DQN):\n",
    "\n",
    "https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/blob/master/contents/5_Deep_Q_Network/RL_brain.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## call el fun that predicts next_states and then combine them with the tuple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN_train(x_inputs, y_outputs):\n",
    "\n",
    "#     print np.shape(y_outputs)\n",
    "    \n",
    "    # Placeholder\n",
    "    X = tf.placeholder(dtype=tf.float32, shape=[None, np.shape(x_inputs)[1] ])\n",
    "    Y = tf.placeholder(dtype=tf.float32, shape=[None])\n",
    "\n",
    "\n",
    "    # Model architecture parameters\n",
    "    n_dim = np.shape(x_inputs)[1] \n",
    "    n_neurons_1 = 40\n",
    "    n_neurons_2 = 15\n",
    "    n_target = 1 #np.shape(x_inputs)[0]\n",
    "    \n",
    "    batch_size = 500 \n",
    "    epochs = 100\n",
    "    \n",
    "    predicted_output = []\n",
    "    \n",
    "        # Initializers\n",
    "    sigma = 1\n",
    "    \n",
    "    #First Q Network\n",
    "    w1 = tf.Variable(tf.random_uniform([n_dim, n_neurons_1], 0, 0.1))\n",
    "    bias1 = tf.Variable(tf.random_uniform([n_neurons_1], 0, 0.1))\n",
    "    \n",
    "    w2 = tf.Variable(tf.random_uniform([n_neurons_1, n_neurons_2], 0, 0.1))\n",
    "    bias2 = tf.Variable(tf.random_uniform([n_neurons_2], 0, 0.1))\n",
    "    \n",
    "    w3 = tf.Variable(tf.random_uniform([n_neurons_2, n_target], 0, 0.1))\n",
    "    bias3 = tf.Variable(tf.random_uniform([n_target], 0, 0.1))\n",
    "    \n",
    "    \n",
    "    hidden_1 = tf.nn.relu(tf.matmul(X, w1) + bias1)\n",
    "    hidden_2 = tf.nn.relu(tf.matmul(hidden_1, w2) + bias2)\n",
    "    y_ = tf.matmul(hidden_2, w3) + bias3\n",
    "    \n",
    "    # initialize variables\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    # Cost function\n",
    "    mse = tf.reduce_mean(tf.squared_difference(y_, Y))\n",
    "\n",
    "    # Optimizer\n",
    "    opt = tf.train.RMSPropOptimizer(0.0001, 0.99).minimize(mse)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        num_itr = int(np.shape(y_outputs)[0] / batch_size)\n",
    "        \n",
    "#         for epoch in range(epochs):\n",
    "#             for i in range(num_itr):\n",
    "        predicted_output = sess.run(y_, feed_dict={X: x_inputs, Y: y_outputs})\n",
    "#     print predicted_output\n",
    "#         print np.shape(predicted_output)       \n",
    "#         _, c = sess.run([opt, mse], feed_dict={X: x_inputs, Y: y_outputs})\n",
    "#         print predicted_output\n",
    "    return predicted_output.astype(int) #[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_learning():\n",
    "    \n",
    "    avg_Q = []  \n",
    "    gamma = 0.9\n",
    "#     actions = actions_prep(df)\n",
    "\n",
    "# nepisode > https://stats.stackexchange.com/questions/250943/what-is-the-difference-between-episode-and-epoch-in-deep-q-learning\n",
    "# means one complete path from state, action, next_s, next_a, reward upuntil terminal state\n",
    "\n",
    "    nepisod = 30 #2 #np.shape(actions)[1]  ##22+ \n",
    "    \n",
    "    predicted_states, _ = train_lstm_model()\n",
    "\n",
    "    \n",
    "    tuplesMx0, tuplesMx1, tuplesMx2, tuplesMx3, tuplesMx4, tuplesMx5, tuplesMx6, tuplesMx7, tuplesMx8, tuplesMx9, tuplesMx10, tuplesMx11 = tuple_(predicted_states) \n",
    "    \n",
    "    num_rows = np.shape(tuplesMx0)[0] #-1\n",
    "    \n",
    "    Q_predicted = np.zeros([num_rows, 12]) #num_rows, num_columns\n",
    "    \n",
    "    best_action = np.zeros([num_rows, 1])\n",
    "#     Q_optimal = np.zeros([nepisod, num_rows])\n",
    "    \n",
    "    for i in xrange(nepisod):\n",
    "        Q_optimal = train_x['rew'].values.astype(np.float32) + gamma*Q_predicted.max(axis=1) #np.max(Q_predicted) # returns max value per row !\n",
    "        Q_predicted0 = DQN_train(tuplesMx0, Q_optimal)\n",
    "        Q_predicted1 = DQN_train(tuplesMx1, Q_optimal)\n",
    "        Q_predicted2 = DQN_train(tuplesMx2, Q_optimal)\n",
    "        Q_predicted3 = DQN_train(tuplesMx3, Q_optimal)\n",
    "        Q_predicted4 = DQN_train(tuplesMx4, Q_optimal)\n",
    "        Q_predicted5 = DQN_train(tuplesMx5, Q_optimal)\n",
    "        Q_predicted6 = DQN_train(tuplesMx6, Q_optimal)\n",
    "        Q_predicted7 = DQN_train(tuplesMx7, Q_optimal)\n",
    "        Q_predicted8 = DQN_train(tuplesMx8, Q_optimal)\n",
    "        Q_predicted9 = DQN_train(tuplesMx9, Q_optimal)\n",
    "        Q_predicted10 = DQN_train(tuplesMx10, Q_optimal)\n",
    "        Q_predicted11 = DQN_train(tuplesMx11, Q_optimal)\n",
    "        Q_predicted = np.column_stack((Q_predicted0, Q_predicted1, Q_predicted2, Q_predicted3,\n",
    "                                          Q_predicted4, Q_predicted5, Q_predicted6, Q_predicted7,\n",
    "                                          Q_predicted8, Q_predicted9, Q_predicted10, Q_predicted11))\n",
    "\n",
    "            \n",
    "    best_action = np.argmax(Q_predicted, axis = 1) \n",
    "         \n",
    "    return best_action, Q_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 0, ..., 1, 0, 1]),\n",
       " array([ 14.4,   5.4,  11.4, ...,   5.4,   5.4,   5.4]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_action, Q_optimal = Q_learning()\n",
    "best_action, Q_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.5163759999847439"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(Q_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('test.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "pd.DataFrame(Q_optimal).to_excel(writer, sheet_name='Sheet1')\n",
    "pd.DataFrame(best_action).to_excel(writer, sheet_name='Sheet2')\n",
    "\n",
    "# # Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
