{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "Main Goals:\n",
    "\n",
    "1. Identify the recipients that will engage with the campaign.\n",
    "2. Maximise the campaign’s revenue.\n",
    "\n",
    "\n",
    "Comments\n",
    "\n",
    "- The dataset contains only 5% of donors.\n",
    "- The donations are usually smaller than $20.\n",
    "- This data is quite noisy, high dimensional.\n",
    "- There is an inverse relationship between the probability to donate and the amount donated.\n",
    "\n",
    "\n",
    "Link for dataset and some analysis ==> \n",
    "\n",
    "https://github.com/rebordao/kdd98cup\n",
    "\n",
    "https://github.com/bobbyantonio/KDD98/blob/master/CleanData.py\n",
    "\n",
    "- Github solutions ==>\n",
    "https://github.com/rebordao/kdd98cup\n",
    "\n",
    "\n",
    "- Siraj notebook for a better data visualization:\n",
    "\n",
    "https://www.youtube.com/watch?v=yQsOFWqpjkE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "## plotting .. \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "# import datetime as dt\n",
    "\n",
    "## warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    list_of_lists = []\n",
    "\n",
    "    ## works correctly but takes too much running time ..\n",
    "    with open('cup98LRN.txt', 'r') as f:# open the file for reading\n",
    "        df = []\n",
    "        for row_num, line in enumerate(f):\n",
    "            # Remove the new line at the end and then split the string based on\n",
    "            # tabs. This creates a python list of the values.\n",
    "            values = line.strip().split(',')\n",
    "            if row_num == 0: # first line is the header\n",
    "                 header = values\n",
    "            else:\n",
    "                df.append([v for v in values])\n",
    "\n",
    "        df = pd.DataFrame(df)\n",
    "        df.columns = header\n",
    "        df.drop(df.index[0], inplace=True)\n",
    "        \n",
    "        df = df[0:1000]  ## to save time .. I gonna work on only 100 records ..\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODATEDW</th>\n",
       "      <th>OSOURCE</th>\n",
       "      <th>TCODE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>MAILCODE</th>\n",
       "      <th>PVASTATE</th>\n",
       "      <th>DOB</th>\n",
       "      <th>NOEXCH</th>\n",
       "      <th>RECINHSE</th>\n",
       "      <th>...</th>\n",
       "      <th>TARGET_D</th>\n",
       "      <th>HPHONE_D</th>\n",
       "      <th>RFA_2R</th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>RFA_2A</th>\n",
       "      <th>MDMAUD_R</th>\n",
       "      <th>MDMAUD_F</th>\n",
       "      <th>MDMAUD_A</th>\n",
       "      <th>CLUSTER2</th>\n",
       "      <th>GEOCODE2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9401</td>\n",
       "      <td>BOA</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>91326</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5202</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>2</td>\n",
       "      <td>G</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9001</td>\n",
       "      <td>AMH</td>\n",
       "      <td>1</td>\n",
       "      <td>NC</td>\n",
       "      <td>27017</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8701</td>\n",
       "      <td>BRY</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>95953</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2801</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>41</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 481 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ODATEDW OSOURCE TCODE STATE    ZIP MAILCODE PVASTATE   DOB NOEXCH RECINHSE  \\\n",
       "1    9401     BOA     1    CA  91326                    5202      0            \n",
       "2    9001     AMH     1    NC  27017                       0      0            \n",
       "3    8701     BRY     0    CA  95953                    2801      0            \n",
       "\n",
       "    ...    TARGET_D HPHONE_D RFA_2R RFA_2F RFA_2A MDMAUD_R MDMAUD_F MDMAUD_A  \\\n",
       "1   ...           0        0      L      2      G        X        X        X   \n",
       "2   ...           0        1      L      4      E        X        X        X   \n",
       "3   ...           0        1      L      4      E        X        X        X   \n",
       "\n",
       "  CLUSTER2 GEOCODE2  \n",
       "1        1        A  \n",
       "2       60        C  \n",
       "3       41        C  \n",
       "\n",
       "[3 rows x 481 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## I have to run it over all the data not just 100 records\n",
    "df = load_data()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only ADATE is valid .. \n",
    "\n",
    "RFA ==> only 3 characters not 4\n",
    "\n",
    "RAMNT_3, RDATE ==> are empty ! ..\n",
    "\n",
    "Continous actions .. \n",
    "\n",
    "Let's assume that ADATE represents the continous actions variable (i.e. the number of the month gifts have been sent in) ..\n",
    "\n",
    "RDATE represents the discrete variable .. action taken (i.e. action # 2, # 3 .. and null values will be replaced by 0, to reprsent no action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discrete + continuous actions \n",
    "def actions_prep(df):\n",
    "    \n",
    "    date_data = ['ADATE_3', 'ADATE_4', 'ADATE_5', 'ADATE_6', 'ADATE_7', 'ADATE_8', \n",
    "                'ADATE_9', 'ADATE_10', 'ADATE_11', 'ADATE_12', 'ADATE_13', 'ADATE_14', 'ADATE_15',\n",
    "                'ADATE_16', 'ADATE_16', 'ADATE_17', 'ADATE_18', 'ADATE_19', 'ADATE_20', 'ADATE_12',\n",
    "                'ADATE_22', 'ADATE_23', 'ADATE_24', 'RDATE_3', 'RDATE_4', 'RDATE_5', 'RDATE_6', 'RDATE_7', 'RDATE_8', \n",
    "                'RDATE_9', 'RDATE_10', 'RDATE_11', 'RDATE_12', 'RDATE_13', 'RDATE_14', 'RDATE_15',\n",
    "                'RDATE_16', 'RDATE_16', 'RDATE_17', 'RDATE_18', 'RDATE_19', 'RDATE_20', 'RDATE_12',\n",
    "                'RDATE_22', 'RDATE_23', 'RDATE_24']\n",
    "    t = []\n",
    "    temp = np.transpose(df[date_data])\n",
    "\n",
    "    for j in xrange(len(temp)):\n",
    "        for i in xrange(np.shape(df)[0]):\n",
    "             t.append(temp.iloc[j].iloc[i][2:])\n",
    "\n",
    "    actions = np.reshape(t, [46, np.shape(df[date_data])[0]])\n",
    "    actions = pd.DataFrame(np.transpose(actions))\n",
    "   \n",
    "    actions = actions.replace('', 0)\n",
    "    \n",
    "    return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping .. to inforce max action to be 11  \n",
    "\n",
    "                              2: 'NK',  3: 'NK',\n",
    "                              4: 'TK',  5: 'SK',\n",
    "                              6: 'LL',  7: 'G1',\n",
    "                              8: 'GK',  9: 'CC',\n",
    "                              10: 'WL', 11: 'X1',\n",
    "                              12: 'XK', 13: 'FS',\n",
    "                              14: 'NK', 15: 'TK',\n",
    "                              16: 'LL', 17: 'G1',\n",
    "                              18: 'GK', 19: 'CC',\n",
    "                              20: 'WL', 21: 'X1',\n",
    "                              22: 'XK', 23: 'FS', 24: 'NK'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing:\n",
    "\n",
    "1. Gets some redundant variables .. by calculating the correlation between all the variables .. \n",
    "those of high correlation coeffecient are redundant .. \n",
    "\n",
    "__NOTE:__\n",
    "In this implementation .. \n",
    "\n",
    "https://github.com/EAboelhamd/kdd98cup/blob/master/donors.py\n",
    "\n",
    "They tried to figure out redundant variables to remove them .. to be able to decrease the dimentionality of the problem .. however, in my case, there is no need to do .. as I'm gonna implement deep learning not a shallow solution .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preperation():\n",
    "    df = load_data()\n",
    "    \n",
    "    df = df[df.columns.difference(['TARGET_B'])]\n",
    "    \n",
    "    actions = actions_prep(df)\n",
    "    \n",
    "    data = ['RFA_2','RFA_3','RFA_4','RFA_5','RFA_6','RFA_7','RFA_8','RFA_9','RFA_10','RFA_11','RFA_12',\n",
    "            'RFA_13','RFA_14','RFA_15','RFA_16','RFA_17','RFA_18','RFA_19','RFA_20','RFA_21','RFA_22','RFA_23','RFA_24'\n",
    "            ,'RAMNT_3', 'RAMNT_4','RAMNT_5','RAMNT_6', 'RAMNT_7','RAMNT_8','RAMNT_9', 'RAMNT_10',\n",
    "          'RAMNT_11','RAMNT_12','RAMNT_13','RAMNT_14','RAMNT_15','RAMNT_16','RAMNT_17','RAMNT_18','RAMNT_19','RAMNT_20'\n",
    "          ,'RAMNT_21','RAMNT_22','RAMNT_23','RAMNT_24']\n",
    "    \n",
    "    \n",
    "    for i in xrange(len(data)):\n",
    "        df[data[i]] = pd.Categorical((pd.factorize(df[data[i]])[0] + 1).astype(str))\n",
    "    \n",
    "    rewards = ['TARGET_D']\n",
    "    \n",
    "    df_data_1 = pd.merge(df[data], df[rewards], left_index = True, right_index = True)\n",
    "    df_data = pd.merge(df_data_1, actions, left_index=True, right_index=True)\n",
    "    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_split():  \n",
    "    df_data = data_preperation()\n",
    "    train, test = train_test_split(df_data, test_size = 0.5)  # split data to 50-50 cross validate \n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df_split()\n",
    "test = test.drop(test.index[len(test)-1]) ## exclude last row in test to have same number of rows as train \n",
    "\n",
    "## prepare train, test\n",
    "rewards = ['TARGET_D']\n",
    "x_train = train[train.columns.difference(['TARGET_D'])]\n",
    "y_train = train[rewards]\n",
    "\n",
    "x_test = test[test.columns.difference(['TARGET_D'])]\n",
    "y_test = test[rewards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RFA_2</th>\n",
       "      <th>RFA_3</th>\n",
       "      <th>RFA_4</th>\n",
       "      <th>RFA_5</th>\n",
       "      <th>RFA_6</th>\n",
       "      <th>RFA_7</th>\n",
       "      <th>RFA_8</th>\n",
       "      <th>RFA_9</th>\n",
       "      <th>RFA_10</th>\n",
       "      <th>RFA_11</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>42</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>36</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>04</td>\n",
       "      <td>04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>04</td>\n",
       "      <td>04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>51</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RFA_2 RFA_3 RFA_4 RFA_5 RFA_6 RFA_7 RFA_8 RFA_9 RFA_10 RFA_11 ...  36  37  \\\n",
       "873    11    19    19    25    36    12     2     5      2      2 ...   0   0   \n",
       "754     8    10    10     9    10     9     8     8      7      7 ...   0   0   \n",
       "119     2    27    28    21    42    46    46    36     23     27 ...  04  04   \n",
       "738     7     9     9     8    35    28    29    35     36     33 ...  04  04   \n",
       "568     3     8     8     7    51    46    46     9      2     65 ...   0   0   \n",
       "\n",
       "    38 39 40  41  42  43 44 45  \n",
       "873  0  0  0   0  09   0  0  0  \n",
       "754  0  0  0   0   0   0  0  0  \n",
       "119  0  0  0   0   0  09  0  0  \n",
       "738  0  0  0  12   0   0  0  0  \n",
       "568  0  0  0  11  10  12  0  0  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current State variables ..\n",
    "Recency, Frequancy, Montery variables .. ['RFA_2R', 'RFA_2F', 'RFA_2A']\n",
    "\n",
    "## Rewards:\n",
    "- Donation amount \n",
    "- These are the target variables as well .. \n",
    "- TARGET_D, TARGET_B \n",
    "\n",
    "\n",
    "## Actions: \n",
    "- 11 mailing type\n",
    "\n",
    "Actions mapping .. \n",
    "https://github.com/EAboelhamd/kdd98-1/tree/master/notebooks\n",
    "\n",
    "## Actions:\n",
    "\n",
    "- mailing types ..\n",
    "action_mapping = {\n",
    "\n",
    "                                    2: 'NK',  3: 'NK',\n",
    "                                    4: 'TK',  5: 'SK',\n",
    "                                    6: 'LL',  7: 'G1',\n",
    "                                    8: 'GK',  9: 'CC',\n",
    "                                    10: 'WL', 11: 'X1',\n",
    "                                    12: 'XK', 13: 'FS',\n",
    "                                    14: 'NK', 15: 'TK',\n",
    "                                    16: 'LL', 17: 'G1',\n",
    "                                    18: 'GK', 19: 'CC',\n",
    "                                    20: 'WL', 21: 'X1',\n",
    "                                    22: 'XK', 23: 'FS', 24: 'NK'\n",
    "                                }\n",
    "\n",
    "this list contains 11 unique values (NK, TK,LL,GK,WL,XK,SK,G1,CC,X1,FS)\n",
    "\n",
    "                                        NK ==> 2, 14, 23, 24\n",
    "                                        LL ==> 2, 16\n",
    "                                        TK ==> 4, 15\n",
    "                                        GK ==> 8, 18\n",
    "                                        WL ==> 10, 20\n",
    "                                        SK ==> 5\n",
    "                                        G1 ==> 7, 17\n",
    "                                        CC ==> 9, 19\n",
    "                                        X1 ==> 11, 21\n",
    "                                        FS ==> 13, 23\n",
    "\n",
    "Their corresponding meanings are:\n",
    "\n",
    "                                        LL mailings had labels only                                        \n",
    "                                        WL mailings had labels only\n",
    "                                        CC mailings are calendars with stickers but do\n",
    "                                           not have labels\n",
    "                                        FS mailings are blank cards that fold into\n",
    "                                           thirds with labels\n",
    "                                        NK mailings are blank cards with labels\n",
    "                                        SK mailings are blank cards with labels\n",
    "                                        TK mailings have thank you printed on the\n",
    "                                           outside with labels\n",
    "                                        GK mailings are general greeting cards (an\n",
    "                                           assortment of birthday, sympathy, blank, & get\n",
    "                                           well) with labels\n",
    "                                        XK mailings are Christmas cards with labels\n",
    "                                        X1 mailings have labels and a notepad\n",
    "                                        G1 mailings have labels and a notepad\n",
    "\n",
    "- This is why I'm gonna extract the last two digits from the sequance to represent mailing type (unique values are 11 .. NK, TK, SK, LL, G1, GK, CC, WL, X1, XK, FS) + no action .. total action are 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## States:\n",
    "\n",
    "In the cited paper .. they defined the states as follows: \n",
    "\n",
    "It is a 5-dimensional vector consisting of \n",
    "\n",
    "(1) how recently the donor donated last (R)\n",
    "\n",
    "(2) how frequently she donates (F)\n",
    "\n",
    "(3) her average donation amount (M)\n",
    "\n",
    "(4) how many times PVA sends her a mail in the last six months\n",
    "\n",
    "(5) how many times PVA has sent her mails.\n",
    "\n",
    "\n",
    "This implementation is considered as a POMPD .. \n",
    "where:\n",
    "b: belief state that is a probability distribution over all states\n",
    "b(s): prob. that the agent in state s \n",
    "after taking action a and observing the state O .. the update rule for the belief state o(s) is using Bayes rule .. \n",
    "\n",
    "## Next States:\n",
    "\n",
    "As mentioned in the paper ==> the 5-dimensional observation is discrete in this problem, and individual dimensions evolve\n",
    "independently of each other. We therefore build an observation probability table for each observation dimension,\n",
    "and the sample next observations using these tables.\n",
    "\n",
    "Hence, Let's create an n*5 dim observations table .. \n",
    "\n",
    "http://www-anw.cs.umass.edu/~barto/courses/cs687/PartialObs-printable.pdf\n",
    "\n",
    "\n",
    "### These researchers proposed other types of state space ==>\n",
    "\n",
    "https://www.cs.cmu.edu/~ebrun/15889e/hw1.pdf\n",
    "\n",
    "as 9 vars (try it out) ;) .. \n",
    "and others consider (belief, observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_(actions):\n",
    "    \n",
    "    train, test = df_split()\n",
    "    \n",
    "    RFA = ['RFA_2']  # don't know if it is NUMPRM12 or CARDPM12 \n",
    "\n",
    "    ## next state\n",
    "    ## next_states are random selection from the current states\n",
    "    RFA_next = ['RFA_3', 'RFA_4', 'RFA_5', 'RFA_6', 'RFA_7', 'RFA_8', 'RFA_9', 'RFA_10',\n",
    "                'RFA_11', 'RFA_12', 'RFA_13', 'RFA_14', 'RFA_15', 'RFA_16', 'RFA_17', 'RFA_18',\n",
    "                'RFA_19', 'RFA_20', 'RFA_21', 'RFA_22', 'RFA_23', 'RFA_24']\n",
    "\n",
    "    current_states = train['RFA_2']\n",
    "    next_states = train[RFA_next]\n",
    "    \n",
    "    rewards = ['TARGET_D']\n",
    "     \n",
    "    next_actions = np.zeros([len(next_states), 12])\n",
    "    \n",
    "    \n",
    "    #     # fill in next_actions  \n",
    "    for i in xrange(np.shape(next_actions)[1]):\n",
    "        next_actions[:, i] = i\n",
    "    \n",
    "    tuplesMx = np.column_stack((current_states.values, actions.values, next_states.values, next_actions, train[rewards].values))\n",
    "\n",
    "    return tuplesMx #next_states, next_actions, curr_state_current_action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression phase:\n",
    "\n",
    "Before performing the prediction task .. let's split the data to training and validation sets .. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid any problems in prediction by having string variables .. let's binarize (catergorize) all the variables .. \n",
    "\n",
    "Guidance ==> https://pythonprogramming.net/rnn-tensorflow-python-machine-learning-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma = 0.9\n",
    "Num_itrs = 2  # no loop 3leha ( w dah el sa7) .. we just have to run the whole algo. 10 times and report the avg. results\n",
    "\n",
    "num_epoch = 1 #23 #epochs are cycles of Feedforward and Backprob\n",
    "## el mafrood yeb2a feh loop 3la el epochs elli heyya el steps .. w avg. reward per step is calculated \n",
    "batch_size = 10 #np.shape(x_train)[0]\n",
    "chunkSize = 1\n",
    "\n",
    "n_nodes_hl1 = 40 #np.shape(x_train)[1]\n",
    "n_nodes_hl2 = 15 #np.shape(x_train)[0]\n",
    "NUM_STATES = np.shape(x_train)[1]\n",
    "NUM_DIM =  np.shape(x_train)[1]\n",
    "num_nodes = np.shape(x_train)[0]\n",
    "num_unrollings = 5\n",
    "\n",
    "best_actions = np.zeros([np.shape(x_train)[0], batch_size])\n",
    "Q_optimal = [] #np.zeros([np.shape(curr_state_current_action)[0], len(df['ACCOUNT_STATUS'].unique())])\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Deep Neural Network (DQN):\n",
    "\n",
    "https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/blob/master/contents/5_Deep_Q_Network/RL_brain.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training:\n",
    "\n",
    "https://stackoverflow.com/questions/46832151/tensorflow-neural-network-multi-layer-perceptron-for-regression-example\n",
    "\n",
    "Guidance: https://www.youtube.com/watch?v=FbJw8J0rTyQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN_train():\n",
    "    ######################## set learning variables ##################\n",
    "    learning_rate = 0.0001  #Learning rate controls how much to change the weight to correct for the error. \n",
    "    epochs = 2000\n",
    "    \n",
    "#     num_nodes = batch_size\n",
    "    \n",
    "#     batch_size = np.shape(x_train)[0]\n",
    "\n",
    "    ## well, I need to update these network to output 49 neuron in output layer, with 40, 15 hidden neurons \n",
    "    \n",
    "    ######################## set some variables #######################\n",
    "    x = tf.placeholder(tf.float32)  # 3 features  # , [None, NUM_DIM], name='x'\n",
    "    y = tf.placeholder(tf.float32)  # 3 outputs   # , [None, 1], name='y'\n",
    "\n",
    "    print x \n",
    "    \n",
    "    # hidden layer 1\n",
    "    W1 = tf.Variable(tf.random_uniform([NUM_DIM, n_nodes_hl1],0,1), name='W1')\n",
    "    b1 = tf.Variable(tf.random_uniform([n_nodes_hl1],0,1), name='b1')\n",
    "\n",
    "    # hidden layer 2\n",
    "    W2 = tf.Variable(tf.random_uniform([n_nodes_hl1, n_nodes_hl2],0,1), name='W2')\n",
    "    b2 = tf.Variable(tf.random_uniform([n_nodes_hl2],0,1), name='b2')\n",
    "\n",
    "    ######################## Activations, outputs ######################\n",
    "    # output hidden layer 1\n",
    "    hidden_out = tf.nn.relu(tf.add(tf.matmul(x, W1), b1))\n",
    "\n",
    "#     total output\n",
    "    y_ = tf.nn.relu(tf.add(tf.matmul(hidden_out, W2), b2))\n",
    "\n",
    "    \n",
    "    ####################### Loss Function  #########################\n",
    "    mse = tf.losses.mean_squared_error(y, y_)\n",
    "\n",
    "    ####################### Optimizer      #########################\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(mse)\n",
    "\n",
    "    ###################### Initialize, Accuracy and Run #################\n",
    "    # initialize variables\n",
    "    init_op = tf.global_variables_initializer()\n",
    "\n",
    "    # accuracy for the test set\n",
    "    accuracy = tf.reduce_mean(tf.square(tf.subtract(y, y_)))  # or could use tf.losses.mean_squared_error\n",
    "\n",
    "    loss_RNN = []\n",
    "    \n",
    "    avg_ = []\n",
    "    \n",
    "    # run\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        total_batch = int(len(y_train) / batch_size)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            avg_cost = 0\n",
    "            \n",
    "            for i in range(total_batch):\n",
    "                batch_x, batch_y = x_train[i * batch_size:min(i * batch_size + batch_size, len(x_train))], \\\n",
    "                             y_train[i * batch_size:min(i * batch_size + batch_size, len(y_train))]\n",
    "                \n",
    "            predicted_output = sess.run(y_, feed_dict={x: batch_x, y: batch_y.values})\n",
    "                \n",
    "            _, c = sess.run([optimizer, mse], feed_dict={x: x_train, y: y_train.values})\n",
    "            avg_cost += c / total_batch          \n",
    "            \n",
    "            if epoch % 100 == 0:\n",
    "                avg_.append(avg_cost)\n",
    "                plt.plot(avg_)\n",
    "                plt.xlabel('Step Number')\n",
    "                plt.ylabel('Prediction Loss')\n",
    "        return np.shape(predicted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_18:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "predicted_output = DQN_train()\n",
    "predicted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN_predict():\n",
    "    \n",
    "    W1, W2, b1, b2, hidden_out = DQN_train()\n",
    "    \n",
    "    x_ = tf.placeholder(tf.float32)  # 3 features, , [num_nodes, NUM_DIM], name='x_'\n",
    "    y_ = tf.placeholder(tf.float32)  # 3 outputs,  , [num_nodes, 1], name='y_'\n",
    "    \n",
    "    # total output\n",
    "    model_output = tf.nn.relu(tf.add(tf.matmul(hidden_out, W2), b2))\n",
    "\n",
    "    \n",
    "    with tf.Session() as sess2:\n",
    "        print sess2.run(model_output, feed_dict={x_:x_test, y_: y_test})\n",
    "    \n",
    "#     return predicted_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_36:0\", dtype=float32)\n",
      "[161736240.0, 19.876251220703125, 19.8759765625, 19.87571907043457, 19.875450134277344, 19.875265121459961, 19.875, 19.874757766723633, 19.874519348144531, 19.874265670776367, 19.874053955078125, 19.873794555664062, 19.873559951782227, 19.873281478881836, 19.873037338256836, 19.872787475585938, 19.872600555419922, 19.87236213684082, 19.872087478637695, 19.871820449829102]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_36' with dtype float\n\t [[Node: Placeholder_36 = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op u'Placeholder_36', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-48-f560e25e6c46>\", line 1, in <module>\n    DQN_predict()\n  File \"<ipython-input-47-ed8233e233cf>\", line 3, in DQN_predict\n    W1, W2, b1, b2, hidden_out = DQN_train()\n  File \"<ipython-input-43-91eb70cc3e10>\", line 13, in DQN_train\n    x = tf.placeholder(tf.float32)  # 3 features  # , [None, NUM_DIM], name='x'\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 1599, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3091, in _placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_36' with dtype float\n\t [[Node: Placeholder_36 = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-f560e25e6c46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDQN_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-47-ed8233e233cf>\u001b[0m in \u001b[0;36mDQN_predict\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mprint\u001b[0m \u001b[0msess2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#     return predicted_reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_36' with dtype float\n\t [[Node: Placeholder_36 = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op u'Placeholder_36', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-48-f560e25e6c46>\", line 1, in <module>\n    DQN_predict()\n  File \"<ipython-input-47-ed8233e233cf>\", line 3, in DQN_predict\n    W1, W2, b1, b2, hidden_out = DQN_train()\n  File \"<ipython-input-43-91eb70cc3e10>\", line 13, in DQN_train\n    x = tf.placeholder(tf.float32)  # 3 features  # , [None, NUM_DIM], name='x'\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 1599, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3091, in _placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_36' with dtype float\n\t [[Node: Placeholder_36 = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAERCAYAAACU1LsdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nh4KZmU1xKJiZ2RSHgpmZTfn/cpcgwR0T43kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d742d2810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DQN_predict()\n",
    "\n",
    "# 6yeb delw2ty I have to search for ezzay 23mil testing ll model w a output el y_predicted .. \n",
    "# however, el training works well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def init_weights(shape):\n",
    "#     return tf.Variable(tf.random_uniform(shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # Definition of the cell computation.\n",
    "# # this method takes single cell and returns single number \n",
    "# def lstm_cell(i, o, state):\n",
    "#     input_gate = tf.sigmoid(tf.matmul(i, ix) + tf.matmul(o, im) + ib)\n",
    "#     forget_gate = tf.sigmoid(tf.matmul(i, fx) + tf.matmul(o, fm) + fb)\n",
    "#     update = tf.matmul(i, cx) + tf.matmul(o, cm) + cb\n",
    "#     state = forget_gate * state + input_gate * tf.tanh(update)\n",
    "#     output_gate = tf.sigmoid(tf.matmul(i, ox) + tf.matmul(o, om) + ob)\n",
    "#     return output_gate * tf.tanh(state), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def DQN_model(X, w_h_1, w_h_2, w_o, bias_I_1, bias_I_2, bias_h):\n",
    "       \n",
    "#     layer_1 = tf.matmul(X, w_h_1) + bias_I_1\n",
    "#     layer_1 = tf.nn.relu(layer_1)  ## el performance of softmax outperforms relu!!\n",
    "    \n",
    "#     layer_2 = tf.matmul(layer_1, w_h_2) + bias_I_2\n",
    "#     layer_2 = tf.nn.sigmoid(layer_2) \n",
    "\n",
    "#     py_x = tf.matmul(layer_2, w_o) + bias_h\n",
    "    \n",
    "#     return py_x  #predicted output\n",
    "#     # note that we dont take the softmax at the end because our cost fn does that for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def DQN_training(X, output):\n",
    "    \n",
    "#     w_h_1 = init_weights([np.shape(X)[1], n_nodes_hl1]) # create symbolic variables\\n\",\n",
    "#     w_h_2 = init_weights([n_nodes_hl1, n_nodes_hl2]) # create symbolic variables\\n\",\n",
    "#     w_o = init_weights([n_nodes_hl2, 1])\n",
    "    \n",
    "#     bias_I_1=init_weights([n_nodes_hl1])\n",
    "#     bias_I_2=init_weights([n_nodes_hl2])\n",
    "#     bias_h=init_weights([1])\n",
    "    \n",
    "#     X = pd.DataFrame(X)\n",
    "    \n",
    "#     py_x = DQN_model(X.convert_objects(convert_numeric=True).astype(np.float32), w_h_1, w_h_2, w_o, bias_I_1, bias_I_2,bias_h)  #model training  \n",
    "    \n",
    "#     cost = tf.reduce_mean(tf.square(output - py_x)) # compute costs\",  # excpect float32\n",
    "\n",
    "#     train_op = tf.train.GradientDescentOptimizer(0.01).minimize(cost) # construct an optimizer\\n\",\n",
    "\n",
    "#     sess = tf.Session()\n",
    "#     init = tf.global_variables_initializer()\n",
    "#     sess.run(init)    \n",
    "#     sess.close()  \n",
    "    \n",
    "#     return w_h_1, w_h_2, w_o,bias_I_1, bias_I_2,bias_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Prediction phase: \n",
    "# def DQN_predict(tuplesMx, output):\n",
    "\n",
    "#     w_h_1, w_h_2, w_o,bias_I_1, bias_I_2,bias_h = DQN_training(tuplesMx, output)\n",
    "    \n",
    "#     tuplesMx = pd.DataFrame(tuplesMx)\n",
    "#     predict_op_0 = DQN_model(tuplesMx.convert_objects(convert_numeric=True).astype(np.float32), w_h_1, w_h_2, w_o,bias_I_1, bias_I_2,bias_h)\n",
    "    \n",
    "#     sess2 = tf.Session()\n",
    "#     init2 = tf.global_variables_initializer()\n",
    "#     sess2.run(init2)\n",
    "\n",
    "#     l0 = sess2.run(predict_op_0)\n",
    "        \n",
    "#     Q_predicted = l0  #, l1, l2, l3, l4, l5, l6\n",
    "    \n",
    "#     sess2.close()\n",
    "    \n",
    "#     return Q_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q(s,a) representing the (Quality) of action a at state is .. \n",
    "\n",
    "this Q value depends on the immediate reward r .. however, it'll be more effective if it takes the future rewards Q(s', a') into consideration .. \n",
    "\n",
    "the future rewards are discounted by probability gama .. cause the evironment is stochastic hence, it is uncertain that each time you select action a you gonna get the same reward r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_reward = np.transpose(predicted_reward) \n",
    "def Q_learning():\n",
    "    \n",
    "    avg_Q = []\n",
    "    tuplesMx = []\n",
    "    rewards = ['TARGET_D']\n",
    "    \n",
    "    Q_predicted = np.zeros([np.shape(train)[0], 12])\n",
    "    best_action = list() #np.zeros([np.shape(train)[0], batch_size])\n",
    "    \n",
    "    actions = actions_prep(df)\n",
    "    nepisod = np.shape(actions)[1]  ##22\n",
    "    \n",
    "    for i in xrange(nepisod):\n",
    "        tuplesMx = tuple_(actions[:49][i])\n",
    "        print tuplesMx\n",
    "        \n",
    "        Q_optimal = train[rewards].values.astype(int) + gamma*np.max(Q_predicted) # returns max value per row !\n",
    "#             Q_optimal = np.array(Q_optimal, dtype = np.float32) # convert output to float32 to match py_x\n",
    "        \n",
    "        Q_predicted = DQN_predict(tuplesMx, Q_optimal) \n",
    "   \n",
    "        try:\n",
    "            best_action.append(np.argmax(Q_predicted, axis=0))\n",
    "#             avg_Q.append(np.mean(Q_optimal))\n",
    "        except ValueError:\n",
    "            print \"Error\"\n",
    "            continue\n",
    "        \n",
    "        \n",
    "#         _, predicted_reward = train_lstm_model()\n",
    "        \n",
    "#         for j in xrange(len(tuplesMx)): #(0, len(tuplesMx), batch_size):\n",
    "            \n",
    "#         print Q_predicted\n",
    "    \n",
    "    return best_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
