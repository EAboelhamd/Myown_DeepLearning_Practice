{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "Main Goals:\n",
    "\n",
    "1. Identify the recipients that will engage with the campaign.\n",
    "2. Maximise the campaign’s revenue.\n",
    "\n",
    "\n",
    "Comments\n",
    "\n",
    "- The dataset contains only 5% of donors.\n",
    "- The donations are usually smaller than $20.\n",
    "- This data is quite noisy, high dimensional.\n",
    "- There is an inverse relationship between the probability to donate and the amount donated.\n",
    "\n",
    "\n",
    "Link for dataset and some analysis ==> \n",
    "\n",
    "https://github.com/rebordao/kdd98cup\n",
    "\n",
    "https://github.com/bobbyantonio/KDD98/blob/master/CleanData.py\n",
    "\n",
    "- Github solutions ==>\n",
    "https://github.com/rebordao/kdd98cup\n",
    "\n",
    "\n",
    "- Siraj notebook for a better data visualization:\n",
    "\n",
    "https://www.youtube.com/watch?v=yQsOFWqpjkE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "## plotting .. \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "# import datetime as dt\n",
    "\n",
    "## warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    list_of_lists = []\n",
    "\n",
    "    ## works correctly but takes too much running time ..\n",
    "    with open('cup98LRN.txt', 'r') as f:# open the file for reading\n",
    "        df = []\n",
    "        for row_num, line in enumerate(f):\n",
    "            # Remove the new line at the end and then split the string based on\n",
    "            # tabs. This creates a python list of the values.\n",
    "            values = line.strip().split(',')\n",
    "            if row_num == 0: # first line is the header\n",
    "                 header = values\n",
    "            else:\n",
    "                df.append([v for v in values])\n",
    "\n",
    "        df = pd.DataFrame(df)\n",
    "        df.columns = header\n",
    "        df.drop(df.index[0], inplace=True)\n",
    "        \n",
    "        df = df[0:1000]  ## to save time .. I gonna work on only 100 records ..\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODATEDW</th>\n",
       "      <th>OSOURCE</th>\n",
       "      <th>TCODE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>MAILCODE</th>\n",
       "      <th>PVASTATE</th>\n",
       "      <th>DOB</th>\n",
       "      <th>NOEXCH</th>\n",
       "      <th>RECINHSE</th>\n",
       "      <th>...</th>\n",
       "      <th>TARGET_D</th>\n",
       "      <th>HPHONE_D</th>\n",
       "      <th>RFA_2R</th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>RFA_2A</th>\n",
       "      <th>MDMAUD_R</th>\n",
       "      <th>MDMAUD_F</th>\n",
       "      <th>MDMAUD_A</th>\n",
       "      <th>CLUSTER2</th>\n",
       "      <th>GEOCODE2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9401</td>\n",
       "      <td>BOA</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>91326</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5202</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>2</td>\n",
       "      <td>G</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9001</td>\n",
       "      <td>AMH</td>\n",
       "      <td>1</td>\n",
       "      <td>NC</td>\n",
       "      <td>27017</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8701</td>\n",
       "      <td>BRY</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>95953</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2801</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>41</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 481 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ODATEDW OSOURCE TCODE STATE    ZIP MAILCODE PVASTATE   DOB NOEXCH RECINHSE  \\\n",
       "1    9401     BOA     1    CA  91326                    5202      0            \n",
       "2    9001     AMH     1    NC  27017                       0      0            \n",
       "3    8701     BRY     0    CA  95953                    2801      0            \n",
       "\n",
       "    ...    TARGET_D HPHONE_D RFA_2R RFA_2F RFA_2A MDMAUD_R MDMAUD_F MDMAUD_A  \\\n",
       "1   ...           0        0      L      2      G        X        X        X   \n",
       "2   ...           0        1      L      4      E        X        X        X   \n",
       "3   ...           0        1      L      4      E        X        X        X   \n",
       "\n",
       "  CLUSTER2 GEOCODE2  \n",
       "1        1        A  \n",
       "2       60        C  \n",
       "3       41        C  \n",
       "\n",
       "[3 rows x 481 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## I have to run it over all the data not just 100 records\n",
    "df = load_data()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only ADATE is valid .. \n",
    "\n",
    "RFA ==> only 3 characters not 4\n",
    "\n",
    "RAMNT_3, RDATE ==> are empty ! ..\n",
    "\n",
    "Continous actions .. \n",
    "\n",
    "Let's assume that ADATE represents the continous actions variable (i.e. the number of the month gifts have been sent in) ..\n",
    "\n",
    "RDATE represents the discrete variable .. action taken (i.e. action # 2, # 3 .. and null values will be replaced by 0, to reprsent no action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discrete + continuous actions \n",
    "def actions_prep(df):\n",
    "    \n",
    "    date_data = ['ADATE_3', 'ADATE_4', 'ADATE_5', 'ADATE_6', 'ADATE_7', 'ADATE_8', \n",
    "                'ADATE_9', 'ADATE_10', 'ADATE_11', 'ADATE_12', 'ADATE_13', 'ADATE_14', 'ADATE_15',\n",
    "                'ADATE_16', 'ADATE_16', 'ADATE_17', 'ADATE_18', 'ADATE_19', 'ADATE_20', 'ADATE_12',\n",
    "                'ADATE_22', 'ADATE_23', 'ADATE_24', 'RDATE_3', 'RDATE_4', 'RDATE_5', 'RDATE_6', 'RDATE_7', 'RDATE_8', \n",
    "                'RDATE_9', 'RDATE_10', 'RDATE_11', 'RDATE_12', 'RDATE_13', 'RDATE_14', 'RDATE_15',\n",
    "                'RDATE_16', 'RDATE_16', 'RDATE_17', 'RDATE_18', 'RDATE_19', 'RDATE_20', 'RDATE_12',\n",
    "                'RDATE_22', 'RDATE_23', 'RDATE_24']\n",
    "    t = []\n",
    "    temp = np.transpose(df[date_data])\n",
    "\n",
    "    for j in xrange(len(temp)):\n",
    "        for i in xrange(np.shape(df)[0]):\n",
    "             t.append(temp.iloc[j].iloc[i][2:])\n",
    "\n",
    "    actions = np.reshape(t, [46, np.shape(df[date_data])[0]])\n",
    "    actions = pd.DataFrame(np.transpose(actions))\n",
    "   \n",
    "    actions = actions.replace('', 0)\n",
    "    \n",
    "    return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping .. to inforce max action to be 11  \n",
    "\n",
    "                              2: 'NK',  3: 'NK',\n",
    "                              4: 'TK',  5: 'SK',\n",
    "                              6: 'LL',  7: 'G1',\n",
    "                              8: 'GK',  9: 'CC',\n",
    "                              10: 'WL', 11: 'X1',\n",
    "                              12: 'XK', 13: 'FS',\n",
    "                              14: 'NK', 15: 'TK',\n",
    "                              16: 'LL', 17: 'G1',\n",
    "                              18: 'GK', 19: 'CC',\n",
    "                              20: 'WL', 21: 'X1',\n",
    "                              22: 'XK', 23: 'FS', 24: 'NK'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing:\n",
    "\n",
    "1. Gets some redundant variables .. by calculating the correlation between all the variables .. \n",
    "those of high correlation coeffecient are redundant .. \n",
    "\n",
    "__NOTE:__\n",
    "In this implementation .. \n",
    "\n",
    "https://github.com/EAboelhamd/kdd98cup/blob/master/donors.py\n",
    "\n",
    "They tried to figure out redundant variables to remove them .. to be able to decrease the dimentionality of the problem .. however, in my case, there is no need to do .. as I'm gonna implement deep learning not a shallow solution .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preperation():\n",
    "    df = load_data()\n",
    "    \n",
    "    df = df[df.columns.difference(['TARGET_B'])]\n",
    "    \n",
    "    actions = actions_prep(df)\n",
    "    \n",
    "    data = ['RFA_2','RFA_3','RFA_4','RFA_5','RFA_6','RFA_7','RFA_8','RFA_9','RFA_10','RFA_11','RFA_12',\n",
    "            'RFA_13','RFA_14','RFA_15','RFA_16','RFA_17','RFA_18','RFA_19','RFA_20','RFA_21','RFA_22','RFA_23','RFA_24'\n",
    "            ,'RAMNT_3', 'RAMNT_4','RAMNT_5','RAMNT_6', 'RAMNT_7','RAMNT_8','RAMNT_9', 'RAMNT_10',\n",
    "          'RAMNT_11','RAMNT_12','RAMNT_13','RAMNT_14','RAMNT_15','RAMNT_16','RAMNT_17','RAMNT_18','RAMNT_19','RAMNT_20'\n",
    "          ,'RAMNT_21','RAMNT_22','RAMNT_23','RAMNT_24']\n",
    "    \n",
    "    \n",
    "    for i in xrange(len(data)):\n",
    "        df[data[i]] = pd.Categorical((pd.factorize(df[data[i]])[0] + 1).astype(str))\n",
    "    \n",
    "    rewards = ['TARGET_D']\n",
    "    \n",
    "    df_data_1 = pd.merge(df[data], df[rewards], left_index = True, right_index = True)\n",
    "    df_data = pd.merge(df_data_1, actions, left_index=True, right_index=True)\n",
    "    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_split():  \n",
    "    df_data = data_preperation()\n",
    "    train, test = train_test_split(df_data, test_size = 0.5)  # split data to 50-50 cross validate \n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df_split()\n",
    "test = test.drop(test.index[len(test)-1]) ## exclude last row in test to have same number of rows as train \n",
    "\n",
    "## prepare train, test\n",
    "rewards = ['TARGET_D']\n",
    "x_train = train[train.columns.difference(['TARGET_D'])]\n",
    "y_train = train[rewards]\n",
    "\n",
    "x_test = test[test.columns.difference(['TARGET_D'])]\n",
    "y_test = test[rewards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RFA_2</th>\n",
       "      <th>RFA_3</th>\n",
       "      <th>RFA_4</th>\n",
       "      <th>RFA_5</th>\n",
       "      <th>RFA_6</th>\n",
       "      <th>RFA_7</th>\n",
       "      <th>RFA_8</th>\n",
       "      <th>RFA_9</th>\n",
       "      <th>RFA_10</th>\n",
       "      <th>RFA_11</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>04</td>\n",
       "      <td>04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>04</td>\n",
       "      <td>04</td>\n",
       "      <td>0</td>\n",
       "      <td>01</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>...</td>\n",
       "      <td>04</td>\n",
       "      <td>04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>09</td>\n",
       "      <td>0</td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RFA_2 RFA_3 RFA_4 RFA_5 RFA_6 RFA_7 RFA_8 RFA_9 RFA_10 RFA_11 ...  36  37  \\\n",
       "783     4     7     7     5     7    11    10     9      2      9 ...  04  04   \n",
       "990     3    21    21    17    46     2     2     3      2      3 ...  04  04   \n",
       "675     4     4     4     5     4    12    14     9      2     68 ...  04  04   \n",
       "264     4     4     4     4    12     1     1     1      1      1 ...   0   0   \n",
       "158     4     4     4     5     4     8     7     7     38     46 ...   0   0   \n",
       "\n",
       "    38  39  40 41  42  43 44  45  \n",
       "783  0   0   0  0   0  10  0   0  \n",
       "990  0  01  12  0  10   0  0  07  \n",
       "675  0   0   0  0   0   0  0   0  \n",
       "264  0   0   0  0   0  09  0  06  \n",
       "158  0   0   0  0   0   0  0   0  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current State variables ..\n",
    "Recency, Frequancy, Montery variables .. ['RFA_2R', 'RFA_2F', 'RFA_2A']\n",
    "\n",
    "## Rewards:\n",
    "- Donation amount \n",
    "- These are the target variables as well .. \n",
    "- TARGET_D, TARGET_B \n",
    "\n",
    "\n",
    "## Actions: \n",
    "- 11 mailing type\n",
    "\n",
    "Actions mapping .. \n",
    "https://github.com/EAboelhamd/kdd98-1/tree/master/notebooks\n",
    "\n",
    "## Actions:\n",
    "\n",
    "- mailing types ..\n",
    "action_mapping = {\n",
    "\n",
    "                                    2: 'NK',  3: 'NK',\n",
    "                                    4: 'TK',  5: 'SK',\n",
    "                                    6: 'LL',  7: 'G1',\n",
    "                                    8: 'GK',  9: 'CC',\n",
    "                                    10: 'WL', 11: 'X1',\n",
    "                                    12: 'XK', 13: 'FS',\n",
    "                                    14: 'NK', 15: 'TK',\n",
    "                                    16: 'LL', 17: 'G1',\n",
    "                                    18: 'GK', 19: 'CC',\n",
    "                                    20: 'WL', 21: 'X1',\n",
    "                                    22: 'XK', 23: 'FS', 24: 'NK'\n",
    "                                }\n",
    "\n",
    "this list contains 11 unique values (NK, TK,LL,GK,WL,XK,SK,G1,CC,X1,FS)\n",
    "\n",
    "                                        NK ==> 2, 14, 23, 24\n",
    "                                        LL ==> 2, 16\n",
    "                                        TK ==> 4, 15\n",
    "                                        GK ==> 8, 18\n",
    "                                        WL ==> 10, 20\n",
    "                                        SK ==> 5\n",
    "                                        G1 ==> 7, 17\n",
    "                                        CC ==> 9, 19\n",
    "                                        X1 ==> 11, 21\n",
    "                                        FS ==> 13, 23\n",
    "\n",
    "Their corresponding meanings are:\n",
    "\n",
    "                                        LL mailings had labels only                                        \n",
    "                                        WL mailings had labels only\n",
    "                                        CC mailings are calendars with stickers but do\n",
    "                                           not have labels\n",
    "                                        FS mailings are blank cards that fold into\n",
    "                                           thirds with labels\n",
    "                                        NK mailings are blank cards with labels\n",
    "                                        SK mailings are blank cards with labels\n",
    "                                        TK mailings have thank you printed on the\n",
    "                                           outside with labels\n",
    "                                        GK mailings are general greeting cards (an\n",
    "                                           assortment of birthday, sympathy, blank, & get\n",
    "                                           well) with labels\n",
    "                                        XK mailings are Christmas cards with labels\n",
    "                                        X1 mailings have labels and a notepad\n",
    "                                        G1 mailings have labels and a notepad\n",
    "\n",
    "- This is why I'm gonna extract the last two digits from the sequance to represent mailing type (unique values are 11 .. NK, TK, SK, LL, G1, GK, CC, WL, X1, XK, FS) + no action .. total action are 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## States:\n",
    "\n",
    "In the cited paper .. they defined the states as follows: \n",
    "\n",
    "It is a 5-dimensional vector consisting of \n",
    "\n",
    "(1) how recently the donor donated last (R)\n",
    "\n",
    "(2) how frequently she donates (F)\n",
    "\n",
    "(3) her average donation amount (M)\n",
    "\n",
    "(4) how many times PVA sends her a mail in the last six months\n",
    "\n",
    "(5) how many times PVA has sent her mails.\n",
    "\n",
    "\n",
    "This implementation is considered as a POMPD .. \n",
    "where:\n",
    "b: belief state that is a probability distribution over all states\n",
    "b(s): prob. that the agent in state s \n",
    "after taking action a and observing the state O .. the update rule for the belief state o(s) is using Bayes rule .. \n",
    "\n",
    "## Next States:\n",
    "\n",
    "As mentioned in the paper ==> the 5-dimensional observation is discrete in this problem, and individual dimensions evolve\n",
    "independently of each other. We therefore build an observation probability table for each observation dimension,\n",
    "and the sample next observations using these tables.\n",
    "\n",
    "Hence, Let's create an n*5 dim observations table .. \n",
    "\n",
    "http://www-anw.cs.umass.edu/~barto/courses/cs687/PartialObs-printable.pdf\n",
    "\n",
    "\n",
    "### These researchers proposed other types of state space ==>\n",
    "\n",
    "https://www.cs.cmu.edu/~ebrun/15889e/hw1.pdf\n",
    "\n",
    "as 9 vars (try it out) ;) .. \n",
    "and others consider (belief, observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_(actions):\n",
    "    \n",
    "    train, test = df_split()\n",
    "    \n",
    "    RFA = ['RFA_2']  # don't know if it is NUMPRM12 or CARDPM12 \n",
    "\n",
    "    ## next state\n",
    "    ## next_states are random selection from the current states\n",
    "    RFA_next = ['RFA_3', 'RFA_4', 'RFA_5', 'RFA_6', 'RFA_7', 'RFA_8', 'RFA_9', 'RFA_10',\n",
    "                'RFA_11', 'RFA_12', 'RFA_13', 'RFA_14', 'RFA_15', 'RFA_16', 'RFA_17', 'RFA_18',\n",
    "                'RFA_19', 'RFA_20', 'RFA_21', 'RFA_22', 'RFA_23', 'RFA_24']\n",
    "\n",
    "    current_states = train['RFA_2']\n",
    "    next_states = train[RFA_next]\n",
    "    \n",
    "    rewards = ['TARGET_D']\n",
    "     \n",
    "    next_actions = np.zeros([len(next_states), 12])\n",
    "    \n",
    "    \n",
    "    #     # fill in next_actions  \n",
    "    for i in xrange(np.shape(next_actions)[1]):\n",
    "        next_actions[:, i] = i\n",
    "        \n",
    "    tuplesMx = np.column_stack((current_states, actions, next_states, next_actions, train[rewards]))\n",
    "\n",
    "    return tuplesMx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actions = actions_prep(df)\n",
    "# tuplesMx = tuple_(actions[:499])\n",
    "# np.shape(tuplesMx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_outputs = tuplesMx[:,-1]\n",
    "# x_inputs = tuplesMx[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression phase:\n",
    "\n",
    "Before performing the prediction task .. let's split the data to training and validation sets .. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid any problems in prediction by having string variables .. let's binarize (catergorize) all the variables .. \n",
    "\n",
    "Guidance ==> https://pythonprogramming.net/rnn-tensorflow-python-machine-learning-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9\n",
    "Num_itrs = 2  \n",
    "batch_size = 200 \n",
    "n_nodes_hl1 = 40 \n",
    "n_nodes_hl2 = 15 \n",
    "NUM_DIM = 81 \n",
    "best_actions = np.zeros([np.shape(x_train)[0], 1])\n",
    "Q_optimal = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Deep Neural Network (DQN):\n",
    "\n",
    "https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/blob/master/contents/5_Deep_Q_Network/RL_brain.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training:\n",
    "\n",
    "https://stackoverflow.com/questions/46832151/tensorflow-neural-network-multi-layer-perceptron-for-regression-example\n",
    "\n",
    "Guidance: https://www.youtube.com/watch?v=FbJw8J0rTyQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN_train(x_inputs, y_outputs):\n",
    "    \n",
    "    ######################## set learning variables ##################\n",
    "    \n",
    "    learning_rate = 0.001  #Learning rate controls how much to change the weight to correct for the error. \n",
    "    epochs = 100\n",
    "    \n",
    "    ######################## set some variables #######################\n",
    "    x = tf.placeholder(tf.float32)  # 3 features  # , [None, NUM_DIM], name='x'\n",
    "    y = tf.placeholder(tf.float32)  # 3 outputs   # , [None, 1], name='y'\n",
    "\n",
    "    \n",
    "    # hidden layer 1\n",
    "    W1 = tf.Variable(tf.random_uniform([NUM_DIM, n_nodes_hl1],0, 3), name='W1')\n",
    "    b1 = tf.Variable(tf.random_uniform([n_nodes_hl1],0,3), name='b1')\n",
    "\n",
    "    # hidden layer 2\n",
    "    W2 = tf.Variable(tf.random_uniform([n_nodes_hl1, n_nodes_hl2],0,3), name='W2')\n",
    "    b2 = tf.Variable(tf.random_uniform([n_nodes_hl2],0,3), name='b2')\n",
    "\n",
    "    ######################## Activations, outputs ######################\n",
    "    # output hidden layer 1\n",
    "    hidden_out = tf.nn.relu(tf.add(tf.matmul(x, W1), b1))\n",
    "\n",
    "#     total output\n",
    "    y_ = tf.nn.relu(tf.add(tf.matmul(hidden_out, W2), b2))\n",
    "    \n",
    "    \n",
    "    ####################### Loss Function  #########################\n",
    "    mse = tf.losses.mean_squared_error(y, y_)\n",
    "\n",
    "    ## I can try Adam optimizer ==> = GD Momentum + RMSProb \n",
    "    ####################### Optimizer ######################### read more about RMSProb: https://www.youtube.com/watch?v=_e-LFe_igno\n",
    "    optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate, decay=0.99).minimize(mse)  # optimizer like Gredient Descent \n",
    "\n",
    "    ###################### Initialize, Accuracy and Run #################\n",
    "    # initialize variables\n",
    "    init_op = tf.global_variables_initializer()\n",
    "\n",
    "    # accuracy for the test set\n",
    "    accuracy = tf.reduce_mean(tf.square(tf.subtract(y, y_)))  # or could use tf.losses.mean_squared_error\n",
    "\n",
    "    loss_RNN = []\n",
    "    \n",
    "    avg_ = []\n",
    "    \n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        total_batch = int(len(y_outputs) / batch_size)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "#             avg_cost = 0\n",
    "            \n",
    "            for i in range(total_batch):\n",
    "                batch_x, batch_y = x_inputs[i * batch_size:min(i * batch_size + batch_size, len(x_inputs))], \\\n",
    "                             y_outputs[i * batch_size:min(i * batch_size + batch_size, len(y_outputs))]\n",
    "                \n",
    "#                 print batch_y[0]\n",
    "                \n",
    "                predicted_output = sess.run(y_[0], feed_dict={x: batch_x, y: batch_y[0]})\n",
    "                \n",
    "                _, c = sess.run([optimizer, mse], feed_dict={x: batch_x, y: batch_y[0]})\n",
    "\n",
    "#                 avg_cost += c / total_batch          \n",
    "            \n",
    "#             if epoch % 100 == 0:\n",
    "#                 avg_.append(avg_cost)\n",
    "#                 plt.plot(avg_)\n",
    "#                 plt.xlabel('Step Number')\n",
    "#                 plt.ylabel('Prediction Loss')\n",
    "                \n",
    "        return predicted_output.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q(s,a) representing the (Quality) of action a at state is .. \n",
    "\n",
    "this Q value depends on the immediate reward r .. however, it'll be more effective if it takes the future rewards Q(s', a') into consideration .. \n",
    "\n",
    "the future rewards are discounted by probability gama .. cause the evironment is stochastic hence, it is uncertain that each time you select action a you gonna get the same reward r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_learning():\n",
    "    \n",
    "    avg_Q = []    \n",
    "    Q_predicted = np.zeros([499, 12]) #num_rows, num_columns\n",
    "    \n",
    "    best_action = list() \n",
    "    \n",
    "    actions = actions_prep(df)\n",
    "    nepisod =  np.shape(actions)[1]  ##22+\n",
    "    \n",
    "    for i in xrange(nepisod):\n",
    "        tuplesMx = tuple_(actions[:499])  # nepisod ==> 46, tuplesMx[:,-1] ==> 499\n",
    "        \n",
    "        Q_optimal = tuplesMx[:,-1].astype(np.float32) + gamma*np.max(Q_predicted) # returns max value per row !\n",
    "        \n",
    "        Q_predicted = DQN_train(tuplesMx[:,:-1], Q_optimal)\n",
    "\n",
    "        best_action.append(np.argmax(Q_predicted, axis=0))\n",
    "       \n",
    "    return best_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_action = Q_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 4,\n",
       "         1: 1,\n",
       "         2: 4,\n",
       "         3: 2,\n",
       "         4: 4,\n",
       "         5: 2,\n",
       "         6: 2,\n",
       "         7: 2,\n",
       "         8: 3,\n",
       "         9: 3,\n",
       "         10: 3,\n",
       "         11: 5,\n",
       "         12: 4,\n",
       "         13: 4,\n",
       "         14: 3})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(best_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
