{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "This is a reimplementation for Siraj's trials to imeplement simple Q learning model .. \n",
    "Link of his trials => https://github.com/llSourcell/q_learning_demo\n",
    "\n",
    "- Rules: The agent (yellow box) has to reach one of the goals to end the game (green or red cell).\n",
    "- Rewards: Each step gives a negative reward of -0.04. The red cell gives a negative reward of -1. The green one gives a positive reward of +1.\n",
    "- States: Each cell is a state the agent can be.\n",
    "- Actions: There are only 4 actions. Up, Down, Right, Left.\n",
    "\n",
    "We gonna import world.py that contains the layout of the play board .. \n",
    "\n",
    "Practice more codes on RL here ==> \n",
    "https://github.com/EAboelhamd/Reinforcement-learning-with-tensorflow\n",
    "\n",
    "and this is the watch list ==> https://www.youtube.com/watch?v=gWNeMs1Fb8I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import World\n",
    "import threading\n",
    "import time\n",
    "\n",
    "## warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discount = 0.3  # discount factor\n",
    "actions = World.actions\n",
    "states = []\n",
    "Q = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(World.x):\n",
    "    for j in range(World.y):\n",
    "        states.append((i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (0, 4),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (1, 4),\n",
       " (2, 0),\n",
       " (2, 1),\n",
       " (2, 2),\n",
       " (2, 3),\n",
       " (2, 4),\n",
       " (3, 0),\n",
       " (3, 1),\n",
       " (3, 2),\n",
       " (3, 3),\n",
       " (3, 4),\n",
       " (4, 0),\n",
       " (4, 1),\n",
       " (4, 2),\n",
       " (4, 3),\n",
       " (4, 4)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states  ## 4 by 4 grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in states:\n",
    "    temp = {}\n",
    "    for action in actions:\n",
    "        temp[action] = 0.1\n",
    "#         World.set_cell_score(state, action, temp[action])\n",
    "    Q[state] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (0, 1): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (0, 2): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (0, 3): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (0, 4): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (1, 0): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (1, 1): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (1, 2): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (1, 3): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (1, 4): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (2, 0): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (2, 1): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (2, 2): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (2, 3): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (2, 4): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (3, 0): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (3, 1): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (3, 2): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (3, 3): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (3, 4): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (4, 0): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (4, 1): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (4, 2): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (4, 3): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (4, 4): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling the special cells .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 1, 'red', -1), (4, 0, 'green', 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "World.specials   ## special cells in the grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, j, c, w) in World.specials:\n",
    "    for action in actions:\n",
    "        Q[(i, j)][action] = w\n",
    "#         World.set_cell_score((i, j), action, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (0, 1): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (0, 2): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (0, 3): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (0, 4): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (1, 0): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (1, 1): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (1, 2): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (1, 3): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (1, 4): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (2, 0): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (2, 1): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (2, 2): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (2, 3): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (2, 4): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (3, 0): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (3, 1): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (3, 2): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (3, 3): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (3, 4): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (4, 0): {'down': 1, 'left': 1, 'right': 1, 'up': 1},\n",
       " (4, 1): {'down': -1, 'left': -1, 'right': -1, 'up': -1},\n",
       " (4, 2): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (4, 3): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1},\n",
       " (4, 4): {'down': 0.1, 'left': 0.1, 'right': 0.1, 'up': 0.1}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do actions .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 4), -1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "World.player, -World.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_action(action):\n",
    "    s = World.player\n",
    "    r = -World.score\n",
    "    if action == actions[0]:\n",
    "        World.try_move(0, -1)\n",
    "    elif action == actions[1]:\n",
    "        World.try_move(0, 1)\n",
    "    elif action == actions[2]:\n",
    "        World.try_move(-1, 0)\n",
    "    elif action == actions[3]:\n",
    "        World.try_move(1, 0)\n",
    "    else:\n",
    "        return\n",
    "    s2 = World.player\n",
    "    r += World.score\n",
    "    return s, action, r, s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max. Q value .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_Q(s):\n",
    "    val = None\n",
    "    act = None\n",
    "    for a, q in Q[s].items():\n",
    "        if val is None or (q > val):\n",
    "            val = q\n",
    "            act = a\n",
    "    return act, val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increment Q .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inc_Q(s, a, alpha, inc):\n",
    "    Q[s][a] *= 1 - alpha\n",
    "    Q[s][a] += alpha * inc\n",
    "    World.set_cell_score(s, a, Q[s][a])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    global discount\n",
    "    time.sleep(1)\n",
    "    alpha = 1\n",
    "    t = 1\n",
    "    while True:  #agent will play indefinitely \n",
    "        # Pick the right action\n",
    "        s = World.player\n",
    "        max_act, max_val = max_Q(s)  # at each state s .. choose a that results in max Q value\n",
    "        (s, a, r, s2) = do_action(max_act)\n",
    "\n",
    "        # Update Q\n",
    "        max_act, max_val = max_Q(s2)  # s2 ==> next state \n",
    "        inc_Q(s, a, alpha, r + discount * max_val)\n",
    "\n",
    "        # Check if the game has restarted\n",
    "        t += 1.0\n",
    "        if World.has_restarted():\n",
    "            World.restart_game()\n",
    "            time.sleep(0.01)\n",
    "            t = 1.0\n",
    "\n",
    "        # Update the learning rate\n",
    "        alpha = pow(t, -0.1)\n",
    "\n",
    "        # MODIFY THIS SLEEP IF THE GAME IS GOING TOO FAST.\n",
    "        time.sleep(0.1)\n",
    "        return max_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Thread(Thread-5, initial)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = threading.Thread(target=run)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"<ipython-input-14-171f240d865e>\", line 10, in run\n",
      "    (s, a, r, s2) = do_action(max_act)\n",
      "  File \"<ipython-input-11-ea97459eb49d>\", line 11, in do_action\n",
      "    World.try_move(1, 0)\n",
      "  File \"World.py\", line 85, in try_move\n",
      "    board.coords(me, new_x*Width+Width*2/10, new_y*Width+Width*2/10, new_x*Width+Width*8/10, new_y*Width+Width*8/10)\n",
      "  File \"/usr/lib/python2.7/lib-tk/Tkinter.py\", line 2298, in coords\n",
      "    self.tk.call((self._w, 'coords') + args)))\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"<ipython-input-20-4a034a73e43d>\", line 14, in run\n",
      "    inc_Q(s, a, alpha, r + discount * max_val)\n",
      "  File \"<ipython-input-13-ab9fc64aac7f>\", line 4, in inc_Q\n",
      "    World.set_cell_score(s, a, Q[s][a])\n",
      "  File \"World.py\", line 74, in set_cell_score\n",
      "    board.itemconfigure(triangle, fill=color)\n",
      "  File \"/usr/lib/python2.7/lib-tk/Tkinter.py\", line 2407, in itemconfigure\n",
      "    return self._configure(('itemconfigure', tagOrId), cnf, kw)\n",
      "  File \"/usr/lib/python2.7/lib-tk/Tkinter.py\", line 1320, in _configure\n",
      "    self.tk.call(_flatten((self._w, cmd)) + self._options(cnf))\n",
      "RuntimeError: main thread is not in main loop\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# t.daemon = True  ## in case we don't want to display the grid of World game .. this will raise an error \n",
    "t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment:\n",
    "\n",
    "This was a basic implementation of Q learning concept for a 4x4 board game .. the aim of the game was to maximize the long term reward of the player through the movements .. the agent is expected to learn from the environment .. update its state and actions based on the recieved reward ..  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
