{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction .. \n",
    "\n",
    "This notebook mimics the imeplmentation of Siraj's notebook hereunder .. \n",
    "https://github.com/llSourcell/deep_q_learning/blob/master/03_PlayingAgent.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential      # One layer after the other\n",
    "from keras.layers import Dense, Flatten  # Dense layers are fully connected layers, Flatten layers flatten out multidimensional inputs\n",
    "from collections import deque            # For storing moves \n",
    "\n",
    "import numpy as np\n",
    "import gym  \n",
    "\n",
    "import random \n",
    "\n",
    "## warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')          # Choose game (any in the gym should work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TimeLimit<MountainCarEnv<MountainCar-v0>>>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model: \n",
    "\n",
    "Create network using Keras..\n",
    "Input is two consecutive game states, output is Q-values of the possible moves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_shape=(2,) + env.observation_space.shape, init='uniform', activation='relu'))\n",
    "model.add(Flatten()) # Flatten input so as to have no problems with processing\n",
    "model.add(Dense(18, init='uniform', activation='relu'))\n",
    "model.add(Dense(10, init='uniform', activation='relu'))\n",
    "model.add(Dense(env.action_space.n, init='uniform', activation='linear'))    # Same number of outputs as possible actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Init vars ..\n",
    "\n",
    "D = deque()                                # Register where the actions will be stored\n",
    "observetime = 500                          # Number of timesteps we will be acting on the game and observing results\n",
    "epsilon = 0.7                              # Probability of doing a random move\n",
    "gamma = 0.9                                # Discounted future reward. How much we care about steps further in time\n",
    "mb_size = 50                               # Learning minibatch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Observation phase:\n",
    "Knowing what each action does (Observing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.59319545  0.        ]]\n",
      "[[[-0.59319545  0.        ]\n",
      "  [-0.59319545  0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "observation = env.reset()                     # Game begins\n",
    "obs = np.expand_dims(observation, axis=0)     # (Formatting issues) Making the observation the first element of a batch of inputs \n",
    "state = np.stack((obs, obs), axis=1)\n",
    "done = False\n",
    "\n",
    "print obs\n",
    "print state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.52951826, -0.00276455],\n",
       "        [-0.5267537 , -0.00378822]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for t in range(observetime):\n",
    "    if np.random.rand() <= epsilon:\n",
    "        action = np.random.randint(0, env.action_space.n, size=1)[0]\n",
    "    else: #Q_learning\n",
    "        Q = model.predict(state)          # Q-values predictions\n",
    "        action = np.argmax(Q)             # Move with highest Q-value is the chosen one\n",
    "        \n",
    "    observation_new, reward, done, info = env.step(action)     # See state of the game, reward... after performing the action\n",
    "    obs_new = np.expand_dims(observation_new, axis=0)          # (Formatting issues)\n",
    "    state_new = np.append(np.expand_dims(obs_new, axis=0), state[:, :1, :], axis=1)     # Update the input with the new state of the game\n",
    "    D.append((state, action, reward, state_new, done))         # 'Remember' action and consequence\n",
    "    state = state_new         # Update state\n",
    "    if done:\n",
    "        env.reset()           # Restart game if it's finished\n",
    "        obs = np.expand_dims(observation, axis=0)     # (Formatting issues) Making the observation the first element of a batch of inputs \n",
    "        state = np.stack((obs, obs), axis=1)\n",
    "        \n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Experience Reply:\n",
    "Learning from the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[[-0.50946858,  0.01168701],\n",
       "          [-0.52115558,  0.01070533]]]),\n",
       "  1,\n",
       "  -1.0,\n",
       "  array([[[-0.49788751,  0.01158106],\n",
       "          [-0.50946858,  0.01168701]]]),\n",
       "  False),\n",
       " (array([[[-0.45920599,  0.01058325],\n",
       "          [-0.46978924,  0.01098507]]]),\n",
       "  0,\n",
       "  -1.0,\n",
       "  array([[[-0.45010269,  0.0091033 ],\n",
       "          [-0.45920599,  0.01058325]]]),\n",
       "  False),\n",
       " (array([[[-0.3260864 ,  0.00365553],\n",
       "          [-0.32974194,  0.00602888]]]),\n",
       "  0,\n",
       "  -1.0,\n",
       "  array([[[-0.32482704,  0.00125937],\n",
       "          [-0.3260864 ,  0.00365553]]]),\n",
       "  False),\n",
       " (array([[[-0.52511013,  0.00976419],\n",
       "          [-0.53487432,  0.00867964]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[-0.51433461,  0.01077552],\n",
       "          [-0.52511013,  0.00976419]]]),\n",
       "  False),\n",
       " (array([[[ -5.02947025e-01,   1.46344345e-04],\n",
       "          [ -5.03093369e-01,  -6.99962086e-04]]]),\n",
       "  1,\n",
       "  -1.0,\n",
       "  array([[[ -5.02955470e-01,  -8.44471655e-06],\n",
       "          [ -5.02947025e-01,   1.46344345e-04]]]),\n",
       "  False),\n",
       " (array([[[-0.5094851 ,  0.00061807],\n",
       "          [-0.51010317,  0.00071926]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[-0.50797286,  0.00151224],\n",
       "          [-0.5094851 ,  0.00061807]]]),\n",
       "  False),\n",
       " (array([[[-0.47514554,  0.00163747],\n",
       "          [-0.47678301,  0.00298743]]]),\n",
       "  1,\n",
       "  -1.0,\n",
       "  array([[[-0.4738702 ,  0.00127535],\n",
       "          [-0.47514554,  0.00163747]]]),\n",
       "  False),\n",
       " (array([[[-0.45955617,  0.001027  ],\n",
       "          [-0.46058318,  0.00049681]]]),\n",
       "  0,\n",
       "  -1.0,\n",
       "  array([[[ -4.60006536e-01,  -4.50365373e-04],\n",
       "          [ -4.59556171e-01,   1.02700460e-03]]]),\n",
       "  False),\n",
       " (array([[[-0.41230656, -0.00042678],\n",
       "          [-0.41187978,  0.00139551]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[ -4.12552617e-01,  -2.46052040e-04],\n",
       "          [ -4.12306565e-01,  -4.26781934e-04]]]),\n",
       "  False),\n",
       " (array([[[ -5.02118640e-01,   8.36829436e-04],\n",
       "          [ -5.02955470e-01,  -8.44471655e-06]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[-0.5004428 ,  0.00167584],\n",
       "          [-0.50211864,  0.00083683]]]),\n",
       "  False),\n",
       " (array([[[-0.64761023, -0.01378622],\n",
       "          [-0.63382402, -0.01359792]]]),\n",
       "  1,\n",
       "  -1.0,\n",
       "  array([[[-0.66048767, -0.01287744],\n",
       "          [-0.64761023, -0.01378622]]]),\n",
       "  False),\n",
       " (array([[[-0.56725   ,  0.0109251 ],\n",
       "          [-0.57817511,  0.01051761]]]),\n",
       "  1,\n",
       "  -1.0,\n",
       "  array([[[-0.55599845,  0.01125155],\n",
       "          [-0.56725   ,  0.0109251 ]]]),\n",
       "  False),\n",
       " (array([[[ -7.16144866e-01,   3.98623216e-04],\n",
       "          [ -7.16543489e-01,  -1.96899770e-03]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[ -7.13381125e-01,   2.76374049e-03],\n",
       "          [ -7.16144866e-01,   3.98623216e-04]]]),\n",
       "  False),\n",
       " (array([[[-0.49454729, -0.01330763],\n",
       "          [-0.48123966, -0.01299079]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[-0.50707252, -0.01252524],\n",
       "          [-0.49454729, -0.01330763]]]),\n",
       "  False),\n",
       " (array([[[-0.43259882,  0.00894734],\n",
       "          [-0.44154615,  0.00855654]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[-0.42332553,  0.00927328],\n",
       "          [-0.43259882,  0.00894734]]]),\n",
       "  False),\n",
       " (array([[[-0.3263599 ,  0.007522  ],\n",
       "          [-0.3338819 ,  0.00986929]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[-0.31923237,  0.00712753],\n",
       "          [-0.3263599 ,  0.007522  ]]]),\n",
       "  False),\n",
       " (array([[[-0.42212449, -0.00364183],\n",
       "          [-0.41848266, -0.00386646]]]),\n",
       "  1,\n",
       "  -1.0,\n",
       "  array([[[-0.42651568, -0.00439119],\n",
       "          [-0.42212449, -0.00364183]]]),\n",
       "  False),\n",
       " (array([[[-0.4723958 ,  0.01310329],\n",
       "          [-0.48549909,  0.01238842]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[-0.45867502,  0.01372078],\n",
       "          [-0.4723958 ,  0.01310329]]]),\n",
       "  False),\n",
       " (array([[[-0.49949958,  0.01352926],\n",
       "          [-0.51302884,  0.01460852]]]),\n",
       "  1,\n",
       "  -1.0,\n",
       "  array([[[-0.48615091,  0.01334867],\n",
       "          [-0.49949958,  0.01352926]]]),\n",
       "  False),\n",
       " (array([[[ -5.87123598e-01,  -1.43605086e-04],\n",
       "          [ -5.86979993e-01,  -6.16104985e-04]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[ -5.85793646e-01,   1.32995240e-03],\n",
       "          [ -5.87123598e-01,  -1.43605086e-04]]]),\n",
       "  False),\n",
       " (array([[[-0.44459232, -0.01149196],\n",
       "          [-0.43310036, -0.01182153]]]),\n",
       "  1,\n",
       "  -1.0,\n",
       "  array([[[-0.4566713 , -0.01207898],\n",
       "          [-0.44459232, -0.01149196]]]),\n",
       "  False),\n",
       " (array([[[-0.48208564,  0.00362574],\n",
       "          [-0.48571138,  0.00490929]]]),\n",
       "  0,\n",
       "  -1.0,\n",
       "  array([[[-0.47977044,  0.0023152 ],\n",
       "          [-0.48208564,  0.00362574]]]),\n",
       "  False),\n",
       " (array([[[-0.54355395,  0.00753006],\n",
       "          [-0.55108401,  0.00832416]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[-0.53487432,  0.00867964],\n",
       "          [-0.54355395,  0.00753006]]]),\n",
       "  False),\n",
       " (array([[[-0.50469018, -0.0071939 ],\n",
       "          [-0.49749627, -0.00799833]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[-0.51102582, -0.00633564],\n",
       "          [-0.50469018, -0.0071939 ]]]),\n",
       "  False),\n",
       " (array([[[-0.64497095, -0.01061327],\n",
       "          [-0.63435768, -0.01042876]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[-0.65369391, -0.00872296],\n",
       "          [-0.64497095, -0.01061327]]]),\n",
       "  False),\n",
       " (array([[[-0.26020385,  0.01054079],\n",
       "          [-0.27074464,  0.01326049]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[-0.25043926,  0.00976458],\n",
       "          [-0.26020385,  0.01054079]]]),\n",
       "  False),\n",
       " (array([[[-0.56209595, -0.00687281],\n",
       "          [-0.55522313, -0.00710964]]]),\n",
       "  0,\n",
       "  -1.0,\n",
       "  array([[[-0.56968067, -0.00758473],\n",
       "          [-0.56209595, -0.00687281]]]),\n",
       "  False),\n",
       " (array([[[-0.41848266, -0.00386646],\n",
       "          [-0.4146162 , -0.00206358]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[-0.42212449, -0.00364183],\n",
       "          [-0.41848266, -0.00386646]]]),\n",
       "  False),\n",
       " (array([[[-0.52763736,  0.01457823],\n",
       "          [-0.54221559,  0.01343868]]]),\n",
       "  1,\n",
       "  -1.0,\n",
       "  array([[[-0.51302884,  0.01460852],\n",
       "          [-0.52763736,  0.01457823]]]),\n",
       "  False),\n",
       " (array([[[-0.2352379 ,  0.00318824],\n",
       "          [-0.23842614,  0.00507551]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[-0.23295254,  0.00228537],\n",
       "          [-0.2352379 ,  0.00318824]]]),\n",
       "  False),\n",
       " (array([[[-0.51774796,  0.00192585],\n",
       "          [-0.51967382,  0.00095529]]]),\n",
       "  1,\n",
       "  -1.0,\n",
       "  array([[[-0.51586599,  0.00188197],\n",
       "          [-0.51774796,  0.00192585]]]),\n",
       "  False),\n",
       " (array([[[-0.48571138,  0.00490929],\n",
       "          [-0.49062067,  0.00615622]]]),\n",
       "  0,\n",
       "  -1.0,\n",
       "  array([[[-0.48208564,  0.00362574],\n",
       "          [-0.48571138,  0.00490929]]]),\n",
       "  False),\n",
       " (array([[[-0.4284929 , -0.01346124],\n",
       "          [-0.41503166, -0.01366131]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[-0.4416578 , -0.0131649 ],\n",
       "          [-0.4284929 , -0.01346124]]]),\n",
       "  False),\n",
       " (array([[[-0.53700788, -0.01325607],\n",
       "          [-0.5237518 , -0.01325722]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[-0.54916341, -0.01215553],\n",
       "          [-0.53700788, -0.01325607]]]),\n",
       "  False),\n",
       " (array([[[-0.69514224,  0.00670073],\n",
       "          [-0.70184297,  0.00642671]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[-0.68621097,  0.00893127],\n",
       "          [-0.69514224,  0.00670073]]]),\n",
       "  False),\n",
       " (array([[[-0.56981797, -0.00969057],\n",
       "          [-0.5601274 , -0.01096399]]]),\n",
       "  1,\n",
       "  -1.0,\n",
       "  array([[[-0.579163  , -0.00934504],\n",
       "          [-0.56981797, -0.00969057]]]),\n",
       "  False),\n",
       " (array([[[-0.61630805,  0.00354016],\n",
       "          [-0.61984821,  0.00382828]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[-0.6110815 ,  0.00522655],\n",
       "          [-0.61630805,  0.00354016]]]),\n",
       "  False),\n",
       " (array([[[-0.68017412, -0.00880707],\n",
       "          [-0.67136706, -0.01087939]]]),\n",
       "  1,\n",
       "  -1.0,\n",
       "  array([[[-0.68784959, -0.00767546],\n",
       "          [-0.68017412, -0.00880707]]]),\n",
       "  False),\n",
       " (array([[[-0.51620281, -0.00069736],\n",
       "          [-0.51550545, -0.00163667]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[ -5.15955639e-01,   2.47173280e-04],\n",
       "          [ -5.16202812e-01,  -6.97361544e-04]]]),\n",
       "  False),\n",
       " (array([[[-0.28990548, -0.00127617],\n",
       "          [-0.28862931,  0.00034374]]]),\n",
       "  1,\n",
       "  -1.0,\n",
       "  array([[[-0.29279425, -0.00288878],\n",
       "          [-0.28990548, -0.00127617]]]),\n",
       "  False),\n",
       " (array([[[-0.35490484,  0.01136553],\n",
       "          [-0.36627037,  0.01150217]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[-0.34375119,  0.01115365],\n",
       "          [-0.35490484,  0.01136553]]]),\n",
       "  False),\n",
       " (array([[[-0.34030762,  0.00213795],\n",
       "          [-0.34244556,  0.0034307 ]]]),\n",
       "  1,\n",
       "  -1.0,\n",
       "  array([[[-0.33947612,  0.0008315 ],\n",
       "          [-0.34030762,  0.00213795]]]),\n",
       "  False),\n",
       " (array([[[-0.36977321,  0.00477746],\n",
       "          [-0.37455067,  0.00485845]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[-0.36510892,  0.00466429],\n",
       "          [-0.36977321,  0.00477746]]]),\n",
       "  False),\n",
       " (array([[[-0.52995122,  0.00918869],\n",
       "          [-0.53913991,  0.00907217]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[-0.51971489,  0.01023633],\n",
       "          [-0.52995122,  0.00918869]]]),\n",
       "  False),\n",
       " (array([[[-0.3338819 ,  0.00986929],\n",
       "          [-0.34375119,  0.01115365]]]),\n",
       "  0,\n",
       "  -1.0,\n",
       "  array([[[-0.3263599 ,  0.007522  ],\n",
       "          [-0.3338819 ,  0.00986929]]]),\n",
       "  False),\n",
       " (array([[[-0.32747917, -0.00195358],\n",
       "          [-0.32552559, -0.00155392]]]),\n",
       "  1,\n",
       "  -1.0,\n",
       "  array([[[-0.33082024, -0.00334107],\n",
       "          [-0.32747917, -0.00195358]]]),\n",
       "  False),\n",
       " (array([[[-0.59439081,  0.00079415],\n",
       "          [-0.59518497,  0.00126137]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[-0.5920697 ,  0.00232111],\n",
       "          [-0.59439081,  0.00079415]]]),\n",
       "  False),\n",
       " (array([[[-0.52636742,  0.00971018],\n",
       "          [-0.53607761,  0.00861661]]]),\n",
       "  1,\n",
       "  -1.0,\n",
       "  array([[[-0.51663648,  0.00973095],\n",
       "          [-0.52636742,  0.00971018]]]),\n",
       "  False),\n",
       " (array([[[-0.45009707,  0.01773896],\n",
       "          [-0.46783603,  0.01715523]]]),\n",
       "  2,\n",
       "  -1.0,\n",
       "  array([[[-0.43190492,  0.01819215],\n",
       "          [-0.45009707,  0.01773896]]]),\n",
       "  False),\n",
       " (array([[[-0.513042  ,  0.00282398],\n",
       "          [-0.51586599,  0.00188197]]]),\n",
       "  1,\n",
       "  -1.0,\n",
       "  array([[[-0.51029718,  0.00274482],\n",
       "          [-0.513042  ,  0.00282398]]]),\n",
       "  False)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minibatch = random.sample(D, mb_size)\n",
    "minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_shape = (mb_size,) + state.shape[1:]\n",
    "inputs_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.zeros(inputs_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = np.zeros((mb_size, env.action_space.n))\n",
    "np.shape(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning is done\n"
     ]
    }
   ],
   "source": [
    "## selecting from D\n",
    "\n",
    "for i in range(0, mb_size):\n",
    "    state = minibatch[i][0]\n",
    "    action = minibatch[i][1]\n",
    "    reward = minibatch[i][2]\n",
    "    state_new = minibatch[i][3]\n",
    "    done = minibatch[i][4]\n",
    "    \n",
    "    # Build Bellman equation for the Q function\n",
    "    inputs[i:i+1] = np.expand_dims(state, axis=0)\n",
    "    targets[i] = model.predict(state)\n",
    "    Q_sa = model.predict(state_new)\n",
    "    \n",
    "    if done:\n",
    "        targets[i, action] = reward\n",
    "    else:\n",
    "        targets[i, action] = reward + gamma * np.max(Q_sa)\n",
    "        \n",
    "    # Train network to output the Q function\n",
    "    model.train_on_batch(inputs, targets)\n",
    "print \"Learning is done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Play!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game ended! Total reward: -1.0\n"
     ]
    }
   ],
   "source": [
    "observation = env.reset()\n",
    "obs = np.expand_dims(observation, axis=0)\n",
    "state = np.stack((obs, obs), axis=1)\n",
    "done = False\n",
    "tot_reward = 0.0\n",
    "\n",
    "while not done:\n",
    "    env.render()                    # Uncomment to see game running\n",
    "    Q = model.predict(state)        \n",
    "    action = np.argmax(Q)         \n",
    "    observation, reward, done, info = env.step(action)\n",
    "    obs = np.expand_dims(observation, axis=0)\n",
    "    state = np.append(np.expand_dims(obs, axis=0), state[:, :1, :], axis=1)    \n",
    "    tot_reward += reward\n",
    "print('Game ended! Total reward: {}'.format(reward))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
